## Project Structure
The project is organized into the following directories:
```
./
│   ├── bamboo_ta/
│   ├── docs/
│   └── setup.py
│   └── requirements.txt
│   └── a.py
│   └── testallatonce.py
│   ├── bamboo_ta/
│   │   └── performance.py
│   │   └── statistics.py
│   │   └── trend.py
│   │   └── volume.py
│   │   └── cycles.py
│   │   └── bamboo_ta.py
│   │   └── candles.py
│   │   └── utility.py
│   │   └── volatility.py
│   │   └── __init__.py
│   │   └── momentum.py
│   ├── docs/
│   │   └── momentum.md
│   │   └── trend.md
│   │   └── volatility.md
│   │   └── volume.md
│   │   └── candles.md
│   │   └── statistics.md
│   │   └── pip-package-making.md
│   │   └── performance.md
│   │   └── cycles.md
│   │   └── utility.md
```

Detailed File Contents:

./
    setup.py

    ----- Start of setup.py -----

from setuptools import setup, find_packages
import os

here = os.path.abspath(os.path.dirname(__file__))

VERSION = '0.2.0'
DESCRIPTION = 'TA library for Pandas'

with open("README.md", "r") as f:
    LONG_DESCRIPTION = f.read()

# Setting up
setup(
    name="bamboo-ta",
    version=VERSION,
    author="DutchCryptoDad (DCD)",
    author_email="<dutchcryptodad@gmail.com>",
    url="https://github.com/DutchCryptoDad/bamboo-ta",
    description=DESCRIPTION,
    long_description_content_type="text/markdown",
    long_description=LONG_DESCRIPTION,
    packages=find_packages(),
    keywords=['python', 'pandas', 'numpy',
              'trading', 'indicator', 'technical analysis'],
    classifiers=[
        "Development Status :: 2 - Pre-Alpha", # see https://pypi.org/classifiers/
        "Intended Audience :: Developers",
        "Programming Language :: Python :: 3",
        "Operating System :: Unix",
        "Operating System :: MacOS :: MacOS X",
        "Operating System :: Microsoft :: Windows",
    ],
    install_requires=['pandas', 'numpy'],
    extras_require={
        "def": ["pytest", "twine"],
    },
    python_requres=">=3.10",
)

    ----- End of setup.py -----

    requirements.txt

    ----- Start of requirements.txt -----

ta
numpy
pandas
pandas_ta

    ----- End of requirements.txt -----

    a.py

    ----- Start of a.py -----

import bamboo_ta as bta
print(dir(bta))

    ----- End of a.py -----

    testallatonce.py

    ----- Start of testallatonce.py -----

# -*- coding: utf-8 -*-
# Import necessary libraries
# Importeer necessary libraries
import bamboo_ta.bamboo_ta as bta
#import pandas_ta as pta
import pandas as pd
from pandas import DataFrame
import numpy as np

# Create dataframe
# create dataframe and read the json data in the datasets directory
df = pd.read_json("./BTC_USDT-1d.json")
# name the columns that are loaded into the dataframe
df.columns = ['date', 'open', 'high', 'low', 'close', 'volume']
# the date column consists of unix time in milliseconds, so this command changes this data into human readable form.
df['date'] = (pd.to_datetime(df['date'], unit='ms'))

# ========================================
# ALl the functions below are tested and work fine. If there are any errors, then they will be discovered when
# executing this file/

### CANDLES.PY FUNCTIES ###

exhaustion = bta.exhaustion_bars(df)
df['leledc_major'] = exhaustion['leledc_major']
df['leledc_minor'] = exhaustion['leledc_minor']

dynamic_exhaustion = bta.dynamic_exhaustion_bars(df)
df['dynamic_leledc_major'] = dynamic_exhaustion['leledc_major']
df['dynamic_leledc_minor'] = dynamic_exhaustion['leledc_minor']

ha_df = bta.heiken_ashi(df)
df['ha_open'] = ha_df['ha_open']
df['ha_high'] = ha_df['ha_high']
df['ha_low'] = ha_df['ha_low']
df['ha_close'] = ha_df['ha_close']

lr_df = bta.linear_regression_candles(df)
df['lrc_open'] = lr_df['bopen']
df['lrc_high'] = lr_df['bhigh']
df['lrc_low'] = lr_df['blow']
df['lrc_close'] = lr_df['bclose']
df['lrc_signal'] = lr_df['signal']

# ## MOMENTUM.PY FUNCTIES ###

df['ao'] = bta.awesome_oscillator(df, 'high', 'low', 5, 34)['ao']

df['cmo'] = bta.chande_momentum_oscillator(df)

df['ewo'] = bta.elliott_wave_oscillator(df, 'close', 5, 35)

fscg = bta.ehlers_fisher_stochastic_center_of_gravity(df)
df['cg'] = fscg['cg']
df['trigger'] = fscg['trigger']

df['kama'] = bta.kaufmans_adaptive_moving_average(df)['kama']

macd_result = bta.macd(df, 'close', 12, 26, 9)
df['macd'] = macd_result['macd']
df['macd_signal'] = macd_result['macd_signal']
df['macd_histogram'] = macd_result['macd_histogram']

df['macd_leader'] = bta.macd_leader(df, 'close')['macd_leader']

df['ma_streak'] = bta.ma_streak(df, length=10, src='close', matype=1)['ma_streak']

ppo = bta.percentage_price_oscillator(df)
df['ppo'] = ppo['ppo']
df['ppo_signal'] = ppo['ppo_signal']
df['ppo_hist'] = ppo['ppo_hist']

pvo = bta.percentage_volume_oscillator(df)
df['pvo'] = pvo['pvo']
df['pvo_signal'] = pvo['pvo_signal']
df['pvo_hist'] = pvo['pvo_hist']

df['rmi'] = bta.relative_momentum_index(df, length=20, mom=5)['rmi']

df['roc'] = bta.rate_of_change(df, column='close', period=21)['roc']

df['sroc'] = bta.smoothed_rate_of_change(df, roclen=21, emalen=13, smooth=21)['sroc']

wae = bta.waddah_attar_explosion_atr(df)
df['trend_up'] = wae['trend_up']
df['trend_down'] = wae['trend_down']
df['explosion_line'] = wae['explosion_line']
df['dead_zone_line'] = wae['dead_zone_line']

wae = bta.waddah_attar_explosion(df)
df['trend_up'] = wae['trend_up']
df['trend_down'] = wae['trend_down']
df['explosion_line'] = wae['explosion_line']
df['dead_zone_line'] = wae['dead_zone_line']

wt = bta.wave_trend(df, chlen=10, avg=21, smalen=4)
df['wt1'] = wt['wt1']
df['wt2'] = wt['wt2']

df['wto'] = bta.wave_trend_oscillator(df, 'close')['wavetrend']

qqe_mod = bta.qqe_mod(df, 6, 5, 3, 3, 50, 0.35, 6, 5, 1.61, 3)
df['qqe_line'] = qqe_mod['qqe_line']
df['histo2'] = qqe_mod['histo2']
df['qqe_up'] = qqe_mod['qqe_up']
df['qqe_down'] = qqe_mod['qqe_down']

df['rsi'] = bta.relative_strength_index(df, column='close', period=14)['rsi']

df['smi'] = bta.stochastic_momentum_index(df, k_length=9, d_length=3)['smi']

stoch = bta.stochastics_oscillator(df, 'high', 'low', 'close', 14, 3)
df['stoch'] = stoch['stoch']
df['stoch_signal'] = stoch['stoch_signal']
df['stoch_hist'] = stoch['stoch_hist']

stoch_rsi = bta.stochastic_rsi(df, length_rsi=14, length_stoch=14, smooth_k=3, smooth_d=3)
df['stoch_rsi_k'] = stoch_rsi['stoch_rsi_k']
df['stoch_rsi_d'] = stoch_rsi['stoch_rsi_d']

df['tsi'] = bta.true_strength_index(df, 'close', 25, 13)['tsi']

df['uo'] = bta.ultimate_oscillator(df, 'high', 'low', 'close', 7, 14, 28)['uo']

df['williams_r'] = bta.williams_r(df, 'high', 'low', 'close', 14)['williams_r']

# ### TREND.PY ####

alligator_result = bta.alligator_bands(df, 'close', 13, 8, 5, jaw_shift=8, teeth_shift=5, lips_shift=3)
df['jaw'] = alligator_result['jaw']
df['teeth'] = alligator_result['teeth']
df['lips'] = alligator_result['lips']

df['bbtrend'] = bta.bollinger_trend(df, 'close', 20, 50, 2.0)['bbtrend']

result = bta.bollinger_trend_fast_with_ma(df, 'close', 10, 50, 1.0, 2.0, 'SMA', 14)
df['bollinger_trend_fast'] = result['bbtrend']
df['bollinger_trend_fast_ma'] = result['bbtrend_ma']

breakout = bta.breakouts(df, length=20)
df['support_level'] = breakout['support_level']
df['resistance_level'] = breakout['resistance_level']
df['support_breakout'] = breakout['support_breakout']
df['resistance_breakout'] = breakout['resistance_breakout']
df['support_retest'] = breakout['support_retest']
df['potential_support_retest'] = breakout['potential_support_retest']
df['resistance_retest'] = breakout['resistance_retest']
df['potential_resistance_retest'] = breakout['potential_resistance_retest']


df['ema'] = bta.exponential_moving_average(df, "close", 21)

df['hma'] = bta.hull_moving_average(df, 'close', 9)['hma']

df['wma'] = bta.weighted_moving_average(df, 'close', 10)['wma']

df['lsma'] = bta.least_squares_moving_average(df, 'close', 50)['lsma']

pcc_result = bta.percent_price_channel(df, period=20, mult=2)
df['pcc_upper'] = pcc_result['pcc_upper']
df['pcc_rangema'] = pcc_result['pcc_rangema']
df['pcc_lower'] = pcc_result['pcc_lower']

ppc_result = bta.price_channel(df, period=20)
df['ppc_upper'] = ppc_result['ppc_upper']
df['ppc_mid'] = ppc_result['ppc_mid']
df['ppc_lower'] = ppc_result['ppc_lower']
df['percent_p'] = ppc_result['percent_p']

df['rma'] = bta.rolling_moving_average(df, 'close', 14)['rma']

df['sma'] = bta.simple_moving_average(df, 'close', 50)['sma']

ssl_result = bta.ssl_channels(df, length=10, mode='sma')
df['ssl_down'] = ssl_result['ssl_down']
df['ssl_up'] = ssl_result['ssl_up']

ssl_result = bta.ssl_channels_atr(df, column='close', length=14, atr_period=7)
df['ssl_atr_down'] = ssl_result['ssl_atr_down']
df['ssl_atr_up'] = ssl_result['ssl_atr_up']

df['t3_average'] = bta.t3_average(df, length=5)['t3_average']

df['zema'] = bta.zero_exponential_moving_average(df, 'close', 21)['zema']

df['zlema'] = bta.zero_lag_exponential_moving_average(df, 'close', 21)['zlema']

###### UTILITY.PY FILE ###############

df['min_max'] = bta.get_min_max(df['open'], df['open'], 'max')

df['daily_return'] = bta.daily_return(df)

df['cumulative_return'] = bta.cumulative_return(df)

df['daily_log_return'] = bta.daily_log_return(df)

maj_qual, min_qual = bta.exhaustion_candles(df, 2, 1)
df['maj_qual'] = maj_qual
df['min_qual'] = min_qual

df['zscore']  = bta.z_score(df['close'])

df['std_dev'] = bta.st_dev(df['close'], period=14)

df['slope'] = bta.regression_slope(df, 20)

### UNTESTABLE FUNCTIONS BELOW ==========================================

# df['df_cleaned'] = bta.drop_na(df)

# atr_sl_tp_df = bta.calculate_atr_stop_loss_take_profit(df, signal_column='signal')
# df['takeprofit'] = atr_sl_tp_df['takeprofit']
# df['stoploss'] = atr_sl_tp_df['stoploss']
# df['buyprice'] = atr_sl_tp_df['buyprice']

### UNTESTABLE FUNCTIONS BELOW
# stop_loss_take_profit = bta.calculate_stop_loss_take_profit(df, 
#                                                             signal_column='trade_signal',
#                                                             long_trade_signal='long_trade', 
#                                                             short_trade_signal='short_trade', 
#                                                             no_trade_signal='no_trade', 
#                                                             lookback_period=5, 
#                                                             long_reward_ratio=2, 
#                                                             short_reward_ratio=1.5, 
#                                                             buffer=0.5)
# df['stop_loss'] = stop_loss_take_profit['stop_loss']
# df['entry_price'] = stop_loss_take_profit['entry_price']
# df['take_profit'] = stop_loss_take_profit['take_profit']
# df['exit_reason'] = stop_loss_take_profit['exit_reason']

### UNTESTABLE FUNCTIONS BELOW
# df['first_crossed_below_second'] = bta.first_crossed_below_second(series1, series2)

### UNTESTABLE FUNCTIONS BELOW
# df['first_crossed_above_second'] = bta.first_crossed_above_second(series1, series2)

### UNTESTABLE FUNCTIONS BELOW
# leledc_major_minor = bta.populate_leledc_major_minor(df, maj_qual, min_qual, maj_len, min_len)
# df['leledc_major'] = leledc_major_minor['leledc_major']
# df['leledc_minor'] = leledc_major_minor['leledc_minor']

###### VOLATILITY.PY FILE ###############

df['atr'] = bta.average_true_range(df, 14)['atr']

bb_result = bta.bollinger_bands(df, 'close', 20, 2, 0)
df['bb_upper'] = bb_result['bb_upper']
df['bb_middle'] = bb_result['bb_middle']
df['bb_lower'] = bb_result['bb_lower']

df['true_range'] = bta.true_range(df)['true_range']

# ##### VOLUME.PY FILE ###############

df['adi'] = bta.accumulation_distribution_index(df, fillna=True)['adi']

df['cmf'] = bta.chaikin_money_flow(df, window=20, fillna=True)['cmf']

eom_df = bta.ease_of_movement(df, eom_length=14, seom_length=14, fillna=True)
df['eom'] = eom_df['eom']
df['seom'] = eom_df['seom']

df['fi'] = bta.force_index(df, window=13, fillna=True)['fi']

df['mfi'] = bta.money_flow_index(df, window=14, fillna=True)['mfi']

nvi_df = bta.negative_volume_index(df, signal_type='EMA', signal_length=255, fillna=True)
df['nvi'] = nvi_df['nvi']
df['nvi_signal'] = nvi_df['nvi_signal']

obv_df = bta.on_balance_volume(df, signal_type='SMA', signal_length=21, show_signal=True, fillna=True)
df['obv'] = obv_df['obv']
df['signal'] = obv_df['signal']

df['obv_oscillator'] = bta.on_balance_volume_oscillator(df, length=20, fillna=True)['obv_oscillator']

pvi_df = bta.positive_volume_index(df, signal_type='EMA', signal_length=255, fillna=True)
df['pvi'] = pvi_df['pvi']
df['pvi_signal'] = pvi_df['pvi_signal']

pvt_df = bta.price_volume_trend(df, fillna=True, signal_type='EMA', signal_length=21, dropnans=True)
df['pvt'] = pvt_df['price_volume_trend']
df['pvt_signal'] = pvt_df['signal']

df['vwap'] = bta.volume_weighted_average_price(df, window=14, fillna=True)['volume_weighted_average_price']


# PRINT THE DATAFRAME WITH ALL VALUES

print(df.tail(40))
print(dir(bta))

# BUGGY INDICATORS..?
# # ## TEST FOR LinearDecay
# df['linear_decay'] =  bta.LinearDecay(start, end, start_time, end_time, trade_time)

# # ## TEST FOR LinearGrowth
# df['linear_growth'] = df.apply(lambda row: bta.LinearGrowth(50, 100, 0, 100, row['time']), axis=1)

# # ## TEST FOR PopulateLeledcMajorMinor
# leledc_df = bta.PopulateLeledcMajorMinor(df, maj_qual, min_qual, maj_len, min_len)
# df['leledc_major'] = leledc_df['leledc_major']
# df['leledc_minor'] = leledc_df['leledc_minor']

# dir(bta)
    ----- End of testallatonce.py -----

    bamboo_ta/
        performance.py

        ----- Start of performance.py -----

# -*- coding: utf-8 -*-
import numpy as np
import pandas as pd
from .bamboo_ta import *

        ----- End of performance.py -----

        statistics.py

        ----- Start of statistics.py -----

# -*- coding: utf-8 -*-
import numpy as np
import pandas as pd
from .bamboo_ta import *

        ----- End of statistics.py -----

        trend.py

        ----- Start of trend.py -----

# -*- coding: utf-8 -*-
from pandas import DataFrame
import math
import numpy as np
import pandas as pd
from .volatility import *
from .utility import *

def alligator_bands(
    df: pd.DataFrame,
    column: str = 'close',
    jaw_period: int = 13,
    teeth_period: int = 8,
    lips_period: int = 5,
    jaw_shift: int = 8,
    teeth_shift: int = 5,
    lips_shift: int = 3
) -> pd.DataFrame:
    """
    Bill Williams Alligator Indicator

    The Alligator Indicator is used to identify trends and their direction in the market.
    It consists of three smoothed moving averages known as the Jaw, Teeth, and Lips.

    Parameters:
    - df (pandas.DataFrame): DataFrame containing the data.
    - column (str): The column name on which the Alligator is to be applied. Default is 'close'.
    - jaw_period (int): Period for the Alligator's Jaw (blue line). Default is 13.
    - teeth_period (int): Period for the Alligator's Teeth (red line). Default is 8.
    - lips_period (int): Period for the Alligator's Lips (green line). Default is 5.
    - jaw_shift (int): Number of periods to shift the Jaw line into the future. Default is 8.
    - teeth_shift (int): Number of periods to shift the Teeth line into the future. Default is 5.
    - lips_shift (int): Number of periods to shift the Lips line into the future. Default is 3.

    Call with:
        alligator_result = bta.alligator_bands(df, 'close', 13, 8, 5, jaw_shift=8, teeth_shift=5, lips_shift=3)
        df['jaw'] = alligator_result['jaw']
        df['teeth'] = alligator_result['teeth']
        df['lips'] = alligator_result['lips']

    Returns:
    - pd.DataFrame: DataFrame with 'jaw', 'teeth', and 'lips' columns.
    """
    df_copy = df.copy()

    df_copy['jaw'] = df_copy[column].rolling(window=jaw_period).mean().shift(jaw_shift)
    df_copy['teeth'] = df_copy[column].rolling(window=teeth_period).mean().shift(teeth_shift)
    df_copy['lips'] = df_copy[column].rolling(window=lips_period).mean().shift(lips_shift)

    df_copy['jaw'] = df_copy['jaw']
    df_copy['teeth'] = df_copy['teeth']
    df_copy['lips'] = df_copy['lips']

    return df_copy[['jaw', 'teeth', 'lips']]


def bollinger_trend(
    df: pd.DataFrame, 
    column: str = 'close', 
    short_length: int = 20, 
    long_length: int = 50, 
    std_dev: float = 2.0
) -> pd.DataFrame:
    """
    Bollinger Trend Indicator

    The Bollinger Trend Indicator calculates the trend based on the difference 
    between short and long Bollinger Bands.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the column specified.
    - column (str): The column on which BBTrend is to be calculated. Default is 'close'.
    - short_length (int): The period for the short Bollinger Bands. Default is 20.
    - long_length (int): The period for the long Bollinger Bands. Default is 50.
    - std_dev (float): The standard deviation multiplier for the Bollinger Bands. Default is 2.0.

    Call with:
        df['bbtrend'] = bta.bollinger_trend(df, 'close', 20, 50, 2.0)['bbtrend']

    Returns:
    - pd.DataFrame: DataFrame with 'bbtrend' column.
    """
    df_copy = df.copy()

    # Calculate short Bollinger Bands
    short_bb = bollinger_bands(df, column=column, period=short_length, std_dev=std_dev)
    short_middle = short_bb['bb_middle']
    short_upper = short_bb['bb_upper']
    short_lower = short_bb['bb_lower']

    # Calculate long Bollinger Bands
    long_bb = bollinger_bands(df, column=column, period=long_length, std_dev=std_dev)
    long_middle = long_bb['bb_middle']
    long_upper = long_bb['bb_upper']
    long_lower = long_bb['bb_lower']

    # Calculate BBTrend
    bbtrend = (np.abs(short_lower - long_lower) - np.abs(short_upper - long_upper)) / short_middle * 100

    # Fill NaN values that may arise from the calculation
    bbtrend = bbtrend.fillna(0)

    df_copy['bbtrend'] = bbtrend

    return df_copy[['bbtrend']]


def bollinger_trend_fast_with_ma(
    df: pd.DataFrame,
    column: str = 'close',
    short_length: int = 10,
    long_length: int = 50,
    short_stddev: float = 1.0,
    long_stddev: float = 2.0,
    ma_type: str = 'SMA',
    ma_length: int = 14
) -> pd.DataFrame:
    """
    Bollinger Trend Indicator with Selectable Moving Average

    This function calculates a more responsive Bollinger Trend (BBTrend) and applies a 
    selected moving average to the BBTrend.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the column specified.
    - column (str): The column on which BBTrend is to be calculated. Default is 'close'.
    - short_length (int): The period for the short Bollinger Bands. Default is 10.
    - long_length (int): The period for the long Bollinger Bands. Default is 50.
    - short_stddev (float): The standard deviation multiplier for the short Bollinger Bands. Default is 1.0.
    - long_stddev (float): The standard deviation multiplier for the long Bollinger Bands. Default is 2.0.
    - ma_type (str): The type of moving average to use ('SMA', 'EMA', 'LSMA', 'HMA', 'WMA'). Default is 'SMA'.
    - ma_length (int): The period for the moving average. Default is 14.

    Call with:
        result = bta.bollinger_trend_fast_with_ma(df, 'close', 10, 50, 1.0, 2.0, 'SMA', 14)
        df['bollinger_trend_fast'] = result['bbtrend']
        df['bollinger_trend_fast_ma'] = result['bbtrend_ma']

    Returns:
    - pd.DataFrame: DataFrame with 'bbtrend' and 'bbtrend_ma' columns.
    """
    df_copy = df.copy()

    # Calculate short Bollinger Bands
    short_bb = bollinger_bands(df, column=column, period=short_length, std_dev=short_stddev)
    short_middle = short_bb['bb_middle']
    short_upper = short_bb['bb_upper']
    short_lower = short_bb['bb_lower']

    # Calculate long Bollinger Bands
    long_bb = bollinger_bands(df, column=column, period=long_length, std_dev=long_stddev)
    long_middle = long_bb['bb_middle']
    long_upper = long_bb['bb_upper']
    long_lower = long_bb['bb_lower']

    # Calculate BBTrend
    bbtrend = (np.abs(short_lower - long_lower) - np.abs(short_upper - long_upper)) / short_middle * 100
    bbtrend = bbtrend

    # Select and calculate the moving average
    bbtrend_df = df.assign(bbtrend=bbtrend)
    if ma_type == 'SMA':
        ma = simple_moving_average(bbtrend_df, column='bbtrend', period=ma_length)
    elif ma_type == 'EMA':
        ma = exponential_moving_average(bbtrend_df, column='bbtrend', period=ma_length)
    elif ma_type == 'LSMA':
        ma = least_squares_moving_average(bbtrend_df, column='bbtrend', period=ma_length)
    elif ma_type == 'HMA':
        ma = hull_moving_average(bbtrend_df, column='bbtrend', period=ma_length)
    elif ma_type == 'WMA':
        ma = weighted_moving_average(bbtrend_df, column='bbtrend', period=ma_length)
    else:
        raise ValueError("Unsupported moving average type")

    # Returning as DataFrame
    result = df.copy()
    result['bbtrend'] = bbtrend
    result['bbtrend_ma'] = ma

    return result[['bbtrend', 'bbtrend_ma']]


def breakouts(df: pd.DataFrame, length: int = 20) -> pd.DataFrame:
    """
    S/R Breakouts and Retests

    Makes it easy to work with Support and Resistance.
    Find Retests, Breakouts, and the next levels.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'high', 'low', and 'close' columns.
    - length (int): Lookback period.

    Call with:
        breakout = bta.breakouts(df, length=20)
        df['support_level'] = breakout['support_level']
        df['resistance_level'] = breakout['resistance_level']
        df['support_breakout'] = breakout['support_breakout']
        df['resistance_breakout'] = breakout['resistance_breakout']
        df['support_retest'] = breakout['support_retest']
        df['potential_support_retest'] = breakout['potential_support_retest']
        df['resistance_retest'] = breakout['resistance_retest']
        df['potential_resistance_retest'] = breakout['potential_resistance_retest']

    Returns:
    - pd.DataFrame: DataFrame with event columns populated.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['high', 'low', 'close']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    high = df_copy['high']
    low = df_copy['low']
    close = df_copy['close']

    pl = low.rolling(window=length * 2 + 1).min()
    ph = high.rolling(window=length * 2 + 1).max()

    s_yLoc = low.shift(length + 1).where(low.shift(length + 1) > low.shift(length - 1), low.shift(length - 1))
    r_yLoc = high.shift(length + 1).where(high.shift(length + 1) > high.shift(length - 1), high.shift(length + 1))

    cu = close < s_yLoc.shift(length)
    co = close > r_yLoc.shift(length)

    s1 = (high >= s_yLoc.shift(length)) & (close <= pl.shift(length))
    s2 = (high >= s_yLoc.shift(length)) & (close >= pl.shift(length)) & (close <= s_yLoc.shift(length))
    s3 = (high >= pl.shift(length)) & (high <= s_yLoc.shift(length))
    s4 = (high >= pl.shift(length)) & (high <= s_yLoc.shift(length)) & (close < pl.shift(length))

    r1 = (low <= r_yLoc.shift(length)) & (close >= ph.shift(length))
    r2 = (low <= r_yLoc.shift(length)) & (close <= ph.shift(length)) & (close >= r_yLoc.shift(length))
    r3 = (low <= ph.shift(length)) & (low >= r_yLoc.shift(length))
    r4 = (low <= ph.shift(length)) & (low >= r_yLoc.shift(length)) & (close > ph.shift(length))

    df_copy['support_level'] = pl.diff().where(pl.diff().notna())
    df_copy['resistance_level'] = ph.diff().where(ph.diff().notna())

    df_copy['support_level'] = df_copy['support_level'].combine_first(df_copy['support_level'].shift())
    df_copy['resistance_level'] = df_copy['resistance_level'].combine_first(df_copy['resistance_level'].shift())

    df_copy['support_breakout'] = cu
    df_copy['resistance_breakout'] = co
    df_copy['support_retest'] = (s1 | s2 | s3 | s4).astype(int)
    df_copy['potential_support_retest'] = (s1 | s2 | s3).astype(int)
    df_copy['resistance_retest'] = (r1 | r2 | r3 | r4).astype(int)
    df_copy['potential_resistance_retest'] = (r1 | r2 | r3).astype(int)

    return df_copy[['support_level', 'resistance_level', 'support_breakout', 'resistance_breakout', 'support_retest', 'potential_support_retest', 'resistance_retest', 'potential_resistance_retest']]


def exponential_moving_average(
    df: pd.DataFrame, 
    column: str = 'close', 
    period: int = 21
) -> pd.DataFrame:
    """
    Exponential Moving Average (EMA)

    The Exponential Moving Average gives more weight to recent prices and thus reacts 
    more quickly to price changes than the Simple Moving Average.

    Call with:
        df['ema'] = bta.exponential_moving_average(df, "close", 21)

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the column specified.
    - column (str): The column on which EMA is to be calculated. Default is 'close'.
    - period (int): The period over which EMA is to be calculated. Default is 21.

    Returns:
    - pd.DataFrame: DataFrame with 'ema' column, where first `period-1` values are NaN.
    """
    df_copy = df.copy()
    
    # Calculate Exponential Moving Average
    df_copy['ema'] = df_copy[column].ewm(span=period, adjust=False).mean()
    
    # Set first `period - 1` values to NaN using `.loc[]` to avoid chained assignment warning
    df_copy.loc[:period-1, 'ema'] = pd.NA
    
    return df_copy[['ema']]


def hull_moving_average(
    df: pd.DataFrame, 
    column: str = 'close', 
    period: int = 9
) -> pd.DataFrame:
    """
    Hull Moving Average (HMA)

    The Hull Moving Average (HMA) is an improved moving average that is responsive and 
    has minimal lag. It involves the combination of WMA (Weighted Moving Average) with 
    different periods.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the column specified.
    - column (str): The column on which HMA is to be calculated. Default is 'close'.
    - period (int): The period over which HMA is to be calculated. Default is 9.

    Call with:
        df['hma'] = bta.hull_moving_average(df, 'close', 9)['hma']

    Returns:
    - pd.DataFrame: DataFrame with 'hma' column.
    """
    df_copy = df.copy()

    half_length = math.floor(period / 2)
    sqrt_length = math.floor(math.sqrt(period))

    wma_half = weighted_moving_average(df_copy, column=column, period=half_length)['wma']
    wma_full = weighted_moving_average(df_copy, column=column, period=period)['wma']

    h = 2 * wma_half - wma_full
    h_df = pd.DataFrame(h, columns=[column])
    hma = weighted_moving_average(h_df.assign(close=h), column='close', period=sqrt_length)['wma']

    df_copy['hma'] = hma

    return df_copy[['hma']]


def least_squares_moving_average(
    df: pd.DataFrame, 
    column: str = 'close', 
    period: int = 21
) -> pd.DataFrame:
    """
    Least Squares Moving Average (LSMA)

    LSMA uses linear regression to compute the trend of the data over a specified period. 
    It fits a straight line to the data points using the method of least squares to depict 
    the direction of movement.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the column specified.
    - column (str): The column on which LSMA is to be calculated. Default is 'close'.
    - period (int): The period over which LSMA is to be calculated. Default is 21.

    Call with:
        df['lsma'] = bta.least_squares_moving_average(df, 'close', 50)['lsma']

    Returns:
    - pd.DataFrame: DataFrame with 'lsma' column.
    """
    lsma_values = []

    for i in range(period - 1, len(df)):
        # Extract the most recent N df points
        subset = df.iloc[i + 1 - period:i + 1]

        # Perform linear regression to fit a line
        x = np.arange(len(subset))
        y = subset[column].values
        slope, intercept = np.polyfit(x, y, 1)

        # Calculate the LSMA value using the linear equation
        lsma = intercept + slope * (period - 1)
        lsma_values.append(lsma)

    lsma_series = pd.Series(lsma_values, index=df.index[period - 1:])

    df_copy = df.copy()
    df_copy['lsma'] = lsma_series

    return df_copy[['lsma']]


def percent_price_channel(
    df: pd.DataFrame, 
    period: int = 20, 
    mult: int = 2
) -> pd.DataFrame:
    """
    Percent Change Channel (PCC)

    PCC is like KC unless it uses percentage changes in price to set channel distance.
    https://www.tradingview.com/script/6wwAWXA1-MA-Streak-Change-Channel/

    Parameters:
    - df (pandas.DataFrame): Input DataFrame containing the data.
    - period (int): Period for the ZEMA calculation. Default is 20.
    - mult (int): Multiplier for the range. Default is 2.

    Call with:
        pcc_result = bta.percent_price_channel(df, period=20, mult=2)
        df['pcc_upper'] = pcc_result['pcc_upper']
        df['pcc_rangema'] = pcc_result['pcc_rangema']
        df['pcc_lower'] = pcc_result['pcc_lower']

    Returns:
    - pd.DataFrame: DataFrame with 'pcc_upper', 'pcc_rangema', and 'pcc_lower' columns.
    """
    df_copy = df.copy()

    df_copy['previous_close'] = df_copy['close'].shift()
    df_copy['close_change'] = (
        (df_copy['close'] - df_copy['previous_close']) / df_copy['previous_close'] * 100
    )
    df_copy['high_change'] = (
        (df_copy['high'] - df_copy['close']) / df_copy['close'] * 100
    )
    df_copy['low_change'] = (
        (df_copy['low'] - df_copy['close']) / df_copy['close'] * 100
    )
    df_copy['delta'] = df_copy['high_change'] - df_copy['low_change']

    mid = zero_exponential_moving_average(df_copy, column='close_change', period=period)['zema']
    rangema = zero_exponential_moving_average(df_copy, column='delta', period=period)['zema']

    df_copy['pcc_upper'] = mid + rangema * mult
    df_copy['pcc_rangema'] = rangema
    df_copy['pcc_lower'] = mid - rangema * mult

    return df_copy[['pcc_upper', 'pcc_rangema', 'pcc_lower']]


def price_channel(
    df: pd.DataFrame, 
    period: int = 20
) -> pd.DataFrame:
    """
    Price Channel (PPC)

    The Price Channel % PC indicator calculates the percent change of the price channel.
    It calculates the highest high and lowest low of the trailing number of bars specified 
    by the input period. The price channel calculates the highest high and lowest low of 
    the trailing number of bars specified by the input period.

    When a market moves above the upper band, it is a sign of market strength. Conversely, 
    when a market moves below the lower band, it is a sign of market weakness. A sustained 
    move above or below the channel lines may indicate a significant breakout.

    The `percent_p` column represents the percentage position of the current closing price 
    within the price channel defined by the highest high and lowest low over a specified 
    period. It shows where the current closing price stands relative to the recent highest 
    and lowest prices.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame containing the data.
    - period (int): Period for the highest high and lowest low calculation. Default is 20.

    Call with:
        ppc_result = bta.price_channel(df, period=20)
        df['ppc_upper'] = ppc_result['ppc_upper']
        df['ppc_mid'] = ppc_result['ppc_mid']
        df['ppc_lower'] = ppc_result['ppc_lower']
        df['percent_p'] = ppc_result['percent_p']

    Returns:
    - pd.DataFrame: DataFrame with 'ppc_upper', 'ppc_mid', 'ppc_lower', and 'percent_p' columns.
    """
    df_copy = df.copy()

    df_copy['highest_high'] = df_copy['high'].rolling(window=period, min_periods=1).max()
    df_copy['lowest_low'] = df_copy['low'].rolling(window=period, min_periods=1).min()

    df_copy['ppc_upper'] = df_copy['highest_high']
    df_copy['ppc_lower'] = df_copy['lowest_low']
    df_copy['ppc_mid'] = (df_copy['ppc_upper'] + df_copy['ppc_lower']) / 2

    df_copy['percent_p'] = (
        (df_copy['close'] - df_copy['ppc_lower']) / (df_copy['ppc_upper'] - df_copy['ppc_lower']) * 100
    )

    return df_copy[['ppc_upper', 'ppc_mid', 'ppc_lower', 'percent_p']]


def rolling_moving_average(
    df: pd.DataFrame, 
    column: str = 'close', 
    period: int = 14
) -> pd.DataFrame:
    """
    Rolling Moving Average (RMA) calculation.

    The RMA function calculates the Rolling Moving Average (RMA) of a specified column 
    in a DataFrame over a given period. It uses an exponential moving average (EMA) 
    calculation with a specified smoothing factor (alpha) and returns a DataFrame 
    containing the RMA values. This function allows for flexible moving average 
    calculations based on any column in the input DataFrame.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the specified column.
    - column (str): The column on which RMA is to be calculated.
    - period (int): The period over which RMA is to be calculated.

    Call with:
        df['rma'] = bta.rolling_moving_average(df, 'close', 14)['rma']

    Returns:
    - pd.DataFrame: DataFrame with 'rma' column.
    """
    df_copy = df.copy()
    df_copy['rma'] = df_copy[column].ewm(alpha=1/period, adjust=False).mean()

    return df_copy[['rma']]


def simple_moving_average(
    df: pd.DataFrame, 
    column: str = 'close', 
    period: int = 21
) -> pd.DataFrame:
    """
    Simple Moving Average (SMA)

    The Simple Moving Average is the unweighted mean of the previous 'period' data points.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the column specified.
    - column (str): The column on which SMA is to be calculated. Default is 'close'.
    - period (int): The period over which SMA is to be calculated. Default is 21.

    Call with:
        df['sma'] = bta.simple_moving_average(df, 'close', 50)['sma']

    Returns:
    - pd.DataFrame: DataFrame with 'sma' column.
    """
    df_copy = df.copy()
    df_copy['sma'] = df_copy[column].rolling(window=period).mean()

    return df_copy[['sma']]


def ssl_channels(
    df: pd.DataFrame, 
    length: int = 10, 
    mode: str = 'sma'
) -> pd.DataFrame:
    """
    SSL Channels

    SSL Channels is an indicator based on the concept of using different moving averages 
    to identify trends. This function calculates the SSL Down and SSL Up series.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame containing the data.
    - length (int): Period for the SMA calculation. Default is 10.
    - mode (str): Type of moving average to use. Currently only 'sma' is supported.

    Call with:
        ssl_result = bta.ssl_channels(df, length=10, mode='sma')
        df['ssl_down'] = ssl_result['ssl_down']
        df['ssl_up'] = ssl_result['ssl_up']

    Returns:
    - pd.DataFrame: DataFrame with 'ssl_down' and 'ssl_up' columns.
    """
    df_copy = df.copy()

    if mode != 'sma':
        raise ValueError(f"Mode '{mode}' not supported yet")

    df_copy['sma_high'] = df_copy['high'].rolling(length).mean()
    df_copy['sma_low'] = df_copy['low'].rolling(length).mean()

    df_copy['hlv'] = np.where(
        df_copy['close'] > df_copy['sma_high'], 
        1, 
        np.where(df_copy['close'] < df_copy['sma_low'], -1, np.nan)
    )
    df_copy['hlv'] = df_copy['hlv'].ffill()

    df_copy['ssl_down'] = np.where(df_copy['hlv'] < 0, df_copy['sma_high'], df_copy['sma_low'])
    df_copy['ssl_up'] = np.where(df_copy['hlv'] < 0, df_copy['sma_low'], df_copy['sma_high'])

    return df_copy[['ssl_down', 'ssl_up']]


def ssl_channels_atr(
    df: pd.DataFrame, 
    column: str = 'close', 
    length: int = 21, 
    atr_period: int = 14
) -> pd.DataFrame:
    """
    SSL Channels with ATR

    The ssl_channels_atr function calculates the SSL (Safe and Secure Levels) channels using 
    the Average True Range (ATR) to adjust the Simple Moving Averages (SMA) of the high 
    and low prices over a specified period. It determines the trend direction based on 
    the comparison of a chosen price column with these adjusted SMAs and generates the 
    SSL ATR Down and Up levels accordingly.

    This indicator helps identify potential trend reversals and continuations by providing 
    dynamic support and resistance levels.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame containing the data.
    - length (int): Period for the SMA calculation. Default is 21.
    - atr_period (int): Period for the ATR calculation. Default is 14.
    - column (str): The column to use for the moving average calculations. Default is 'close'.

    Call with:
        ssl_result = bta.ssl_channels_atr(df, column='close', length=14, atr_period=7)
        df['ssl_atr_down'] = ssl_result['ssl_atr_down']
        df['ssl_atr_up'] = ssl_result['ssl_atr_up']

    Returns:
    - pd.DataFrame: DataFrame with 'ssl_atr_down' and 'ssl_atr_up' columns.
    """
    def calculate_atr(df, period):
        high_low = df['high'] - df['low']
        high_close = np.abs(df['high'] - df['close'].shift())
        low_close = np.abs(df['low'] - df['close'].shift())
        tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
        atr = tr.rolling(window=period, min_periods=1).mean()
        return atr

    df_copy = df.copy()

    df_copy['atr'] = calculate_atr(df_copy, atr_period)
    df_copy['sma_high'] = df_copy['high'].rolling(length).mean() + df_copy['atr']
    df_copy['sma_low'] = df_copy['low'].rolling(length).mean() - df_copy['atr']

    df_copy['hlv'] = np.where(
        df_copy[column] > df_copy['sma_high'], 
        1, 
        np.where(df_copy[column] < df_copy['sma_low'], -1, np.nan)
    )
    df_copy['hlv'] = df_copy['hlv'].ffill()

    df_copy['ssl_atr_down'] = np.where(df_copy['hlv'] < 0, df_copy['sma_high'], df_copy['sma_low'])
    df_copy['ssl_atr_up'] = np.where(df_copy['hlv'] < 0, df_copy['sma_low'], df_copy['sma_high'])

    return df_copy[['ssl_atr_down', 'ssl_atr_up']]


def t3_average(
    df: pd.DataFrame, 
    length: int = 5
) -> pd.DataFrame:
    """
    T3 Average
    
    The T3 average is a smoothed moving average designed to reduce lag while maintaining 
    responsiveness to price changes. This implementation uses multiple exponential moving 
    averages (EMA) to achieve its smoothing effect.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame containing the data.
    - length (int): Period for the EMA calculation. Default is 5.

    Call with:
        df['t3_average'] = bta.t3_average(df, length=5)['t3_average']

    Returns:
    - pd.DataFrame: DataFrame with 't3_average' column.
    """
    df_copy = df.copy()

    # Calculating multiple EMA stages
    df_copy['xe1'] = exponential_moving_average(df_copy, column='close', period=length)['ema']
    df_copy['xe2'] = exponential_moving_average(df_copy, column='xe1', period=length)['ema']
    df_copy['xe3'] = exponential_moving_average(df_copy, column='xe2', period=length)['ema']
    df_copy['xe4'] = exponential_moving_average(df_copy, column='xe3', period=length)['ema']
    df_copy['xe5'] = exponential_moving_average(df_copy, column='xe4', period=length)['ema']
    df_copy['xe6'] = exponential_moving_average(df_copy, column='xe5', period=length)['ema']

    # Constants for T3 calculation
    b = 0.7
    c1 = -b * b * b
    c2 = 3 * b * b + 3 * b * b * b
    c3 = -6 * b * b - 3 * b - 3 * b * b * b
    c4 = 1 + 3 * b + b * b * b + 3 * b * b

    # T3 average calculation
    df_copy['t3_average'] = (
        c1 * df_copy['xe6'] +
        c2 * df_copy['xe5'] +
        c3 * df_copy['xe4'] +
        c4 * df_copy['xe3']
    )

    return df_copy[['t3_average']]


def weighted_moving_average(
    df: pd.DataFrame, 
    column: str = 'close', 
    period: int = 10
) -> pd.DataFrame:
    """
    Weighted Moving Average (WMA)

    The Weighted Moving Average (WMA) gives more weight to recent data points and 
    less weight to older data points.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame.
    - column (str): The column to calculate the WMA on.
    - period (int): The period for the WMA calculation.

    Call with:
        df['wma'] = bta.weighted_moving_average(df, 'close', 10)['wma']

    Returns:
    - pd.DataFrame: DataFrame with 'wma' column.
    """
    df_copy = df.copy()
    weights = pd.Series(range(1, period + 1))
    df_copy['wma'] = df_copy[column].rolling(period).apply(
        lambda prices: (prices * weights).sum() / weights.sum(), raw=True
    )

    return df_copy[['wma']]


def zero_exponential_moving_average(
    df: pd.DataFrame, 
    column: str = 'close', 
    period: int = 21
) -> pd.DataFrame:
    """
    Zero Exponential Moving Average (ZEMA)

    The Zero Exponential Moving Average (ZEMA) is an improved version of the Exponential 
    Moving Average (EMA) that reduces lag by incorporating a zero-lag component.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the column specified.
    - column (str): The column on which ZEMA is to be calculated. Default is 'close'.
    - period (int): The period over which ZEMA is to be calculated. Default is 21.

    Call with:
        df['zema'] = bta.zero_exponential_moving_average(df, 'close', 21)['zema']

    Returns:
    - pd.DataFrame: DataFrame with 'zema' column.
    """
    df_copy = df.copy()

    # Calculate EMA components
    ema1 = df_copy[column].ewm(span=period, adjust=False).mean()
    ema2 = ema1.ewm(span=period, adjust=False).mean()

    # ZEMA calculation
    df_copy['zema'] = 2 * ema1 - ema2

    return df_copy[['zema']]


def zero_lag_exponential_moving_average(
    df: pd.DataFrame, 
    column: str = 'close', 
    period: int = 21
) -> pd.DataFrame:
    """
    Zero Lag Exponential Moving Average (ZLEMA)

    ZLEMA is an Exponential Moving Average (EMA) that adjusts for lag, making it more responsive 
    to recent price changes. It uses lagged data differences to adjust the EMA calculation, 
    thereby reducing the inherent lag of EMA.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the column specified.
    - column (str): The column on which ZLEMA is to be calculated. Default is 'close'.
    - period (int): The period over which ZLEMA is to be calculated. Default is 21.

    Call with:
        df['zlema'] = bta.zero_lag_exponential_moving_average(df, 'close', 21)['zlema']

    Returns:
    - pd.DataFrame: DataFrame with 'zlema' column.
    """
    lag = int((period - 1) / 2)

    # Calculating the adjusted data series
    ema_data = df[column] + (df[column] - df[column].shift(lag))

    # Computing the EMA of the adjusted data series
    zlema = ema_data.ewm(span=period, adjust=False).mean()

    df_copy = df.copy()
    df_copy['zlema'] = zlema

    return df_copy[['zlema']]

        ----- End of trend.py -----

        volume.py

        ----- Start of volume.py -----

# -*- coding: utf-8 -*-
import numpy as np
import pandas as pd
from .bamboo_ta import *
from .trend import *


def accumulation_distribution_index(
    df: pd.DataFrame, 
    fillna: bool = False
) -> pd.DataFrame:
    """
    Accumulation/Distribution Index (ADI)

    The ADI acts as a leading indicator of price movements. It is calculated using the 
    high, low, close, and volume data.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'high', 'low', 'close', and 'volume' columns.
    - fillna (bool): If True, fill NaN values.

    Call with:
        df['adi'] = bta.accumulation_distribution_index(df, fillna=True)['adi']

    Returns:
    - pd.DataFrame: DataFrame with 'adi' column.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['high', 'low', 'close', 'volume']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # Calculate the ADI values
    clv = ((df_copy['close'] - df_copy['low']) - (df_copy['high'] - df_copy['close'])) / (
        df_copy['high'] - df_copy['low']
    )
    clv = clv.fillna(0.0)  # Handling division by zero
    adi = clv * df_copy['volume']
    adi = adi.cumsum()

    if fillna:
        adi = adi.fillna(0)

    df_copy['adi'] = adi

    return df_copy[['adi']]


def chaikin_money_flow(
    df: pd.DataFrame, 
    window: int = 20, 
    fillna: bool = False
) -> pd.DataFrame:
    """
    Chaikin Money Flow (CMF)

    The Chaikin Money Flow measures the amount of Money Flow Volume over a specific period.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'high', 'low', 'close', and 'volume' columns.
    - window (int): Number of periods for the calculation. Default is 20.
    - fillna (bool): If True, fill NaN values with 0.

    Call with:
        df['cmf'] = bta.chaikin_money_flow(df, window=20, fillna=True)['cmf']

    Returns:
    - pd.DataFrame: DataFrame with 'cmf' column.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['high', 'low', 'close', 'volume']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # Calculate the Money Flow Multiplier (MFV)
    mfv = ((df_copy['close'] - df_copy['low']) - (df_copy['high'] - df_copy['close'])) / (
        df_copy['high'] - df_copy['low']
    )
    mfv = mfv.fillna(0.0)  # Handling division by zero
    mfv *= df_copy['volume']

    # Calculate CMF: sum of MFV over window divided by the sum of volume over the same window
    min_periods = 0 if fillna else window
    cmf = mfv.rolling(window, min_periods=min_periods).sum() / df_copy['volume'].rolling(window, min_periods=min_periods).sum()

    # Fill NaN values if fillna is True
    if fillna:
        cmf = cmf.fillna(0)

    df_copy['cmf'] = cmf

    return df_copy[['cmf']]


def ease_of_movement(
    df: pd.DataFrame, 
    eom_length: int = 14, 
    seom_length: int = 14, 
    fillna: bool = False
) -> pd.DataFrame:
    """
    Ease of Movement (EoM, EMV) and Signal Ease of Movement (SMA of EoM)

    Relates an asset's price change to its volume and is useful for assessing trend strength.
    The SMA of the EoM serves as a signal line for the indicator.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'high', 'low', and 'volume' columns.
    - eom_length (int): Period for the EoM calculation. Default is 14.
    - seom_length (int): Period for the SMA of EoM calculation. Default is 14.
    - fillna (bool): If True, fill NaN values.

    Call with:
        eom_df = bta.ease_of_movement(df, eom_length=14, seom_length=14, fillna=True)
        df['eom'] = eom_df['eom']
        df['seom'] = eom_df['seom']

    Returns:
    - pd.DataFrame: DataFrame with 'eom' and 'seom' columns.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['high', 'low', 'volume']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # Calculate the Ease of Movement (EoM) values
    emv = ((df_copy['high'].diff(1) + df_copy['low'].diff(1)) * (df_copy['high'] - df_copy['low'])) / (
        2 * df_copy['volume']
    )
    emv *= 100000000
    if fillna:
        emv = emv.fillna(0)

    df_copy['eom'] = emv / 100000  # No rounding per your preference

    # Calculate the Signal Ease of Movement (SMA of EoM)
    min_periods = 0 if fillna else seom_length
    sma_emv = df_copy['eom'].rolling(seom_length, min_periods=min_periods).mean()
    if fillna:
        sma_emv = sma_emv.fillna(0)

    df_copy['seom'] = sma_emv

    return df_copy[['eom', 'seom']]


def force_index(df: pd.DataFrame, window: int = 13, fillna: bool = False) -> pd.DataFrame:
    """
    Force Index (FI)

    Illustrates how strong the actual buying or selling pressure is.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'close' and 'volume' columns.
    - window (int): Period for calculating the exponential moving average of the Force Index. Default is 13.
    - fillna (bool): If True, fill NaN values.

    Call with:
        df['fi'] = bta.force_index(df, window=13, fillna=True)['fi']

    Returns:
    - pd.DataFrame: DataFrame with 'fi' column.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['close', 'volume']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # Calculate the Force Index values
    fi = (df_copy['close'] - df_copy['close'].shift(1)) * df_copy['volume']
    fi_ema = fi.ewm(span=window, adjust=False).mean()
    if fillna:
        fi_ema = fi_ema.fillna(0)

    df_copy['fi'] = fi_ema

    return df_copy[['fi']]


def money_flow_index(df: pd.DataFrame, window: int = 14, fillna: bool = False) -> pd.DataFrame:
    """
    Money Flow Index (MFI)

    Uses both price and volume to measure buying and selling pressure.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'high', 'low', 'close', and 'volume' columns.
    - window (int): Period for calculating MFI. Default is 14.
    - fillna (bool): If True, fill NaN values.

    Call with:
        df['mfi'] = bta.money_flow_index(df, window=14, fillna=True)['mfi']

    Returns:
    - pd.DataFrame: DataFrame with 'mfi' column.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['high', 'low', 'close', 'volume']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # Calculate typical price
    typical_price = (df_copy['high'] + df_copy['low'] + df_copy['close']) / 3.0
    up_down = np.where(
        typical_price > typical_price.shift(1),
        1,
        np.where(typical_price < typical_price.shift(1), -1, 0)
    )
    mfr = typical_price * df_copy['volume'] * up_down

    # Calculate positive and negative money flow
    min_periods = 0 if fillna else window
    n_positive_mf = mfr.rolling(window, min_periods=min_periods).apply(
        lambda x: np.sum(np.where(x >= 0.0, x, 0.0)), raw=True
    )
    n_negative_mf = abs(mfr.rolling(window, min_periods=min_periods).apply(
        lambda x: np.sum(np.where(x < 0.0, x, 0.0)), raw=True
    ))

    # Calculate Money Flow Index
    mfi = n_positive_mf / n_negative_mf
    mfi = 100 - (100 / (1 + mfi))
    if fillna:
        mfi = mfi.fillna(50)

    df_copy['mfi'] = mfi

    return df_copy[['mfi']]


def negative_volume_index(df: pd.DataFrame, signal_type: str = 'EMA', signal_length: int = 255, fillna: bool = False) -> pd.DataFrame:
    """
    Negative Volume Index (NVI) with Signal Smoothing

    The Negative Volume Index (NVI) measures price changes on days when trading volume decreases compared to the previous day.
    Informed traders are thought to be more active on low volume days, hence the NVI accumulates price rate of change only on such days.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'close' and 'volume' columns.
    - signal_type (str): Type of signal smoothing ('EMA' or 'SMA'). Default is 'EMA'.
    - signal_length (int): Length for the EMA/SMA calculation. Default is 255.
    - fillna (bool): If True, fill NaN values.

    Call with:
        nvi_df = bta.negative_volume_index(df, signal_type='EMA', signal_length=255, fillna=True)
        df['nvi'] = nvi_df['nvi']
        df['nvi_signal'] = nvi_df['nvi_signal']

    Returns:
    - pd.DataFrame: DataFrame with 'nvi' and 'nvi_signal' columns.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['close', 'volume']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # Calculate Rate of Change (ROC)
    df_copy['roc'] = df_copy['close'].pct_change() * 100

    # Initialize the NVI starting from the first valid value
    df_copy['nvi'] = 1000  # Starting point for NVI, common practice

    # Calculate NVI values only when volume decreases
    for i in range(1, len(df_copy)):
        if df_copy['volume'].iloc[i] < df_copy['volume'].iloc[i - 1]:
            df_copy.loc[df_copy.index[i], 'nvi'] = df_copy['nvi'].iloc[i - 1] + df_copy['roc'].iloc[i]
        else:
            df_copy.loc[df_copy.index[i], 'nvi'] = df_copy['nvi'].iloc[i - 1]

    # Calculate NVI Signal
    if signal_type == 'EMA':
        df_copy['nvi_signal'] = df_copy['nvi'].ewm(span=signal_length, adjust=False).mean()
    elif signal_type == 'SMA':
        df_copy['nvi_signal'] = df_copy['nvi'].rolling(window=signal_length, min_periods=1).mean()
    else:
        raise ValueError(f"Invalid signal_type: {signal_type}. Use 'EMA' or 'SMA'.")

    if fillna:
        df_copy['nvi'] = df_copy['nvi'].fillna(0)
        df_copy['nvi_signal'] = df_copy['nvi_signal'].fillna(0)

    return df_copy[['nvi', 'nvi_signal']]


def on_balance_volume(df: pd.DataFrame, signal_type: str = 'SMA', signal_length: int = 21, 
                      show_signal: bool = True, fillna: bool = False) -> pd.DataFrame:
    """
    On Balance Volume (OBV) with Signal Smoothing

    The On Balance Volume (OBV) indicator measures buying and selling pressure by accumulating volume based on price movements.
    When the close price is higher than the previous close, the volume is added to the OBV; when lower, it's subtracted.
    Rising OBV indicates buying pressure, and falling OBV suggests selling pressure.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'close' and 'volume' columns.
    - signal_type (str): Type of signal smoothing ('EMA' or 'SMA'). Default is 'SMA'.
    - signal_length (int): Length for the signal smoothing. Default is 21.
    - show_signal (bool): If True, calculate and return the signal line. Default is True.
    - fillna (bool): If True, fill nan values with 0. Default is False.

    Call with:
        obv_df = bta.on_balance_volume(df, signal_type='SMA', signal_length=21, show_signal=True, fillna=True)
        df['obv'] = obv_df['obv']
        df['signal'] = obv_df['signal']

    Returns:
    - pd.DataFrame: DataFrame with 'obv' and 'signal' columns.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['close', 'volume']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # Calculate OBV
    df_copy['change'] = df_copy['close'].diff()
    df_copy['obv'] = np.where(df_copy['change'] > 0, df_copy['volume'], 
                              np.where(df_copy['change'] < 0, -df_copy['volume'], 0))
    df_copy['obv'] = df_copy['obv'].cumsum()

    # Calculate Signal if requested
    if show_signal:
        if signal_type == 'EMA':
            df_copy['signal'] = df_copy['obv'].ewm(span=signal_length, adjust=False).mean()
        elif signal_type == 'SMA':
            df_copy['signal'] = df_copy['obv'].rolling(window=signal_length, min_periods=1).mean()
        else:
            raise ValueError(f"Invalid signal_type: {signal_type}. Use 'EMA' or 'SMA'.")
    else:
        df_copy['signal'] = np.nan

    # Fill NaN values if requested
    if fillna:
        df_copy['obv'] = df_copy['obv'].fillna(0)
        df_copy['signal'] = df_copy['signal'].fillna(0)

    return df_copy[['obv', 'signal']]


def on_balance_volume_oscillator(df: pd.DataFrame, length: int = 20, fillna: bool = False) -> pd.DataFrame:
    """
    On Balance Volume (OBV) Oscillator

    The On Balance Volume (OBV) Oscillator measures the difference between the OBV and its Exponential Moving Average (EMA). 
    It helps in identifying trends and confirming price movements. An increasing OBV oscillator indicates buying pressure, while a decreasing one indicates selling pressure.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'close' and 'volume' columns.
    - length (int): Length for the EMA calculation. Default is 20.
    - fillna (bool): If True, fill nan values with 0.

    Call with:
        df['obv_oscillator'] = bta.on_balance_volume_oscillator(df, length=20, fillna=True)['obv_oscillator']

    Returns:
    - pd.DataFrame: DataFrame with 'obv_oscillator' column.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['close', 'volume']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # Calculate OBV
    df_copy['change'] = df_copy['close'].diff()
    df_copy['obv'] = np.where(df_copy['change'] > 0, df_copy['volume'], 
                              np.where(df_copy['change'] < 0, -df_copy['volume'], 0))
    df_copy['obv'] = df_copy['obv'].cumsum()

    # Calculate OBV Oscillator
    df_copy['ema_obv'] = df_copy['obv'].ewm(span=length, adjust=False).mean()
    df_copy['obv_oscillator'] = df_copy['obv'] - df_copy['ema_obv']

    # Fill NaN values if requested
    if fillna:
        df_copy['obv_oscillator'] = df_copy['obv_oscillator'].fillna(0)

    return df_copy[['obv_oscillator']]


def positive_volume_index(df: pd.DataFrame, signal_type: str = 'EMA', signal_length: int = 255, fillna: bool = False) -> pd.DataFrame:
    """
    Positive Volume Index (PVI) with Signal Smoothing

    The Positive Volume Index (PVI) measures price changes on days when the trading volume increases compared to the previous day. It accumulates the price rate of change on those days, helping to identify trends driven by high-volume activity.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'close' and 'volume' columns.
    - signal_type (str): Type of signal smoothing ('EMA' or 'SMA'). Default is 'EMA'.
    - signal_length (int): Length for the EMA/SMA calculation. Default is 255.
    - fillna (bool): If True, fill nan values.

    Call with:
        pvi_df = bta.positive_volume_index(df, signal_type='EMA', signal_length=255, fillna=True)
        df['pvi'] = pvi_df['pvi']
        df['pvi_signal'] = pvi_df['pvi_signal']

    Returns:
    - pd.DataFrame: DataFrame with 'pvi' and 'pvi_signal' columns.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['close', 'volume']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # Calculate Rate of Change (ROC)
    df_copy['roc'] = df_copy['close'].pct_change() * 100

    # Initialize PVI column with appropriate dtype
    df_copy['pvi'] = 0.0

    # Calculate PVI
    pvi_condition = df_copy['volume'] > df_copy['volume'].shift(1)
    df_copy.loc[pvi_condition, 'pvi'] = df_copy['roc']
    df_copy['pvi'] = df_copy['pvi'].cumsum().shift(1).fillna(0)

    # Calculate PVI Signal
    if signal_type == 'EMA':
        df_copy['pvi_signal'] = df_copy['pvi'].ewm(span=signal_length, adjust=False).mean()
    elif signal_type == 'SMA':
        df_copy['pvi_signal'] = df_copy['pvi'].rolling(window=signal_length, min_periods=1).mean()
    else:
        raise ValueError(f"Invalid signal_type: {signal_type}. Use 'EMA' or 'SMA'.")

    if fillna:
        df_copy['pvi'] = df_copy['pvi'].fillna(0)
        df_copy['pvi_signal'] = df_copy['pvi_signal'].fillna(0)

    return df_copy[['pvi', 'pvi_signal']]


def price_volume_trend(df: pd.DataFrame, fillna: bool = False, smoothing_factor: int = None, signal_type: str = 'SMA', signal_length: int = 21, dropnans: bool = False) -> pd.DataFrame:
    """
    Price Volume Trend (PVT)

    Based on cumulative volume that adds or subtracts a multiple of the percentage change in share price trend. 
    PVT = [((CurrentClose - PreviousClose) / PreviousClose) x Volume] + PreviousPVT

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'close' and 'volume' columns.
    - fillna (bool): If True, fill nan values.
    - smoothing_factor (int, optional): Will smooth PVT implementation with SMA.
    - signal_type (str): Type of signal smoothing ('SMA' or 'EMA').
    - signal_length (int): Length of the signal smoothing.
    - dropnans (bool): Drop NaN values after indicator calculated.

    Call with:
        pvt_df = bta.price_volume_trend(df, fillna=True, signal_type='EMA', signal_length=21, dropnans=True)
        df['pvt'] = pvt_df['price_volume_trend']
        df['pvt_signal'] = pvt_df['signal']

    Returns:
    - pd.DataFrame: DataFrame with 'price_volume_trend' and 'signal' columns.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['close', 'volume']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # Initialize PVT column
    df_copy['price_volume_trend'] = 0.0

    # Calculate PVT iteratively
    for i in range(1, len(df_copy)):
        prev_pvt = df_copy.at[i-1, 'price_volume_trend']
        price_change = (df_copy.at[i, 'close'] - df_copy.at[i-1, 'close']) / df_copy.at[i-1, 'close']
        df_copy.at[i, 'price_volume_trend'] = price_change * df_copy.at[i, 'volume'] + prev_pvt

    # Optional smoothing
    if smoothing_factor:
        min_periods = 0 if fillna else smoothing_factor
        df_copy['price_volume_trend'] = df_copy['price_volume_trend'].rolling(smoothing_factor, min_periods=min_periods).mean()

    if dropnans:
        df_copy['price_volume_trend'] = df_copy['price_volume_trend'].dropna()

    if fillna:
        df_copy['price_volume_trend'] = df_copy['price_volume_trend'].fillna(0)

    # Calculate signal based on the specified type
    if signal_type == 'SMA':
        df_copy['signal'] = df_copy['price_volume_trend'].rolling(window=signal_length, min_periods=1 if fillna else signal_length).mean()
    elif signal_type == 'EMA':
        df_copy['signal'] = df_copy['price_volume_trend'].ewm(span=signal_length, adjust=False, min_periods=1 if fillna else signal_length).mean()
    else:
        raise ValueError("signal_type must be either 'SMA' or 'EMA'")

    if dropnans:
        df_copy['signal'] = df_copy['signal'].dropna()

    if fillna:
        df_copy['signal'] = df_copy['signal'].fillna(0)

    return df_copy[['price_volume_trend', 'signal']]


def volume_weighted_average_price(df: pd.DataFrame, window: int = 14, fillna: bool = False) -> pd.DataFrame:
    """
    Volume Weighted Average Price (VWAP)
    Equals the dollar value of all trading periods divided by the total trading volume for the current day.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'high', 'low', 'close', and 'volume' columns.
    - window (int): n period for rolling calculation.
    - fillna (bool): If True, fill nan values.

    Call with:
        df['vwap'] = bta.volume_weighted_average_price(df, window=14, fillna=True)['volume_weighted_average_price']

    Returns:
    - pd.DataFrame: DataFrame with 'volume_weighted_average_price' column.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['high', 'low', 'close', 'volume']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # Calculate typical price
    typical_price = (df_copy['high'] + df_copy['low'] + df_copy['close']) / 3.0
    typical_price_volume = typical_price * df_copy['volume']

    # Calculate VWAP over the rolling window
    min_periods = 0 if fillna else window
    total_pv = typical_price_volume.rolling(window, min_periods=min_periods).sum()
    total_volume = df_copy['volume'].rolling(window, min_periods=min_periods).sum()

    # VWAP calculation
    vwap = total_pv / total_volume
    if fillna:
        vwap = vwap.fillna(0)

    # Add the VWAP to the DataFrame
    df_copy['volume_weighted_average_price'] = vwap

    return df_copy[['volume_weighted_average_price']]


        ----- End of volume.py -----

        cycles.py

        ----- Start of cycles.py -----

# -*- coding: utf-8 -*-
import numpy as np
import pandas as pd
from .bamboo_ta import *

        ----- End of cycles.py -----

        bamboo_ta.py

        ----- Start of bamboo_ta.py -----

# bamboo_ta.py
# -*- coding: utf-8 -*-
# Import the individual bamboo ta libraries
from bamboo_ta.candles import *
from bamboo_ta.cycles import *
from bamboo_ta.momentum import *
from bamboo_ta.performance import *
from bamboo_ta.statistics import *
from bamboo_ta.trend import *
from bamboo_ta.utility import *
from bamboo_ta.volatility import *
from bamboo_ta.volume import *
        ----- End of bamboo_ta.py -----

        candles.py

        ----- Start of candles.py -----

# -*- coding: utf-8 -*-
import numpy as np
import pandas as pd
from .bamboo_ta import *
from .trend import *
from .utility import *
from.momentum import *


def exhaustion_bars(df, maj_qual=6, maj_len=30, min_qual=5, min_len=5, core_length=4):
    """
    Leledc Exhaustion Bars

    Infamous S/R Reversal Indicator

    Leledc exhaustion bars are a specific type of price action pattern used in 
    technical analysis to identify potential reversals in the market trend. 
    These bars are characterized by a sharp move in price with an increase in 
    volume, often indicating that the current trend is losing momentum and may 
    reverse direction soon. Traders use them to pinpoint the end of a trend 
    and the beginning of a new one, thereby making more informed trading decisions.

    For more information, see: 
    https://www.abundancetradinggroup.com/leledc-exhaustion-bar-mt4-indicator/
    
    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'open', 
      'high', 'low', and 'close' columns.
    - maj_qual (int): Major quality parameter. Default is 6.
    - maj_len (int): Major length parameter. Default is 30.
    - min_qual (int): Minor quality parameter. Default is 5.
    - min_len (int): Minor length parameter. Default is 5.
    - core_length (int): Core length parameter. Default is 4.

    Call with:
        exhaustion = bta.exhaustion_bars(df)
        df['leledc_major'] = exhaustion['leledc_major']
        df['leledc_minor'] = exhaustion['leledc_minor']

    Returns:
    - pd.DataFrame: DataFrame with 'leledc_major' and 'leledc_minor' columns.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['open', 'high', 'low', 'close']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    bindex_maj, sindex_maj, trend_maj = 0, 0, 0
    bindex_min, sindex_min = 0, 0

    for i in range(len(df_copy)):
        close = df_copy['close'][i]

        if i < 1 or i - core_length < 0:
            df_copy.loc[i, 'leledc_major'] = np.nan
            df_copy.loc[i, 'leledc_minor'] = 0
            continue

        bindex_maj = np.nan_to_num(bindex_maj)
        sindex_maj = np.nan_to_num(sindex_maj)
        bindex_min = np.nan_to_num(bindex_min)
        sindex_min = np.nan_to_num(sindex_min)

        if close > df_copy['close'][i - core_length]:
            bindex_maj += 1
            bindex_min += 1
        elif close < df_copy['close'][i - core_length]:
            sindex_maj += 1
            sindex_min += 1

        update_major = False
        if (
            bindex_maj > maj_qual and 
            close < df_copy['open'][i] and 
            df_copy['high'][i] >= df_copy['high'][i - maj_len:i].max()
        ):
            bindex_maj = 0
            trend_maj = 1
            update_major = True
        elif (
            sindex_maj > maj_qual and 
            close > df_copy['open'][i] and 
            df_copy['low'][i] <= df_copy['low'][i - maj_len:i].min()
        ):
            sindex_maj = 0
            trend_maj = -1
            update_major = True

        if update_major:
            df_copy.loc[i, 'leledc_major'] = trend_maj
        else:
            df_copy.loc[i, 'leledc_major'] = np.nan if trend_maj == 0 else trend_maj

        if (
            bindex_min > min_qual and 
            close < df_copy['open'][i] and 
            df_copy['high'][i] >= df_copy['high'][i - min_len:i].max()
        ):
            bindex_min = 0
            df_copy.loc[i, 'leledc_minor'] = -1
        elif (
            sindex_min > min_qual and 
            close > df_copy['open'][i] and 
            df_copy['low'][i] <= df_copy['low'][i - min_len:i].min()
        ):
            sindex_min = 0
            df_copy.loc[i, 'leledc_minor'] = 1
        else:
            df_copy.loc[i, 'leledc_minor'] = 0

    return df_copy[['leledc_major', 'leledc_minor']]


def dynamic_exhaustion_bars(df, window=500):
    """
    Dynamic Leledc Exhaustion Bars
    The lookback length and exhaustion bars adjust dynamically to the market conditions.

    This indicator dynamically adjusts the lookback length and the exhaustion 
    bars based on the market's behavior, helping to identify potential reversals 
    and trend strength.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the 'close' column.
    - window (int): Lookback window for z-score calculation. Default is 500.

    Call with:
        dynamic_exhaustion = bta.dynamic_exhaustion_bars(df)
        df['dynamic_leledc_major'] = dynamic_exhaustion['leledc_major']
        df['dynamic_leledc_minor'] = dynamic_exhaustion['leledc_minor']

    Returns:
    - pd.DataFrame: DataFrame with 'leledc_major' and 'leledc_minor' columns.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['close']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    df_copy['close_pct_change'] = df_copy['close'].pct_change()
    df_copy['pct_change_zscore'] = z_score(df_copy['close_pct_change'], window)
    df_copy['pct_change_zscore_smoothed'] = (
        df_copy['pct_change_zscore']
        .rolling(window=3)
        .mean()
    )
    df_copy['pct_change_zscore_smoothed'] = df_copy['pct_change_zscore_smoothed'].fillna(1.0)

    zscore = df_copy['pct_change_zscore_smoothed'].to_numpy()
    zscore_multi = np.maximum(np.minimum(5.0 - zscore * 2, 5.0), 1.5)

    maj_qual, min_qual = exhaustion_candles(df_copy, window, zscore_multi)
    
    df_copy['maj_qual'] = maj_qual
    df_copy['min_qual'] = min_qual

    maj_len, min_len = exhaustion_lengths(df_copy)
    
    df_copy['maj_len'] = maj_len
    df_copy['min_len'] = min_len

    df_copy = populate_leledc_major_minor(df_copy, maj_qual, min_qual, maj_len, min_len)

    return df_copy[['leledc_major', 'leledc_minor']]


def heiken_ashi(df, pre_smoothing_period=None, post_smoothing_period=None):
    """
    Heiken Ashi (HA) with Optional Pre and Post Smoothing

    Heiken Ashi is a type of price chart that shares some characteristics with 
    candlestick charts but differs due to the values used to plot them. This 
    modified version allows for optional smoothing of the original data before 
    the Heiken Ashi calculation and/or smoothing of the Heiken Ashi values 
    themselves, aiming to provide a more refined and smoother representation 
    of price action, making it easier to identify the trend.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain columns: 
      'open', 'high', 'low', and 'close'.
    - pre_smoothing_period (int, optional): Period for EMA pre-smoothing of the 
      original data. If provided, original price bars are smoothed before Heiken 
      Ashi calculations.
    - post_smoothing_period (int, optional): Period for EMA post-smoothing of 
      Heiken Ashi values. If provided, Heiken Ashi values are smoothed post calculations.

    Call with:
        ha_df = bta.heiken_ashi(df)
        df['ha_open'] = ha_df['ha_open']
        df['ha_high'] = ha_df['ha_high']
        df['ha_low'] = ha_df['ha_low']
        df['ha_close'] = ha_df['ha_close']

    Returns:
    - pd.DataFrame: DataFrame with 'ha_open', 'ha_high', 'ha_low', and 'ha_close' columns.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['open', 'high', 'low', 'close']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # If pre-smoothing is required
    if pre_smoothing_period:
        df_copy['open'] = EMA(df_copy, 'open', pre_smoothing_period)
        df_copy['close'] = EMA(df_copy, 'close', pre_smoothing_period)
        df_copy['high'] = EMA(df_copy, 'high', pre_smoothing_period)
        df_copy['low'] = EMA(df_copy, 'low', pre_smoothing_period)

    # Regular Heiken Ashi calculations
    df_copy['ha_close'] = (
        (df_copy['open'] + df_copy['high'] + df_copy['low'] + df_copy['close']) / 4
    )
    df_copy.reset_index(inplace=True)

    ha_open = [(df_copy['open'][0] + df_copy['close'][0]) / 2]
    [ha_open.append((ha_open[i] + df_copy['ha_close'].values[i]) / 2)
     for i in range(0, len(df_copy) - 1)]

    df_copy['ha_open'] = ha_open
    df_copy.set_index('index', inplace=True)

    df_copy['ha_high'] = df_copy[['ha_open', 'ha_close', 'high']].max(axis=1)
    df_copy['ha_low'] = df_copy[['ha_open', 'ha_close', 'low']].min(axis=1)

    # If post-smoothing is required
    if post_smoothing_period:
        df_copy['ha_open'] = EMA(df_copy, 'ha_open', post_smoothing_period)
        df_copy['ha_high'] = EMA(df_copy, 'ha_high', post_smoothing_period)
        df_copy['ha_low'] = EMA(df_copy, 'ha_low', post_smoothing_period)
        df_copy['ha_close'] = EMA(df_copy, 'ha_close', post_smoothing_period)

    return df_copy[['ha_open', 'ha_high', 'ha_low', 'ha_close']]


def linear_regression_candles(df, linreg_length=11, sma_signal=True, signal_length=11):
    """
    Linear Regression Candles with Optional Signal Line

    The Linear Regression Candles transform the traditional OHLC bars using a 
    linear regression algorithm, providing a smoothed representation of price 
    action. The function also provides an optional signal line, which can be 
    either an SMA or an EMA of the Linear Regression Candle close. This signal 
    line can help to identify trends and potential trading signals.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain columns: 
      'open', 'high', 'low', and 'close'.
    - linreg_length (int, optional): Period for linear regression calculation. 
      Default is 11.
    - sma_signal (bool, optional): If True, uses SMA for the signal line. If 
      False, uses EMA. Default is True.
    - signal_length (int, optional): Period for the moving average signal line. 
      Default is 11.

    Call with:
        lr_df = bta.linear_regression_candles(df)
        df['lrc_open'] = lr_df['bopen']
        df['lrc_high'] = lr_df['bhigh']
        df['lrc_low'] = lr_df['blow']
        df['lrc_close'] = lr_df['bclose']
        df['lrc_signal'] = lr_df['signal']

    Returns:
    - pd.DataFrame: DataFrame with 'bopen', 'bhigh', 'blow', 'bclose' as the 
      Linear Regression Candles, and 'signal' as the signal line.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['open', 'high', 'low', 'close']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # Calculate linear regression coefficients for open, high, low, and close
    df_copy['bopen'] = df_copy['open'].rolling(window=linreg_length).apply(
        lambda x: np.polyfit(np.arange(len(x)), x, 1)[1] + 
                  np.polyfit(np.arange(len(x)), x, 1)[0] * (len(x) - 1),
        raw=True
    )

    df_copy['bhigh'] = df_copy['high'].rolling(window=linreg_length).apply(
        lambda x: np.polyfit(np.arange(len(x)), x, 1)[1] + 
                  np.polyfit(np.arange(len(x)), x, 1)[0] * (len(x) - 1),
        raw=True
    )

    df_copy['blow'] = df_copy['low'].rolling(window=linreg_length).apply(
        lambda x: np.polyfit(np.arange(len(x)), x, 1)[1] + 
                  np.polyfit(np.arange(len(x)), x, 1)[0] * (len(x) - 1),
        raw=True
    )

    df_copy['bclose'] = df_copy['close'].rolling(window=linreg_length).apply(
        lambda x: np.polyfit(np.arange(len(x)), x, 1)[1] + 
                  np.polyfit(np.arange(len(x)), x, 1)[0] * (len(x) - 1),
        raw=True
    )

    # Calculate the signal line using SMA or EMA
    if sma_signal:
        df_copy['signal'] = df_copy['bclose'].rolling(window=signal_length).mean()
    else:
        df_copy['signal'] = df_copy['bclose'].ewm(span=signal_length, adjust=False).mean()

    return df_copy[['bopen', 'bhigh', 'blow', 'bclose', 'signal']]

        ----- End of candles.py -----

        utility.py

        ----- Start of utility.py -----

# -*- coding: utf-8 -*-
import math
import numpy as np
import pandas as pd
from .bamboo_ta import *
from scipy.signal import argrelextrema
from scipy.stats import linregress
from typing import Tuple


def calculate_atr_stop_loss_take_profit(
    df: pd.DataFrame,
    signal_column: str = 'signal',
    atr_column: str = 'atr',
    atr_sl_mult: float = 1,
    atr_tp_mult: float = 2
) -> pd.DataFrame:
    """
    Calculate take profit, stop loss, and buy price based on ATR, signal, and advice changes.

    This version includes an internal logic that calculates 'advice_changed' based on whether
    the current signal differs from the previous signal.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame with columns 'signal', 'close', and 'atr'.
    - signal_column (str): Column with buy/sell signals. Default is 'signal'.
    - atr_column (str): Column with ATR values. Default is 'atr'.
    - atr_sl_mult (float): Multiplier for stop loss based on ATR. Default is 1.
    - atr_tp_mult (float): Multiplier for take profit based on ATR. Default is 2.

    Call with:
        atr_sl_tp_df = bta.calculate_atr_stop_loss_take_profit(df, signal_column='signal')
        df['takeprofit'] = atr_sl_tp_df['takeprofit']
        df['stoploss'] = atr_sl_tp_df['stoploss']
        df['buyprice'] = atr_sl_tp_df['buyprice']

    Returns:
    - pd.DataFrame: DataFrame with 'takeprofit', 'stoploss', and 'buyprice' columns.
    """
    # Create a new column for advice_changed if it does not exist
    df['advice_changed'] = df[signal_column] != df[signal_column].shift(1)

    # Initialize new columns for take profit, stop loss, and buy price
    takeprofit = np.full(len(df), np.nan)
    stoploss = np.full(len(df), np.nan)
    buyprice = np.full(len(df), np.nan)

    # Logic for when the advice has changed and signal is 'buy'
    buy_mask = (df['advice_changed']) & (df[signal_column] == 'buy')
    takeprofit[buy_mask] = df['close'][buy_mask] + (df[atr_column][buy_mask] * atr_tp_mult)
    stoploss[buy_mask] = df['close'][buy_mask] - (df[atr_column][buy_mask] * atr_sl_mult)
    buyprice[buy_mask] = df['close'][buy_mask]

    # Logic for carrying forward the previous values if the advice has not changed
    no_change_mask = ~df['advice_changed']
    takeprofit[no_change_mask] = pd.Series(takeprofit).shift(1)
    stoploss[no_change_mask] = pd.Series(stoploss).shift(1)
    buyprice[no_change_mask] = pd.Series(buyprice).shift(1)

    # Return the result as a DataFrame
    result_df = pd.DataFrame({
        'takeprofit': takeprofit,
        'stoploss': stoploss,
        'buyprice': buyprice
    })
    
    return result_df


def calculate_stop_loss_take_profit(
    df: pd.DataFrame,
    signal_column: str = 'trade_signal',
    long_trade_signal: str = 'long_trade',
    short_trade_signal: str = 'short_trade',
    no_trade_signal: str = 'no_trade',
    lookback_period: int = 5,
    long_reward_ratio: float = 2,
    short_reward_ratio: float = 2,
    buffer: float = 0.0
) -> pd.DataFrame:
    """
    Calculate stop loss, take profit, and entry price based on customizable trade signals.
  
    Parameters:
    - df (pandas.DataFrame): Input DataFrame containing trading data and trade signals.
    - signal_column (str): Column name where trade signals ('long_trade', 'short_trade', etc.) are stored. Default is 'trade_signal'.
    - long_trade_signal (str): The value in signal_column that represents a long trade. Default is 'long_trade'.
    - short_trade_signal (str): The value in signal_column that represents a short trade. Default is 'short_trade'.
    - no_trade_signal (str): The value in signal_column that represents no trade. Default is 'no_trade'.
    - lookback_period (int): The lookback period for calculating stop loss. Default is 5.
    - long_reward_ratio (float): Reward-risk ratio for long trades. Default is 2.
    - short_reward_ratio (float): Reward-risk ratio for short trades. Default is 2.
    - buffer (float): Buffer added to the stop loss. Default is 0.0.

    Call with:
        stop_loss_take_profit = bta.calculate_stop_loss_take_profit(df, 
                                                                    signal_column='trade_signal',
                                                                    long_trade_signal='long_trade', 
                                                                    short_trade_signal='short_trade', 
                                                                    no_trade_signal='no_trade', 
                                                                    lookback_period=5, 
                                                                    long_reward_ratio=2, 
                                                                    short_reward_ratio=1.5, 
                                                                    buffer=0.5)

    Add the new columns to the original DataFrame:
        df['stop_loss'] = stop_loss_take_profit['stop_loss']
        df['entry_price'] = stop_loss_take_profit['entry_price']
        df['take_profit'] = stop_loss_take_profit['take_profit']
        df['exit_reason'] = stop_loss_take_profit['exit_reason']

    Returns:
    - pd.DataFrame: Updated DataFrame with new columns: 'stop_loss', 'take_profit', 'entry_price', and 'exit_reason'.
    """
    stop_loss = []
    take_profit = []
    entry_price = []
    exit_reason = []

    current_signal = None
    current_stop_loss = None
    current_take_profit = None
    current_entry_price = None

    for i, row in df.iterrows():
        signal = row[signal_column]
        
        if signal == long_trade_signal:
            if current_signal != long_trade_signal:  # New long trade signal
                low_window = df['low'].iloc[max(0, i - lookback_period):i + 1]
                lowest_low = low_window.min()
                stop_loss_price = lowest_low - buffer
                current_entry_price = row['close']
                risk = current_entry_price - stop_loss_price
                take_profit_price = current_entry_price + risk * long_reward_ratio

                current_stop_loss = stop_loss_price
                current_take_profit = take_profit_price
                current_signal = long_trade_signal

            stop_loss.append(float(current_stop_loss) if current_stop_loss is not None else np.nan)
            take_profit.append(float(current_take_profit) if current_take_profit is not None else np.nan)
            entry_price.append(float(current_entry_price) if current_entry_price is not None else np.nan)

            # Determine exit reason
            if row['close'] < current_stop_loss:
                exit_reason.append('stop_loss_exit')
            elif row['close'] > current_take_profit:
                exit_reason.append('take_profit_hit')
            else:
                exit_reason.append('')

        elif signal == short_trade_signal:
            if current_signal != short_trade_signal:  # New short trade signal
                high_window = df['high'].iloc[max(0, i - lookback_period):i + 1]
                highest_high = high_window.max()
                stop_loss_price = highest_high + buffer
                current_entry_price = row['close']
                risk = stop_loss_price - current_entry_price
                take_profit_price = current_entry_price - risk * short_reward_ratio

                current_stop_loss = stop_loss_price
                current_take_profit = take_profit_price
                current_signal = short_trade_signal

            stop_loss.append(float(current_stop_loss) if current_stop_loss is not None else np.nan)
            take_profit.append(float(current_take_profit) if current_take_profit is not None else np.nan)
            entry_price.append(float(current_entry_price) if current_entry_price is not None else np.nan)

            # Determine exit reason
            if row['close'] > current_stop_loss:
                exit_reason.append('stop_loss_exit')
            elif row['close'] < current_take_profit:
                exit_reason.append('take_profit_hit')
            else:
                exit_reason.append('')

        elif signal == no_trade_signal:
            # No trade signal, reset values
            current_signal = None
            current_stop_loss = None
            current_take_profit = None
            current_entry_price = None
            stop_loss.append(np.nan)
            take_profit.append(np.nan)
            entry_price.append(np.nan)
            exit_reason.append('trade_signal_lost')

    # Create a new DataFrame with only the calculated columns
    result_df = pd.DataFrame({
        'stop_loss': stop_loss,
        'take_profit': take_profit,
        'entry_price': entry_price,
        'exit_reason': exit_reason
    })
    
    return result_df


def consecutive_count(consecutive_diff: np.ndarray) -> float:
    """
    Calculate the average consecutive count of non-zero differences.
    
    Parameters:
    - consecutive_diff (np.ndarray): Array of consecutive differences.

    Returns:
    - float: Average consecutive count. If there are fewer than two non-zero differences, returns 0.
    """
    # Find indices of non-zero elements in the array
    non_zero_diff = np.where(consecutive_diff != 0)[0]

    # If fewer than two non-zero elements, return 0 as no valid calculation can be performed
    if len(non_zero_diff) < 2:
        return 0

    # Calculate and return the average distance between consecutive non-zero indices
    return np.mean(np.diff(non_zero_diff))


def first_crossed_above_second(series1: pd.Series, series2: pd.Series) -> pd.Series:
    """
    Check if series1 crosses above series2 in a vectorized manner.

    Parameters:
    - series1 (pd.Series): First input series to check for crossover.
    - series2 (pd.Series): Second input series to compare against.

    Call with:
        df['first_crossed_above_second'] = bta.first_crossed_above_second(series1, series2)

    Returns:
    - pd.Series: Boolean series where True indicates a crossover above.
    """
    # Ensure both series have the same length
    if len(series1) != len(series2):
        raise ValueError("Input series must have the same length")

    # Vectorized check for crossover above
    return (series1 > series2) & (series1.shift(1) <= series2.shift(1))


def first_crossed_below_second(series1: pd.Series, series2: pd.Series) -> pd.Series:
    """
    Check if series1 crosses below series2 in a vectorized manner.

    Parameters:
    - series1 (pd.Series): First input series to check for crossover.
    - series2 (pd.Series): Second input series to compare against.

    Call with:
        df['first_crossed_below_second'] = bta.first_crossed_below_second(series1, series2)

    Returns:
    - pd.Series: Boolean series where True indicates a crossover below.
    """
    # Ensure both series have the same length
    if len(series1) != len(series2):
        raise ValueError("Input series must have the same length")

    # Vectorized check for crossover below
    return (series1 < series2) & (series1.shift(1) >= series2.shift(1))


def cumulative_return(df: pd.DataFrame, column: str = "close", fillna: bool = False) -> pd.Series:
    """
    Calculate the Cumulative Return (CR) of a specified column in a DataFrame.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame containing the specified column.
    - column (str): The column on which the cumulative return is to be calculated. Default is "close".
    - fillna (bool): If True, fill NaN values. Default is False.

    Call with:
        df['cumulative_return'] = bta.cumulative_return(df)

    Returns:
    - pd.Series: Series of cumulative return values.
    """
    # Create a copy of the DataFrame to avoid modifying the original
    df_copy = df.copy()

    # Calculate cumulative return
    df_copy['cum_ret'] = (df_copy[column] / df_copy[column].iloc[0]) - 1
    df_copy['cum_ret'] *= 100  # Expressing cumulative return as a percentage

    # Handle NaN values if requested
    if fillna:
        df_copy['cum_ret'] = df_copy['cum_ret'].fillna(-1)

    return df_copy['cum_ret'].rename("cumulative_return")


def daily_log_return(df: pd.DataFrame, column: str = "close", fillna: bool = False) -> pd.Series:
    """
    Calculate the Daily Log Return (DLR) of a specified column in a DataFrame.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the specified column.
    - column (str): The column on which the daily log return is to be calculated. Default is "close".
    - fillna (bool): If True, fill NaN values with 0. Default is False.

    Call with:
        df['daily_log_return'] = bta.daily_log_return(df)

    Returns:
    - pd.Series: Series of daily log return values.
    """
    # Copy the DataFrame to avoid modifying the original data
    df_copy = df.copy()

    # Calculate the daily log return
    df_copy['daily_log_return'] = np.log(df_copy[column]).diff() * 100  # Expressing as a percentage

    # Handle NaN values if requested
    if fillna:
        df_copy['daily_log_return'] = df_copy['daily_log_return'].fillna(0)

    return df_copy['daily_log_return'].rename("daily_log_return")


def daily_return(df: pd.DataFrame, column: str = "close", fillna: bool = False) -> pd.Series:
    """
    Calculate the Daily Return (DR) of a specified column in a DataFrame.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the specified column.
    - column (str): The column on which the daily return is to be calculated. Default is "close".
    - fillna (bool): If True, fill NaN values with 0. Default is False.

    Call with:
        df['daily_return'] = bta.daily_return(df)

    Returns:
    - pd.Series: Series of daily return values.
    """
    # Copy the DataFrame to avoid modifying the original data
    df_copy = df.copy()

    # Calculate the daily return as a percentage
    df_copy['daily_return'] = (df_copy[column] / df_copy[column].shift(1)) - 1
    df_copy['daily_return'] *= 100

    # Handle NaN values if requested
    if fillna:
        df_copy['daily_return'] = df_copy['daily_return'].fillna(0)

    return df_copy['daily_return'].rename("daily_return")


def exhaustion_candles(df: pd.DataFrame, window: int = 1, multiplier: int = 1) -> Tuple[np.ndarray, np.ndarray]:
    """
    Calculate the average consecutive length of ups and downs to adjust the exhaustion bands dynamically.
    
    Parameters:
    - df (pandas.DataFrame): Input DataFrame containing the 'close' price series.
    - window (int): Lookback window for calculation.
    - multiplier (int): Scalar multiplier for both major and minor quality.

    Call with:
        maj_qual, min_qual = exhaustion_candles(df, window, multiplier)
        df['maj_qual'] = maj_qual
        df['min_qual'] = min_qual

    Returns:
    - Tuple[np.ndarray, np.ndarray]: Arrays of major and minor quality values.
    """
    consecutive_diff = np.sign(df['close'].diff())
    maj_qual = np.zeros(len(df))
    min_qual = np.zeros(len(df))

    # Ensure multiplier is applied consistently
    multiplier = np.full(len(df), multiplier)

    for i in range(len(df)):
        idx_range = consecutive_diff[i - window + 1:i + 1] if i >= window else consecutive_diff[:i + 1]
        avg_consecutive = consecutive_count(idx_range)
        
        # Ensure avg_consecutive is a scalar, not an array
        if isinstance(avg_consecutive, np.ndarray):
            avg_consecutive = avg_consecutive.item()

        maj_qual[i] = int(avg_consecutive * (3 * multiplier[i])) if not np.isnan(avg_consecutive) else 0
        min_qual[i] = int(avg_consecutive * (3 * multiplier[i])) if not np.isnan(avg_consecutive) else 0

    return maj_qual, min_qual


import numpy as np
import pandas as pd
from scipy.signal import argrelextrema

def exhaustion_lengths(df: pd.DataFrame) -> Tuple[int, int]:
    """
    Calculate the average length of peaks and valleys to adjust the exhaustion bands dynamically.
    
    Parameters:
    - df (pandas.DataFrame): Input DataFrame containing 'high' and 'low' columns.

    Call with:
        maj_len, min_len = exhaustion_lengths(df)
        df['maj_len'] = maj_len
        df['min_len'] = min_len

    Returns:
    - int, int: Average peak distance and average valley distance.
    """
    # Find relative maxima (peaks) and minima (valleys) in the 'high' and 'low' columns
    high_indices = argrelextrema(df['high'].to_numpy(), np.greater)[0]
    low_indices = argrelextrema(df['low'].to_numpy(), np.less)[0]

    # If there are fewer than two peaks or valleys, return zero
    if len(high_indices) < 2 or len(low_indices) < 2:
        return 0, 0

    # Calculate average and standard deviation of distances between peaks and valleys
    avg_peak_distance = np.mean(np.diff(high_indices))
    std_peak_distance = np.std(np.diff(high_indices))
    avg_valley_distance = np.mean(np.diff(low_indices))
    std_valley_distance = np.std(np.diff(low_indices))

    # Determine major and minor lengths using average + standard deviation
    maj_len = int(avg_peak_distance + std_peak_distance)
    min_len = int(avg_valley_distance + std_valley_distance)

    return maj_len, min_len


def get_min_max(series1: pd.Series, series2: pd.Series, function: str = "min") -> pd.Series:
    """
    Find the minimum or maximum value between two series for each index.

    Parameters:
    - series1 (pd.Series): First input series.
    - series2 (pd.Series): Second input series.
    - function (str): Function to apply ("min" or "max"). Default is "min".

    Call with:
        df['min_max'] = bta.get_min_max(series1, series2, function)
    Like:
        df['min_max'] = bta.get_min_max(df['open'], df['open'], 'max')

    Returns:
    - pd.Series: Series with min or max values for each index.
    """
    series1 = np.array(series1)
    series2 = np.array(series2)

    if function == "min":
        output = np.amin([series1, series2], axis=0)
    elif function == "max":
        output = np.amax([series1, series2], axis=0)
    else:
        raise ValueError('"function" variable should be "min" or "max"')

    return pd.Series(output)


def linear_decay(start: float, end: float, start_time: int, 
                 end_time: int, trade_time: int) -> float:
    """
    Simple linear decay function. Decays from start to end after 
    end_time minutes (starts after start_time minutes).

    Parameters:
    - start (float): Starting value.
    - end (float): Ending value.
    - start_time (int): Start time in minutes.
    - end_time (int): End time in minutes.
    - trade_time (int): Current trade time in minutes.

    Call with:
        decayed_value = linear_decay(start, end, start_time, end_time, trade_time)

    Returns:
    - float: Decayed value.
    """
    time = max(0, trade_time - start_time)
    rate = (start - end) / (end_time - start_time)
    return max(end, start - (rate * time))


def linear_growth(start: float, end: float, start_time: int, 
                  end_time: int, trade_time: int) -> float:
    """
    Simple linear growth function. Grows from start to end after 
    end_time minutes (starts after start_time minutes).

    Parameters:
    - start (float): Starting value.
    - end (float): Ending value.
    - start_time (int): Start time in minutes.
    - end_time (int): End time in minutes.
    - trade_time (int): Current trade time in minutes.

    Call with:
        grown_value = linear_growth(start, end, start_time, end_time, trade_time)

    Returns:
    - float: Grown value.
    """
    time = max(0, trade_time - start_time)
    rate = (end - start) / (end_time - start_time)
    return min(end, start + (rate * time))


def populate_leledc_major_minor(df: pd.DataFrame, maj_qual: np.ndarray, 
                                min_qual: np.ndarray, maj_len: int, 
                                min_len: int) -> pd.DataFrame:
    """
    Populate Leledc Major and Minor columns.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame.
    - maj_qual (np.ndarray): Array of major quality values.
    - min_qual (np.ndarray): Array of minor quality values.
    - maj_len (int): Major length value.
    - min_len (int): Minor length value.

    Call with:
        leledc_major_minor = bta.populate_leledc_major_minor(df, maj_qual, min_qual, maj_len, min_len)
        df['leledc_major'] = leledc_major_minor['leledc_major']
        df['leledc_minor'] = leledc_major_minor['leledc_minor']

    Returns:
    - pd.DataFrame: DataFrame with 'leledc_major' and 'leledc_minor' columns.
    """
    df_copy = df.copy()
    bindex_maj, sindex_maj, trend_maj = 0, 0, 0
    bindex_min, sindex_min = 0, 0

    df_copy['leledc_major'] = np.nan
    df_copy['leledc_minor'] = 0

    for i in range(1, len(df_copy)):
        close = df_copy['close'][i]
        short_length = i if i < 4 else 4

        if close > df_copy['close'][i - short_length]:
            bindex_maj += 1
            bindex_min += 1
        elif close < df_copy['close'][i - short_length]:
            sindex_maj += 1
            sindex_min += 1

        update_major = False
        if (bindex_maj > maj_qual[i] and close < df_copy['open'][i] and
                df_copy['high'][i] >= df_copy['high'][i - maj_len:i].max()):
            bindex_maj, trend_maj, update_major = 0, 1, True
        elif (sindex_maj > maj_qual[i] and close > df_copy['open'][i] and
              df_copy['low'][i] <= df_copy['low'][i - maj_len:i].min()):
            sindex_maj, trend_maj, update_major = 0, -1, True

        df_copy.at[i, 'leledc_major'] = trend_maj if update_major else np.nan if trend_maj == 0 else trend_maj

        if (bindex_min > min_qual[i] and close < df_copy['open'][i] and
                df_copy['high'][i] >= df_copy['high'][i - min_len:i].max()):
            bindex_min = 0
            df_copy.at[i, 'leledc_minor'] = -1
        elif (sindex_min > min_qual[i] and close > df_copy['open'][i] and
              df_copy['low'][i] <= df_copy['low'][i - min_len:i].min()):
            sindex_min = 0
            df_copy.at[i, 'leledc_minor'] = 1
        else:
            df_copy.at[i, 'leledc_minor'] = 0

    return df_copy[['leledc_major', 'leledc_minor']]


def regression_slope(df: pd.DataFrame, lookback_period: int = 20) -> pd.Series:
    """
    Calculate the slope of the linear regression for a given lookback period.

    This function computes the slope of a linear regression line (least squares) fitted to the
    'close' prices over the specified lookback period.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame containing the 'close' prices.
    - lookback_period (int): The lookback period for calculating the regression slope. Default is 20.

    Call with:
        df['slope'] = bta.regression_slope(df, 20)

    Returns:
    - pd.Series: Series containing the regression slopes.
    """
    # Ensure the 'close' column exists in the DataFrame
    if 'close' not in df.columns:
        raise KeyError("The input DataFrame must contain a 'close' column.")
    
    # Extract the 'close' prices as a NumPy array for faster processing
    y_values = df['close'].values
    
    # Create an array for the x-values (time steps) for the regression
    x_values = np.arange(lookback_period)
    x_mean = x_values.mean()
    
    # Function to calculate the slope for a given rolling window
    def calculate_slope(window):
        y_mean = window.mean()
        numerator = np.sum((x_values - x_mean) * (window - y_mean))
        denominator = np.sum((x_values - x_mean) ** 2)
        return numerator / denominator

    # Apply the slope calculation to the rolling window on the 'close' prices
    slope_series = df['close'].rolling(window=lookback_period).apply(calculate_slope, raw=True)
    
    return slope_series


def same_length(bigger: np.ndarray, shorter: np.ndarray) -> np.ndarray:
    """
    Ensures the shorter array has the same length as the bigger array by padding with NaN values.

    Parameters:
    - bigger (np.ndarray): The array with the larger size.
    - shorter (np.ndarray): The array with the smaller size.

    Call with:
        padded_array = same_length(bigger_array, shorter_array)

    Returns:
    - np.ndarray: The shorter array padded with NaN values to match the size of the bigger array.
    """
    if not isinstance(bigger, np.ndarray) or not isinstance(shorter, np.ndarray):
        raise ValueError("Both inputs must be NumPy arrays.")
    
    if bigger.shape[0] < shorter.shape[0]:
        raise ValueError("The first array must be bigger or equal in length to the second array.")
    
    # Calculate how many NaN values to add to the shorter array
    pad_size = bigger.shape[0] - shorter.shape[0]
    
    # Return the concatenated array of NaNs followed by the shorter array
    return np.concatenate((np.full(pad_size, np.nan), shorter))


def st_dev(series: pd.Series, period: int) -> pd.Series:
    """
    Calculate the rolling standard deviation over a specified period.

    Parameters:
    - series (pd.Series): The data series to calculate the standard deviation for.
    - period (int): The period over which to calculate the standard deviation.

    Call with:
        df['std_dev'] = bta.st_dev(df['column_name'], period=14)
    
    Like:
        df['std_dev'] = bta.st_dev(df['close'], period=14)

    Returns:
    - pd.Series: The rolling standard deviation of the series over the specified period.
    """
    if not isinstance(series, pd.Series):
        raise ValueError("Input must be a pandas Series.")
    if period <= 0:
        raise ValueError("Period must be a positive integer.")

    return series.rolling(window=period).std()


def z_score(series: pd.Series, window: int = 500) -> pd.Series:
    """
    Calculate the z-score of a series.

    Parameters:
    - series (pd.Series): Input series.
    - window (int): Lookback window for mean and standard deviation calculation.

    Call with:
        df['zscore']  = bta.z_score(series)
    
    Like:
        df['zscore']  = bta.z_score(df['close'])

    Returns:
    - pd.Series: Z-score series.
    """
    mean = series.rolling(window=window, min_periods=1).mean()
    std = series.rolling(window=window, min_periods=1).std(ddof=0)
    zscore = (series - mean) / std
    zscore = zscore.fillna(0)  # Fill NaN values with 0 to avoid issues with calculations

    return zscore


class IndicatorMixin:
    """Utility mixin class for indicator calculations."""

    _fillna = False

    def _check_fillna(self, series: pd.Series, value: int = 0) -> pd.Series:
        """
        Check if the fillna flag is True and handle NaN values accordingly.

        Parameters:
        - series (pd.Series): Calculated indicator series.
        - value (int): Value to fill gaps; if -1, fill values using 'backfill' mode.

        Returns:
        - pd.Series: Series with NaN values handled.
        """
        if self._fillna:
            series_output = series.copy(deep=False)
            series_output = series_output.replace([np.inf, -np.inf], np.nan)
            if isinstance(value, int) and value == -1:
                series = series_output.ffill().bfill()
            else:
                series = series_output.ffill().fillna(value)
        return series

    @staticmethod
    def _true_range(high: pd.Series, low: pd.Series, prev_close: pd.Series) -> pd.Series:
        """
        Calculate the true range.

        Parameters:
        - high (pd.Series): High price series.
        - low (pd.Series): Low price series.
        - prev_close (pd.Series): Previous close price series.

        Returns:
        - pd.Series: True range series.
        """
        tr1 = high - low
        tr2 = (high - prev_close).abs()
        tr3 = (low - prev_close).abs()
        true_range = pd.DataFrame(data={"tr1": tr1, "tr2": tr2, "tr3": tr3}).max(axis=1)
        return true_range


def drop_na(df: pd.DataFrame) -> pd.DataFrame:
    """
    Drop rows with 'NaN' values and handle very large numbers and zeros in numeric columns.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame.

    Call with:
        df['df_cleaned'] = bta.drop_na(df)

    Returns:
    - pd.DataFrame: DataFrame without NaN values, extremely large values, and zeroes in numeric columns.
    """
    df_copy = df.copy()
    
    # Select numeric columns
    number_cols = df_copy.select_dtypes(include=np.number).columns.tolist()
    
    # Replace extremely large values (greater than exp(709)) with NaN
    df_copy[number_cols] = df_copy[number_cols].where(df_copy[number_cols] < math.exp(709))
    
    # Replace zero values with NaN
    df_copy[number_cols] = df_copy[number_cols].replace(0.0, np.nan)
    
    # Drop rows with any NaN values
    df_cleaned = df_copy.dropna()
    
    return df_cleaned



        ----- End of utility.py -----

        volatility.py

        ----- Start of volatility.py -----

# -*- coding: utf-8 -*-
# volatility.py
import numpy as np
import pandas as pd


def average_true_range(df: pd.DataFrame, period: int = 14) -> pd.DataFrame:
    """
    Average True Range (ATR)

    The Average True Range (ATR), smoothed by the Moving Average, is a measure of volatility. It was introduced by Welles Wilder in his book 'New Concepts in Technical Trading Systems'.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain columns 'high', 'low', and 'close'.
    - period (int): Period for the ATR calculation. Default is 14.

    Call with:
        df['atr'] = bta.average_true_range(df, 14)['atr']

    Returns:
    - pd.DataFrame: DataFrame with 'atr' column.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['high', 'low', 'close']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # Calculate True Range components
    df_copy['high_low'] = df_copy['high'] - df_copy['low']
    df_copy['high_close'] = (df_copy['high'] - df_copy['close'].shift()).abs()
    df_copy['low_close'] = (df_copy['low'] - df_copy['close'].shift()).abs()

    # Calculate True Range
    df_copy['true_range'] = df_copy[['high_low', 'high_close', 'low_close']].max(axis=1)

    # Calculate ATR as the rolling mean of True Range
    df_copy['atr'] = df_copy['true_range'].rolling(window=period, min_periods=1).mean()

    return df_copy[['atr']]


def bollinger_bands(df: pd.DataFrame, column: str = 'close', period: int = 20, std_dev: float = 2.0, ddof: int = 0) -> pd.DataFrame:
    """
    Bollinger Bands (BBANDS)

    Bollinger Bands are a type of statistical chart characterizing the prices and volatility over time of a financial instrument or commodity.

    Parameters:
    - df (pandas.DataFrame): DataFrame containing the data.
    - column (str): The column name on which the BBANDS is to be applied. Default is 'close'.
    - period (int): Look-back period to compute the moving average. Default is 20.
    - std_dev (float): Number of standard deviations to compute the upper and lower bands. Default is 2.0.
    - ddof (int): Degrees of Freedom to use in standard deviation calculation. Default is 0.

    Call with:
        bb_result = bta.bollinger_bands(df, 'close', 20, 2, 0)
        df['bb_upper'] = bb_result['bb_upper']
        df['bb_middle'] = bb_result['bb_middle']
        df['bb_lower'] = bb_result['bb_lower']

    Returns:
    - pd.DataFrame: DataFrame with 'bb_upper', 'bb_middle', 'bb_lower' columns.
    """
    df_copy = df.copy()

    # Calculate middle band (SMA)
    sma = df_copy[column].rolling(window=period).mean()

    # Calculate standard deviation of the specified column
    rolling_std = df_copy[column].rolling(window=period).std(ddof=ddof)

    # Calculate upper and lower bands
    df_copy['bb_upper'] = sma + (rolling_std * std_dev)
    df_copy['bb_middle'] = sma
    df_copy['bb_lower'] = sma - (rolling_std * std_dev)

    return df_copy[['bb_upper', 'bb_middle', 'bb_lower']]

def true_range(df: pd.DataFrame) -> pd.DataFrame:
    """
    Calculate True Range (TR)

    The True Range indicator measures market volatility. True Range is defined as the greatest of the following:
    - The current high minus the current low
    - The absolute value of the current high minus the previous close
    - The absolute value of the current low minus the previous close

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'high', 'low', and 'close' columns.

    Call with:
        df['true_range'] = bta.true_range(df)['true_range']

    Returns:
    - pd.DataFrame: DataFrame with 'true_range' column.
    """
    df_copy = df.copy()
    prev_close = df_copy['close'].shift()
    
    # Calculate the true range components
    true_range = pd.concat(
        [
            df_copy['high'] - df_copy['low'],
            (df_copy['high'] - prev_close).abs(),
            (df_copy['low'] - prev_close).abs()
        ], axis=1
    ).max(axis=1)

    df_copy['true_range'] = true_range

    return df_copy[['true_range']]

'''
TODO:
KeltnerChannel (+ width)
DonchianChannel (+ width)
Ulcer Index

    https://stockcharts.com/school/doku.php?id=chart_school:technical_indicators:ulcer_index

Bollingerbands width and more

'''
        ----- End of volatility.py -----

        __init__.py

        ----- Start of __init__.py -----

# -*- coding: utf-8 -*-
from bamboo_ta.bamboo_ta import *
import numpy as np
from pandas import DataFrame
import pandas as pd

name = "bamboo_ta"
"""
.. moduleauthor:: DutchCryptoDad
"""

        ----- End of __init__.py -----

        momentum.py

        ----- Start of momentum.py -----

# -*- coding: utf-8 -*-
import numpy as np
import pandas as pd
from .bamboo_ta import *
from .trend import *
from .volatility import *
from .utility import *


def awesome_oscillator(
    df: pd.DataFrame, 
    high_col: str = 'high', 
    low_col: str = 'low', 
    window1: int = 5, 
    window2: int = 34, 
    fillna: bool = False
) -> pd.DataFrame:
    """
    Awesome Oscillator (AO)

    The Awesome Oscillator is a momentum indicator used to measure market momentum.
    It is calculated by subtracting a 34-period simple moving average (SMA) of the
    median price from a 5-period SMA of the median price.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame containing 'high' and 'low' columns.
    - high_col (str): The name of the 'high' column. Default is 'high'.
    - low_col (str): The name of the 'low' column. Default is 'low'.
    - window1 (int, optional): Short period. Default is 5.
    - window2 (int, optional): Long period. Default is 34.
    - fillna (bool, optional): If True, fill nan values with 0. Default is False.

    Call with:
        df['ao'] = bta.awesome_oscillator(df, 'high', 'low', 5, 34)['ao']

    Returns:
    - pd.DataFrame: DataFrame with the 'ao' column.
    """
    df_copy = df.copy()

    median_price = 0.5 * (df_copy[high_col] + df_copy[low_col])
    min_periods_s = 0 if fillna else window1
    min_periods_l = 0 if fillna else window2

    df_copy['ao'] = (
        median_price.rolling(window1, min_periods=min_periods_s).mean()
        - median_price.rolling(window2, min_periods=min_periods_l).mean()
    )
    
    if fillna:
        df_copy['ao'] = df_copy['ao'].fillna(0)

    return df_copy[['ao']]


def chande_momentum_oscillator(df: pd.DataFrame, length: int = 14) -> pd.DataFrame:
    """
    Chande Momentum Oscillator (CMO)

    The Chande Momentum Oscillator (CMO) is a technical momentum indicator developed 
    by Tushar Chande. It measures the amount that an asset's price has changed over 
    a specified period of time.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the 'close' column.
    - length (int): Length for the CMO calculation. Default is 14.

    Call with:
        df['cmo'] = bta.chande_momentum_oscillator(df)

    For Signal line:
        df['cmo_signal'] = df['cmo'].rolling(window=10).mean()  # Using SMA for signal

    Returns:
    - pd.DataFrame: DataFrame with 'cmo' column.
    """
    df_copy = df.copy()

    mom = df['close'].diff()
    pos_mom = mom.where(mom > 0, 0)
    neg_mom = -mom.where(mom < 0, 0)
    
    sm1 = pos_mom.rolling(window=length).sum()
    sm2 = neg_mom.rolling(window=length).sum()
    
    df_copy['cmo'] = 100 * (sm1 - sm2) / (sm1 + sm2)

    return df_copy[['cmo']]


def elliott_wave_oscillator(
    df: pd.DataFrame, 
    column: str = 'close', 
    sma1_period: int = 5, 
    sma2_period: int = 35
) -> pd.DataFrame:
    """
    Elliott Wave Oscillator (EWO)

    The Elliott Wave Oscillator (EWO) is a tool to help identify the trend and 
    overall market pattern, assisting in finding future trading opportunities.
    It is derived by calculating the difference between a short and long period 
    simple moving average, then normalizing the result with the close price.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the 
      column specified.
    - column (str): The column on which EWO is to be calculated. Default is 'close'.
    - sma1_period (int): The period for the shorter SMA used in EWO calculation. 
      Default is 5.
    - sma2_period (int): The period for the longer SMA used in EWO calculation. 
      Default is 35.

    Call with:
        df['ewo'] = bta.elliott_wave_oscillator(df, 'close', 5, 35)

    Returns:
    - pd.DataFrame: DataFrame with 'ewo' column.
    """
    df_copy = df.copy()

    sma1 = df[column].rolling(window=sma1_period).mean()
    sma2 = df[column].rolling(window=sma2_period).mean()
    
    df_copy['ewo'] = ((sma1 - sma2) / df[column] * 100)

    return df_copy[['ewo']]


def ehlers_fisher_stochastic_center_of_gravity(df: pd.DataFrame, length: int = 8) -> pd.DataFrame:
    """
    Ehlers Fisher Stochastic Center of Gravity Indicator

    The Fisher Stochastic Center of Gravity indicator, developed by John Ehlers, 
    is used to identify potential turning points in the market by calculating 
    the center of gravity of price movements.

    Inspired by: 
    https://ninjatraderecosystem.com/user-app-share-download/john-ehlers-the-fisher-stochastic-center-of-gravity/
    and: https://fxstill.com/indikators/the-fisher-stochastic-center-of-gravity
    and: https://viewer.mathworks.com/?viewer=plain_code&url=https%3A%2F%2Fes.mathworks.com%2Fmatlabcentral%2Fmlc-downloads%2Fdownloads%2F5a9e5f01-906c-4152-98c6-87484eed86bf%2F853ab8ad-8751-4bcd-ae00-60a9444e9182%2Ffiles%2Fmatlab%2FChapter4-Ehlers%2FEhlerStochCG.m&embed=web
    and: https://www.tradingview.com/script/TLjl71aL-Ehlers-Fisher-Stochastic-Center-Of-Gravity-CC/

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain columns: 'high', 'low'.
    - length (int): Period for the indicator. Default is 8.

    Call with:
        fscg = bta.ehlers_fisher_stochastic_center_of_gravity(df)
        df['cg'] = fscg['cg']
        df['trigger'] = fscg['trigger']

    Returns:
    - pd.DataFrame: DataFrame with 'CG' and 'Trigger' columns.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['high', 'low']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    price = (df['high'] + df['low']) / 2

    # Initialize series
    num = pd.Series([0.0] * len(df), index=df.index)
    denom = pd.Series([0.0] * len(df), index=df.index)
    sg = pd.Series([0.0] * len(df), index=df.index)

    min_bar = length + 1
    l = (length + 1) / 2

    # Calculate CG
    for i in range(min_bar, len(df)):
        num_val = 0.0
        denom_val = 0.0
        for count in range(length):
            num_val += (1 + count) * price.iloc[i - count]
            denom_val += price.iloc[i - count]

        if denom_val != 0:
            sg.iloc[i] = l - num_val / denom_val
        else:
            sg.iloc[i] = 0.0

        max_cg = sg.iloc[i - length + 1:i + 1].max()
        min_cg = sg.iloc[i - length + 1:i + 1].min()

        if max_cg != min_cg:
            num.iloc[i] = (sg.iloc[i] - min_cg) / (max_cg - min_cg)
        else:
            num.iloc[i] = 0.0

        denom.iloc[i] = (4 * num.iloc[i] + 3 * num.iloc[i - 1] + 
                         2 * num.iloc[i - 2] + num.iloc[i - 3]) / 10

    # Calculate Value3 (V3) and Trigger
    v3 = 0.5 * np.log((1 + 1.98 * (denom - 0.5)) / (1 - 1.98 * (denom - 0.5)))
    trigger = v3.shift(1)

    df_copy['cg'] = v3
    df_copy['trigger'] = trigger

    return df_copy[['cg', 'trigger']]


def kaufmans_adaptive_moving_average(
    df: pd.DataFrame,
    close_col: str = 'close',
    window: int = 14,
    pow1: int = 2,
    pow2: int = 30,
    fillna: bool = False,
) -> pd.DataFrame:
    """
    Kaufman's Adaptive Moving Average (KAMA)

    Moving average designed to account for market noise or volatility. KAMA
    will closely follow prices when the price swings are relatively small and
    the noise is low. KAMA will adjust when the price swings widen and follow
    prices from a greater distance. This trend-following indicator can be
    used to identify the overall trend, time turning points, and filter price
    movements.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the 'close' column.
    - close_col (str): Column name for the close prices. Default is 'close'.
    - window (int): Number of periods for the efficiency ratio. Default is 10.
    - pow1 (int): Number of periods for the fastest EMA constant. Default is 2.
    - pow2 (int): Number of periods for the slowest EMA constant. Default is 30.
    - fillna (bool): If True, fill nan values with the close prices. Default is False.

    Call with:
        df['kama'] = bta.kaufmans_adaptive_moving_average(df)['kama']

    Returns:
    - pd.DataFrame: DataFrame with 'kama' column.
    """
    close = df[close_col]
    close_values = close.values
    vol = pd.Series(abs(close - np.roll(close, 1)))

    min_periods = 0 if fillna else window
    er_num = abs(close_values - np.roll(close_values, window))
    er_den = vol.rolling(window, min_periods=min_periods).sum()
    efficiency_ratio = np.divide(
        er_num, er_den, out=np.zeros_like(er_num), where=er_den != 0
    )

    smoothing_constant = (
        (
            efficiency_ratio * (2.0 / (pow1 + 1) - 2.0 / (pow2 + 1.0))
            + 2 / (pow2 + 1.0)
        )
        ** 2.0
    ).values

    kama = np.zeros(smoothing_constant.size)
    len_kama = len(kama)
    first_value = True

    for i in range(len_kama):
        if np.isnan(smoothing_constant[i]):
            kama[i] = np.nan
        elif first_value:
            kama[i] = close_values[i]
            first_value = False
        else:
            kama[i] = kama[i - 1] + smoothing_constant[i] * (
                close_values[i] - kama[i - 1]
            )
    
    kama_series = pd.Series(kama, index=close.index)

    if fillna:
        kama_series = kama_series.fillna(close)

    df_copy = df.copy()
    df_copy['kama'] = kama_series

    return df_copy[['kama']]


def macd(
    df: pd.DataFrame, 
    column: str = 'close', 
    short_window: int = 12, 
    long_window: int = 26, 
    signal_window: int = 9
) -> pd.DataFrame:
    """
    Moving Average Convergence Divergence (MACD)

    MACD is a trend-following momentum indicator that shows the relationship 
    between two moving averages of a security’s price.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the "close" column.
    - column (str): The column on which MACD is to be calculated. Default is "close".
    - short_window (int): The short-term period for EMA. Default is 12.
    - long_window (int): The long-term period for EMA. Default is 26.
    - signal_window (int): The signal line period for EMA. Default is 9.

    Call with:
        macd_result = bta.macd(df, 'close', 12, 26, 9)
        df['macd'] = macd_result['macd']
        df['macd_signal'] = macd_result['macd_signal']
        df['macd_histogram'] = macd_result['macd_histogram']

    Returns:
    - pd.DataFrame: DataFrame with 'macd', 'macd_signal', and 'macd_histogram' columns.
    """
    def ema_calculation(series, span):
        return series.ewm(span=span, adjust=False).mean()

    short_ema = ema_calculation(df[column], span=short_window)
    long_ema = ema_calculation(df[column], span=long_window)
    macd = short_ema - long_ema
    signal = ema_calculation(macd, span=signal_window)
    histogram = macd - signal

    df_copy = df.copy()
    df_copy['macd'] = macd
    df_copy['macd_signal'] = signal
    df_copy['macd_histogram'] = histogram
    
    return df_copy[['macd', 'macd_signal', 'macd_histogram']]


def macd_leader(
    df: pd.DataFrame, 
    src: str = 'close', 
    fast_length: int = 12, 
    slow_length: int = 26, 
    signal_length: int = 9
) -> pd.DataFrame:
    """
    MACD Leader

    The MACD Leader is a variation of the standard MACD that aims to provide an 
    earlier signal by using a different calculation method.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the source column.
    - src (str): The column to use for calculations. Default is 'close'.
    - fast_length (int): Length for the fast EMA. Default is 12.
    - slow_length (int): Length for the slow EMA. Default is 26.
    - signal_length (int): Length for the signal EMA. Default is 9.

    Call with:
        df['macd_leader'] = bta.macd_leader(df, 'close')['macd_leader']

    Returns:
    - pd.DataFrame: DataFrame with 'macd_leader' column.
    """
    def ema_calculation(series, span):
        return series.ewm(span=span, adjust=False).mean()

    df_copy = df.copy()
    src_series = df[src]

    sema = ema_calculation(src_series, span=fast_length)
    lema = ema_calculation(src_series, span=slow_length)
    diff_sema = src_series - sema
    diff_lema = src_series - lema
    i1 = sema + ema_calculation(diff_sema, span=fast_length)
    i2 = lema + ema_calculation(diff_lema, span=slow_length)
    macd_leader = ((i1 - i2) / 10) * 10

    df_copy['macd_leader'] = macd_leader
    
    return df_copy[['macd_leader']]

def ma_streak(
    df: pd.DataFrame, 
    length: int = 10, 
    src: str = 'close', 
    matype: int = 1
) -> pd.DataFrame:
    """
    MA Streak Indicator

    This indicator tracks how many bars a given moving average is rising or falling. 
    It's color-coded green (positive) or red (negative).

    Inspired by: 
    https://www.tradingview.com/script/Yq1z7cIv-MA-Streak-Can-Show-When-a-Run-Is-Getting-Long-in-the-Tooth/
    
    Call with:
        df['ma_streak'] = bta.ma_streak(df, length=10, src='close', matype=1)['ma_streak']

    MA types:
    1 - Simple Moving Average (SMA)
    2 - Exponential Moving Average (EMA)
    3 - Hull Moving Average (HMA)
    4 - Weighted Moving Average (WMA)
    5 - Volume Weighted Moving Average (VWMA)

    Parameters:
    - df (pd.DataFrame): Input DataFrame containing the data.
    - length (int): Period for the moving average calculation. Default is 10.
    - src (str): The column name to use for the moving average calculation. Default is 'close'.
    - matype (int): Type of moving average to use. Default is 1 (SMA).

    Returns:
    - pd.DataFrame: DataFrame with 'ma_streak' column.
    """
    df_copy = df.copy()

    # Calculate different types of moving averages
    df_copy['sma'] = df_copy[src].rolling(window=length).mean()
    df_copy['ema'] = df_copy[src].ewm(span=length, adjust=False).mean()
    df_copy['wma'] = df_copy[src].rolling(window=length).apply(
        lambda prices: np.dot(prices, np.arange(1, length + 1)) / np.arange(1, length + 1).sum(), 
        raw=True
    )
    df_copy['vwma'] = (
        (df_copy[src] * df_copy['volume']).rolling(window=length).sum() 
        / df_copy['volume'].rolling(window=length).sum()
    )

    # Calculate Hull Moving Average (HMA)
    half_length = int(length / 2)
    sqrt_length = int(np.sqrt(length))
    df_copy['hma'] = df_copy[src].rolling(window=half_length).mean()
    df_copy['hma'] = 2 * df_copy['hma'] - df_copy[src].rolling(window=length).mean()
    df_copy['hma'] = df_copy['hma'].rolling(window=sqrt_length).mean()

    # Select the appropriate moving average
    if matype == 1:
        df_copy['avgval'] = df_copy['sma']
    elif matype == 2:
        df_copy['avgval'] = df_copy['ema']
    elif matype == 3:
        df_copy['avgval'] = df_copy['hma']
    elif matype == 4:
        df_copy['avgval'] = df_copy['wma']
    elif matype == 5:
        df_copy['avgval'] = df_copy['vwma']
    else:
        raise ValueError("Invalid moving average type. Choose a value between 1 and 5.")

    # Initialize the streak columns
    df_copy['upcount'] = 0
    df_copy['dncount'] = 0
    df_copy['ma_streak'] = 0

    # Calculate the streak
    for i in range(1, len(df_copy)):
        if df_copy['avgval'].iloc[i] > df_copy['avgval'].iloc[i - 1]:
            df_copy.at[i, 'upcount'] = df_copy.at[i - 1, 'upcount'] + 1
            df_copy.at[i, 'dncount'] = 0
        elif df_copy['avgval'].iloc[i] < df_copy['avgval'].iloc[i - 1]:
            df_copy.at[i, 'dncount'] = df_copy.at[i - 1, 'dncount'] - 1
            df_copy.at[i, 'upcount'] = 0
        df_copy.at[i, 'ma_streak'] = df_copy.at[i, 'upcount'] + df_copy.at[i, 'dncount']

    return df_copy[['ma_streak']]


def percentage_price_oscillator(
    df: pd.DataFrame,
    close_col: str = 'close',
    window_slow: int = 26,
    window_fast: int = 12,
    window_sign: int = 9,
    fillna: bool = False
) -> pd.DataFrame:
    """
    Percentage Price Oscillator (PPO) Combined Function

    This function calculates and returns the PPO, PPO Signal, and PPO Histogram values.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the close column.
    - close_col (str): Name of the column containing close price data. Default is 'close'.
    - window_slow (int): n period long-term. Default is 26.
    - window_fast (int): n period short-term. Default is 12.
    - window_sign (int): n period to signal. Default is 9.
    - fillna (bool): if True, fill nan values. Default is False.

    Call with:
        ppo = bta.percentage_price_oscillator(df)
        df['ppo'] = ppo['ppo']
        df['ppo_signal'] = ppo['ppo_signal']
        df['ppo_hist'] = ppo['ppo_hist']

    Returns:
    - pd.DataFrame: DataFrame with columns ['ppo', 'ppo_signal', 'ppo_hist'].
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required column
    if close_col not in df.columns:
        raise KeyError(f"DataFrame must contain '{close_col}' column")

    close = df_copy[close_col]

    # Calculate EMA
    emafast = close.ewm(span=window_fast, adjust=False).mean()
    emaslow = close.ewm(span=window_slow, adjust=False).mean()
    ppo = ((emafast - emaslow) / emaslow) * 100

    ppo_signal = ppo.ewm(span=window_sign, adjust=False).mean()
    ppo_hist = ppo - ppo_signal

    if fillna:
        ppo = ppo.fillna(0)
        ppo_signal = ppo_signal.fillna(0)
        ppo_hist = ppo_hist.fillna(0)

    df_copy['ppo'] = ppo
    df_copy['ppo_signal'] = ppo_signal
    df_copy['ppo_hist'] = ppo_hist

    return df_copy[['ppo', 'ppo_signal', 'ppo_hist']]


def percentage_volume_oscillator(
    df: pd.DataFrame,
    volume_col: str = 'volume',
    window_slow: int = 26,
    window_fast: int = 12,
    window_sign: int = 9,
    fillna: bool = False
) -> pd.DataFrame:
    """
    Percentage Volume Oscillator (PVO) Combined Function
    
    This function calculates and returns the PVO, PVO Signal, and PVO Histogram values.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the volume column.
    - volume_col (str): Name of the column containing volume data. Default is 'volume'.
    - window_slow (int): n period long-term. Default is 26.
    - window_fast (int): n period short-term. Default is 12.
    - window_sign (int): n period to signal. Default is 9.
    - fillna (bool): if True, fill nan values. Default is False.

    Call with:
        pvo = bta.percentage_volume_oscillator(df)
        df['pvo'] = pvo['pvo']
        df['pvo_signal'] = pvo['pvo_signal']
        df['pvo_hist'] = pvo['pvo_hist']

    Returns:
    - pd.DataFrame: DataFrame with columns ['pvo', 'pvo_signal', 'pvo_hist'].
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required column
    if volume_col not in df.columns:
        raise KeyError(f"DataFrame must contain '{volume_col}' column")

    volume = df_copy[volume_col]

    # Calculate EMA
    emafast = volume.ewm(span=window_fast, adjust=False).mean()
    emaslow = volume.ewm(span=window_slow, adjust=False).mean()
    pvo = ((emafast - emaslow) / emaslow) * 100

    pvo_signal = pvo.ewm(span=window_sign, adjust=False).mean()
    pvo_hist = pvo - pvo_signal

    if fillna:
        pvo = pvo.fillna(0)
        pvo_signal = pvo_signal.fillna(0)
        pvo_hist = pvo_hist.fillna(0)

    df_copy['pvo'] = pvo
    df_copy['pvo_signal'] = pvo_signal
    df_copy['pvo_hist'] = pvo_hist

    return df_copy[['pvo', 'pvo_signal', 'pvo_hist']]


def relative_momentum_index(df: pd.DataFrame, length: int = 20, mom: int = 5) -> pd.DataFrame:
    """
    Relative Momentum Index (RMI)

    The Relative Momentum Index (RMI) is an oscillator that applies the RSI formula 
    to momentum rather than price.

    Source: 
    https://www.tradingview.com/script/DdT7MmPa/ 
    https://github.com/freqtrade/technical/blob/master/technical/indicators/indicators.py#L912  

    Parameters:
    - df (pd.DataFrame): DataFrame containing the data.
    - length (int): Period for the EMA calculation. Default is 20.
    - mom (int): Momentum period. Default is 5.

    Call with:
        df['rmi'] = bta.relative_momentum_index(df, length=20, mom=5)['rmi']

    Returns:
    - pd.DataFrame: DataFrame with 'rmi' column.
    """
    df_copy = df.copy()

    # Calculate the momentum up and down changes
    df_copy['maxup'] = (df_copy['close'] - df_copy['close'].shift(mom)).clip(lower=0)
    df_copy['maxdown'] = (df_copy['close'].shift(mom) - df_copy['close']).clip(lower=0)
    
    df_copy.fillna(0, inplace=True)
    
    # Calculate the EMA of increases and decreases
    df_copy["ema_inc"] = exponential_moving_average(df_copy, column='maxup', period=length)
    df_copy["ema_dec"] = exponential_moving_average(df_copy, column='maxdown', period=length)
    
    # Calculate the Relative Momentum Index (RMI)
    df_copy['rmi'] = np.where(
        df_copy['ema_dec'] == 0, 
        0, 
        100 - 100 / (1 + df_copy["ema_inc"] / df_copy["ema_dec"])
    )

    return df_copy[['rmi']]


def rate_of_change(df: pd.DataFrame, column: str = 'close', period: int = 21) -> pd.DataFrame:
    """
    Rate of Change (ROC)

    The Rate of Change (ROC) is a momentum oscillator that measures the percentage 
    change in price between the current price and the price n periods ago.

    Parameters:
    - df (pd.DataFrame): DataFrame containing the data.
    - column (str): The column name on which the ROC is to be applied. Default is 'close'.
    - period (int): Period for the ROC calculation. Default is 21.

    Call with:
        df['roc'] = bta.rate_of_change(df, column='close', period=21)['roc']

    Returns:
    - pd.DataFrame: DataFrame with 'roc' column.
    """
    df_copy = df.copy()

    df_copy['roc'] = df_copy[column].diff(period) / df_copy[column].shift(period) * 100
    
    return df_copy[['roc']]


def smoothed_rate_of_change(
    df: pd.DataFrame, 
    roclen: int = 21, 
    emalen: int = 13, 
    smooth: int = 21
) -> pd.DataFrame:
    """
    Smoothed Rate of Change (SROC)

    The Smoothed Rate of Change (SROC) is a momentum oscillator that applies 
    an exponential moving average (EMA) to the Rate of Change (ROC) to smooth 
    out short-term fluctuations.

    Parameters:
    - df (pd.DataFrame): DataFrame containing the data.
    - roclen (int): Period for the ROC calculation. Default is 21.
    - emalen (int): Period for the EMA calculation. Default is 13.
    - smooth (int): Smoothing period for the ROC calculation. Default is 21.

    Call with:
        df['sroc'] = bta.smoothed_rate_of_change(df, roclen=21, emalen=13, smooth=21)['sroc']

    Returns:
    - pd.DataFrame: DataFrame with 'sroc' column.
    """
    df_copy = df.copy()

    # Calculate ROC
    roc = df_copy['close'].diff(roclen) / df_copy['close'].shift(roclen) * 100

    # Calculate EMA of the close price
    ema = df_copy['close'].ewm(span=emalen, adjust=False).mean()

    # Calculate SROC
    sroc = ema.diff(smooth) / ema.shift(smooth) * 100

    df_copy['sroc'] = sroc
    
    return df_copy[['sroc']]


def waddah_attar_explosion_atr(
    df: pd.DataFrame,
    sensitivity: int = 150,
    fast_length: int = 20,
    slow_length: int = 40,
    channel_length: int = 20,
    mult: float = 2.0
) -> pd.DataFrame:
    """
    Waddah Attar Explosion Indicator

    The Waddah Attar Explosion indicator is used to identify potential breakout 
    opportunities by combining the MACD and Bollinger Bands. The dead zone line 
    is based on ATR in this indicator.

    Inspired by: https://www.tradingview.com/script/d9IjcYyS-Waddah-Attar-Explosion-V2-SHK/

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain columns: 'open', 'high', 'low', and 'close'.
    - sensitivity (int): Sensitivity factor for the indicator. Default is 150.
    - fast_length (int): Length for the fast EMA. Default is 20.
    - slow_length (int): Length for the slow EMA. Default is 40.
    - channel_length (int): Length for the Bollinger Bands. Default is 20.
    - mult (float): Standard deviation multiplier for the Bollinger Bands. Default is 2.0.

    Call with:
        wae = bta.waddah_attar_explosion_atr(df)
        df['trend_up'] = wae['trend_up']
        df['trend_down'] = wae['trend_down']
        df['explosion_line'] = wae['explosion_line']
        df['dead_zone_line'] = wae['dead_zone_line']

    Returns:
    - pd.DataFrame: DataFrame with 'trend_up', 'trend_down', 'explosion_line', and 'dead_zone_line' columns.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['open', 'high', 'low', 'close']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # Calculate EMA
    def calculate_ema(series, period):
        return series.ewm(span=period, adjust=False).mean()
    
    # Calculate RMA
    def calculate_rma(series, period):
        return series.ewm(alpha=1 / period, adjust=False).mean()

    # Calculate DEAD_ZONE
    true_range = pd.DataFrame({
        'high_low': df['high'] - df['low'],
        'high_close': (df['high'] - df['close'].shift()).abs(),
        'low_close': (df['low'] - df['close'].shift()).abs()
    })
    true_range['true_range'] = true_range[['high_low', 'high_close', 'low_close']].max(axis=1)
    dead_zone = calculate_rma(true_range['true_range'], 100) * 3.7

    # Calculate MACD
    macd_fast = calculate_ema(df['close'], fast_length)
    macd_slow = calculate_ema(df['close'], slow_length)
    macd_diff = macd_fast - macd_slow
    t1 = (macd_diff - macd_diff.shift(1)) * sensitivity

    # Calculate Bollinger Bands
    bb = bollinger_bands(df, column='close', period=channel_length, std_dev=mult)
    e1 = bb['bb_upper'] - bb['bb_lower']

    trend_up = np.where(t1 >= 0, t1, 0)
    trend_down = np.where(t1 < 0, -t1, 0)

    df_copy['trend_up'] = trend_up
    df_copy['trend_down'] = trend_down
    df_copy['explosion_line'] = e1
    df_copy['dead_zone_line'] = dead_zone.values

    return df_copy[['trend_up', 'trend_down', 'explosion_line', 'dead_zone_line']]


def waddah_attar_explosion(
    df: pd.DataFrame,
    sensitivity: int = 150,
    fast_length: int = 20,
    slow_length: int = 40,
    channel_length: int = 20,
    dead_zone: int = 20,
    mult: float = 2.0
) -> pd.DataFrame:
    """
    Waddah Attar Explosion Indicator

    The Waddah Attar Explosion indicator is used to identify potential breakout 
    opportunities by combining the MACD and Bollinger Bands.

    Inspired by: https://www.tradingview.com/script/iu3kKWDI-Waddah-Attar-Explosion-LazyBear/

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain columns: 'open', 'high', 'low', and 'close'.
    - sensitivity (int): Sensitivity factor for the indicator. Default is 150.
    - fast_length (int): Length for the fast EMA. Default is 20.
    - slow_length (int): Length for the slow EMA. Default is 40.
    - channel_length (int): Length for the Bollinger Bands. Default is 20.
    - dead_zone (int): Dead zone factor for the indicator. Default is 20.
    - mult (float): Standard deviation multiplier for the Bollinger Bands. Default is 2.0.

    Call with:
        wae = bta.waddah_attar_explosion(df)
        df['trend_up'] = wae['trend_up']
        df['trend_down'] = wae['trend_down']
        df['explosion_line'] = wae['explosion_line']
        df['dead_zone_line'] = wae['dead_zone_line']

    Returns:
    - pd.DataFrame: DataFrame with 'trend_up', 'trend_down', 'explosion_line', and 'dead_zone_line' columns.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['open', 'high', 'low', 'close']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # Calculate EMA
    def calculate_ema(series, period):
        return series.ewm(span=period, adjust=False).mean()
    
    # Calculate MACD
    macd_fast = calculate_ema(df['close'], fast_length)
    macd_slow = calculate_ema(df['close'], slow_length)
    macd_diff = macd_fast - macd_slow
    t1 = (macd_diff - macd_diff.shift(1)) * sensitivity

    # Calculate Bollinger Bands
    bb = bollinger_bands(df, column='close', period=channel_length, std_dev=mult)
    e1 = bb['bb_upper'] - bb['bb_lower']

    trend_up = np.where(t1 >= 0, t1, 0)
    trend_down = np.where(t1 < 0, -t1, 0)

    df_copy['trend_up'] = trend_up
    df_copy['trend_down'] = trend_down
    df_copy['explosion_line'] = e1
    df_copy['dead_zone_line'] = dead_zone

    return df_copy[['trend_up', 'trend_down', 'explosion_line', 'dead_zone_line']]


def wave_trend(df: pd.DataFrame, chlen: int = 10, avg: int = 21, smalen: int = 4) -> pd.DataFrame:
    """
    WaveTrend

    The WaveTrend is used to identify overbought and oversold conditions in the market.

    Inspired by:  
    https://www.tradingview.com/script/2KE8wTuF-Indicator-WaveTrend-Oscillator-WT/ 
    and: https://www.tradingview.com/script/jFQn4jYZ-WaveTrend-with-Crosses-LazyBear/
    
    Parameters:
    - df (pd.DataFrame): DataFrame containing the data.
    - chlen (int): Channel length for the EMA calculation. Default is 10.
    - avg (int): Average period for the EMA calculation. Default is 21.
    - smalen (int): Period for the SMA calculation. Default is 4.

    Call with:
        wt = bta.wave_trend(df, chlen=10, avg=21, smalen=4)
        df['wt1'] = wt['wt1']
        df['wt2'] = wt['wt2']

    Returns:
    - pd.DataFrame: DataFrame with 'wt1' and 'wt2' columns.
    """
    df_copy = df.copy()

    df_copy['hlc3'] = (df_copy['high'] + df_copy['low'] + df_copy['close']) / 3
    df_copy['esa'] = exponential_moving_average(df_copy, column='hlc3', period=chlen)
    df_copy['abs_diff'] = (df_copy['hlc3'] - df_copy['esa']).abs()
    df_copy['d'] = exponential_moving_average(df_copy, column='abs_diff', period=chlen)
    df_copy['ci'] = (df_copy['hlc3'] - df_copy['esa']) / (0.015 * df_copy['d'])
    df_copy['tci'] = exponential_moving_average(df_copy, column='ci', period=avg)
    df_copy['wt1'] = df_copy['tci']
    df_copy['wt2'] = simple_moving_average(df_copy, column='wt1', period=smalen)

    return df_copy[['wt1', 'wt2']]


def wave_trend_oscillator(
    df: pd.DataFrame, 
    src: str = 'close', 
    n1: int = 8, 
    n2: int = 12
) -> pd.DataFrame:
    """
    WaveTrend Oscillator

    The WaveTrend Oscillator is used to identify overbought and oversold conditions 
    in the market.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the source column.
    - src (str): The column to use for calculations. Default is 'close'.
    - n1 (int): Length for the first EMA. Default is 8.
    - n2 (int): Length for the second EMA. Default is 12.

    Call with:
        df['wto'] = bta.wave_trend_oscillator(df, 'close')['wavetrend']

    Returns:
    - pd.DataFrame: DataFrame with 'wavetrend' column.
    """
    df_copy = df.copy()

    src_series = df[src]
    ema_src = exponential_moving_average(df, column=src, period=n1)['ema']
    diff_series = np.abs(src_series - ema_src)
    d = exponential_moving_average(pd.DataFrame({'diff': diff_series}), column='diff', period=n1)['ema']
    ci = (src_series - ema_src) / (0.015 * d)
    tci = exponential_moving_average(pd.DataFrame({'ci': ci}), column='ci', period=n2)['ema']
    wavetrend = tci - simple_moving_average(pd.DataFrame({'tci': tci}), column='tci', period=4)['sma']

    df_copy['wavetrend'] = wavetrend
    
    return df_copy[['wavetrend']]


def qqe_mod(
    df: pd.DataFrame, 
    rsi_period: int = 6, 
    rsi_smoothing: int = 5, 
    qqe_factor: int = 3, 
    threshold: int = 3, 
    bollinger_length: int = 50, 
    bb_multiplier: float = 0.35, 
    rsi_period2: int = 6, 
    rsi_smoothing2: int = 5, 
    qqe_factor2: float = 1.61, 
    threshold2: int = 3
) -> pd.DataFrame:
    """
    QQE Mod Indicator

    The QQE (Quantitative Qualitative Estimation) is a technical analysis indicator 
    that combines the Relative Strength Index (RSI) with a smoothing technique to 
    generate buy and sell signals. The QQE indicator helps traders identify trends, 
    potential breakouts, and changes in market momentum by providing an enhanced 
    visualization of the underlying price dynamics.

    Inspired by: https://www.tradingview.com/script/TpUW4muw-QQE-MOD/

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain a 'close' column.
    - rsi_period (int): Period for RSI calculation. Default is 6.
    - rsi_smoothing (int): Smoothing period for RSI. Default is 5.
    - qqe_factor (int): Fast QQE Factor. Default is 3.
    - threshold (int): Threshold value. Default is 3.
    - bollinger_length (int): Length for Bollinger Bands calculation. Default is 50.
    - bb_multiplier (float): Multiplier for Bollinger Bands. Default is 0.35.
    - rsi_period2 (int): Period for the second RSI calculation. Default is 6.
    - rsi_smoothing2 (int): Smoothing period for the second RSI. Default is 5.
    - qqe_factor2 (float): Fast QQE Factor for the second QQE. Default is 1.61.
    - threshold2 (int): Threshold value for the second QQE. Default is 3.

    Call with:
        qqe_mod = bta.qqe_mod(df, 6, 5, 3, 3, 50, 0.35, 6, 5, 1.61, 3)
        df['qqe_line'] = qqe_mod['qqe_line']
        df['histo2'] = qqe_mod['histo2']
        df['qqe_up'] = qqe_mod['qqe_up']
        df['qqe_down'] = qqe_mod['qqe_down']

    Returns:
    - pd.DataFrame: DataFrame with 'qqe_line', 'histo2', 'qqe_up', and 'qqe_down' columns.
    """
    
    def wilders_ema(series, period):
        return series.ewm(alpha=1 / period, adjust=False).mean()

    df_copy = df.copy()

    # First QQE Calculation
    src = df_copy['close']
    wilders_period = rsi_period * 2 - 1

    rsi = relative_strength_index(df_copy, column='close', period=rsi_period)
    rsi_ma = exponential_moving_average(df_copy.assign(rsi=rsi), column='rsi', period=rsi_smoothing)['ema']
    atr_rsi = abs(rsi_ma.shift(1) - rsi_ma)
    ma_atr_rsi = wilders_ema(atr_rsi, wilders_period)
    dar = wilders_ema(ma_atr_rsi, wilders_period) * qqe_factor

    longband = np.zeros(len(df_copy))
    shortband = np.zeros(len(df_copy))
    trend = np.zeros(len(df_copy))

    delta_fast_atr_rsi = dar
    rsindex = rsi_ma
    newshortband = rsindex + delta_fast_atr_rsi
    newlongband = rsindex - delta_fast_atr_rsi

    for i in range(1, len(df_copy)):
        if rsindex.iloc[i - 1] > longband[i - 1] and rsindex.iloc[i] > longband[i - 1]:
            longband[i] = max(longband[i - 1], newlongband.iloc[i])
        else:
            longband[i] = newlongband.iloc[i]

        if rsindex.iloc[i - 1] < shortband[i - 1] and rsindex.iloc[i] < shortband[i - 1]:
            shortband[i] = min(shortband[i - 1], newshortband.iloc[i])
        else:
            shortband[i] = newshortband.iloc[i]

        cross_1 = (longband[i - 1] > rsindex.iloc[i]) and (longband[i - 1] <= rsindex.iloc[i - 1])
        if rsindex.iloc[i] > shortband[i - 1]:
            trend[i] = 1
        elif cross_1:
            trend[i] = -1
        else:
            trend[i] = trend[i - 1]

    fast_atr_rsi_tl = np.where(trend == 1, longband, shortband)

    # Bollinger Bands on FastATRRSI TL
    basis = simple_moving_average(pd.DataFrame(fast_atr_rsi_tl - 50), column=0, period=bollinger_length)['sma']
    dev = bb_multiplier * (pd.Series(fast_atr_rsi_tl - 50).rolling(window=bollinger_length).std())
    upper = basis + dev
    lower = basis - dev

    # Second QQE Calculation
    wilders_period2 = rsi_period2 * 2 - 1

    rsi2 = relative_strength_index(df_copy, column='close', period=rsi_period2)
    rsi_ma2 = exponential_moving_average(df_copy.assign(rsi2=rsi2), column='rsi2', period=rsi_smoothing2)['ema']
    atr_rsi2 = abs(rsi_ma2.shift(1) - rsi_ma2)
    ma_atr_rsi2 = wilders_ema(atr_rsi2, wilders_period2)
    dar2 = wilders_ema(ma_atr_rsi2, wilders_period2) * qqe_factor2

    longband2 = np.zeros(len(df_copy))
    shortband2 = np.zeros(len(df_copy))
    trend2 = np.zeros(len(df_copy))

    delta_fast_atr_rsi2 = dar2
    rsindex2 = rsi_ma2
    newshortband2 = rsindex2 + delta_fast_atr_rsi2
    newlongband2 = rsindex2 - delta_fast_atr_rsi2

    for i in range(1, len(df_copy)):
        if rsindex2.iloc[i - 1] > longband2[i - 1] and rsindex2.iloc[i] > longband2[i - 1]:
            longband2[i] = max(longband2[i - 1], newlongband2.iloc[i])
        else:
            longband2[i] = newlongband2.iloc[i]

        if rsindex2.iloc[i - 1] < shortband2[i - 1] and rsindex2.iloc[i] < shortband2[i - 1]:
            shortband2[i] = min(shortband2[i - 1], newshortband2.iloc[i])
        else:
            shortband2[i] = newshortband2.iloc[i]

        cross_2 = (longband2[i - 1] > rsindex2.iloc[i]) and (longband2[i - 1] <= rsindex2.iloc[i - 1])
        if rsindex2.iloc[i] > shortband2[i - 1]:
            trend2[i] = 1
        elif cross_2:
            trend2[i] = -1
        else:
            trend2[i] = trend2[i - 1]

    fast_atr_rsi2_tl = np.where(trend2 == 1, longband2, shortband2)

    df_copy['qqe_line'] = (fast_atr_rsi2_tl - 50)
    df_copy['histo2'] = (rsi_ma2 - 50)

    greenbar1 = rsi_ma2 - 50 > threshold2
    greenbar2 = rsi_ma - 50 > upper

    redbar1 = rsi_ma2 - 50 < -threshold2
    redbar2 = rsi_ma - 50 < lower

    df_copy['qqe_up'] = np.where(greenbar1 & greenbar2, rsi_ma2 - 50, np.nan)
    df_copy['qqe_down'] = np.where(redbar1 & redbar2, rsi_ma2 - 50, np.nan)

    return df_copy[['qqe_line', 'histo2', 'qqe_up', 'qqe_down']]


def relative_strength_index(df: pd.DataFrame, column: str = 'close', period: int = 14) -> pd.DataFrame:
    """
    Relative Strength Index (RSI)

    RSI measures the magnitude of recent price changes to evaluate overbought or oversold 
    conditions in the price of a stock or other asset.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the column specified.
    - column (str): The column on which RSI is to be calculated. Default is "close".
    - period (int): The period over which RSI is to be calculated. Default is 14.

    Call with:
        df['rsi'] = bta.relative_strength_index(df, column='close', period=14)['rsi']

    Returns:
    - pd.DataFrame: DataFrame with 'rsi' column.
    """
    df_copy = df.copy()

    delta = df_copy[column].diff(1)
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)

    avg_gain = gain.rolling(window=period, min_periods=1).mean()
    avg_loss = loss.rolling(window=period, min_periods=1).mean()

    # Apply the Wilder's smoothing technique for gain and loss averages
    for i in range(period, len(df_copy)):
        avg_gain.iloc[i] = (avg_gain.iloc[i - 1] * (period - 1) + gain.iloc[i]) / period
        avg_loss.iloc[i] = (avg_loss.iloc[i - 1] * (period - 1) + loss.iloc[i]) / period

    rs = avg_gain / avg_loss
    rsi = 100 - (100 / (1 + rs))

    df_copy['rsi'] = rsi

    return df_copy[['rsi']]


def stochastic_momentum_index(df: pd.DataFrame, k_length: int = 9, d_length: int = 3) -> pd.DataFrame:
    """
    The Stochastic Momentum Index (SMI) Indicator

    The Stochastic Momentum Index (SMI) Indicator was developed by William Blau 
    in 1993 and is considered to be a momentum indicator that can help identify 
    trend reversal points.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'high', 'low', and 'close' columns.
    - k_length (int): Period for %K. Default is 9.
    - d_length (int): Period for %D. Default is 3.

    Call with:
        df['smi'] = bta.stochastic_momentum_index(df, k_length=9, d_length=3)['smi']

    Returns:
    - pd.DataFrame: DataFrame with 'smi' column populated.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['high', 'low', 'close']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    ll = df_copy['low'].rolling(window=k_length).min()
    hh = df_copy['high'].rolling(window=k_length).max()

    diff = hh - ll
    rdiff = df_copy['close'] - (hh + ll) / 2

    avgrel = rdiff.ewm(span=d_length).mean().ewm(span=d_length).mean()
    avgdiff = diff.ewm(span=d_length).mean().ewm(span=d_length).mean()

    df_copy['smi'] = np.where(avgdiff != 0, (avgrel / (avgdiff / 2) * 100), 0)

    return df_copy[['smi']]


def stochastics_oscillator(
    df: pd.DataFrame,
    high_col: str = 'high',
    low_col: str = 'low',
    close_col: str = 'close',
    window: int = 14,
    smooth_window: int = 3,
    fillna: bool = False
) -> pd.DataFrame:
    """
    Stochastic Oscillator, Stochastic Signal, and Histogram Combined.

    The Stochastic Oscillator is a momentum indicator comparing a particular 
    closing price of a security to a range of its prices over a certain period of time.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame.
    - high_col (str): Column name for 'High' prices. Default is 'high'.
    - low_col (str): Column name for 'Low' prices. Default is 'low'.
    - close_col (str): Column name for 'Close' prices. Default is 'close'.
    - window (int): Lookback period for stochastic calculation. Default is 14.
    - smooth_window (int): Lookback period for signal calculation. Default is 3.
    - fillna (bool): If True, fill nan values. Default is False.

    Call with:
        stoch = bta.stochastics_oscillator(df, 'high', 'low', 'close', 14, 3)
        df['stoch'] = stoch['stoch']
        df['stoch_signal'] = stoch['stoch_signal']
        df['stoch_hist'] = stoch['stoch_hist']

    Returns:
    - pd.DataFrame: DataFrame with 'stoch', 'stoch_signal', and 'stoch_hist' columns.
    """
    df_copy = df.copy()

    high = df_copy[high_col]
    low = df_copy[low_col]
    close = df_copy[close_col]

    min_periods = 0 if fillna else window
    smin = low.rolling(window, min_periods=min_periods).min()
    smax = high.rolling(window, min_periods=min_periods).max()
    stoch_k = 100 * (close - smin) / (smax - smin)
    if fillna:
        stoch_k = stoch_k.fillna(50)

    min_periods = 0 if fillna else smooth_window
    stoch_d = stoch_k.rolling(smooth_window, min_periods=min_periods).mean()
    if fillna:
        stoch_d = stoch_d.fillna(50)

    stoch_hist = stoch_k - stoch_d
    if fillna:
        stoch_hist = stoch_hist.fillna(0)

    df_copy['stoch'] = stoch_k
    df_copy['stoch_signal'] = stoch_d
    df_copy['stoch_hist'] = stoch_hist

    return df_copy[['stoch', 'stoch_signal', 'stoch_hist']]


def stochastic_rsi(
    df: pd.DataFrame, 
    length_rsi: int = 14, 
    length_stoch: int = 14, 
    smooth_k: int = 3, 
    smooth_d: int = 3
) -> pd.DataFrame:
    """
    Stochastic RSI (StochasticRSI)
    
    The Stochastic RSI is used to identify overbought and oversold conditions in the market.
    
    Parameters:
    - df (pd.DataFrame): DataFrame containing the data with a 'close' column.
    - length_rsi (int): Period for the RSI calculation. Default is 14.
    - length_stoch (int): Period for the Stochastic calculation. Default is 14.
    - smooth_k (int): Smoothing period for %K line. Default is 3.
    - smooth_d (int): Smoothing period for %D line. Default is 3.
    
    Call with:
        stoch_rsi = bta.stochastic_rsi(df, length_rsi=14, length_stoch=14, smooth_k=3, smooth_d=3)
        df['stoch_rsi_k'] = stoch_rsi['stoch_rsi_k']
        df['stoch_rsi_d'] = stoch_rsi['stoch_rsi_d']
    
    Returns:
    - pd.DataFrame: DataFrame with 'stoch_rsi_k' and 'stoch_rsi_d' columns.
    """
    df_copy = df.copy()
    
    # Step 1: Calculate RSI
    delta = df_copy['close'].diff()
    gain = delta.where(delta > 0, 0).rolling(window=length_rsi).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=length_rsi).mean()
    rs = gain / loss
    df_copy['rsi'] = 100 - (100 / (1 + rs))
    
    # Step 2: Calculate the Stochastic Oscillator on RSI
    df_copy['min_rsi'] = df_copy['rsi'].rolling(window=length_stoch).min()
    df_copy['max_rsi'] = df_copy['rsi'].rolling(window=length_stoch).max()
    df_copy['stoch_rsi'] = (df_copy['rsi'] - df_copy['min_rsi']) / (df_copy['max_rsi'] - df_copy['min_rsi']) * 100
    
    # Step 3: Smooth the Stochastic RSI values
    df_copy['stoch_rsi_k'] = df_copy['stoch_rsi'].rolling(window=smooth_k).mean()
    df_copy['stoch_rsi_d'] = df_copy['stoch_rsi_k'].rolling(window=smooth_d).mean()
    
    return df_copy[['stoch_rsi_k', 'stoch_rsi_d']]


def true_strength_index(
    df: pd.DataFrame, 
    close_col: str = 'close', 
    window_slow: int = 25, 
    window_fast: int = 13, 
    fillna: bool = False
) -> pd.DataFrame:
    """
    True Strength Index (TSI)

    The True Strength Index (TSI) shows both trend direction and overbought/oversold conditions.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the close column.
    - close_col (str): Name of the column containing close price data. Default is 'close'.
    - window_slow (int): High period. Default is 25.
    - window_fast (int): Low period. Default is 13.
    - fillna (bool): If True, fill nan values. Default is False.

    Call with:
        df['tsi'] = bta.true_strength_index(df, 'close', 25, 13)['tsi']

    Returns:
    - pd.DataFrame: DataFrame with 'tsi' column.
    """
    df_copy = df.copy()

    diff_close = df_copy[close_col] - df_copy[close_col].shift(1)
    min_periods_r = 0 if fillna else window_slow
    min_periods_s = 0 if fillna else window_fast
    
    smoothed = (
        diff_close.ewm(span=window_slow, min_periods=min_periods_r, adjust=False)
        .mean()
        .ewm(span=window_fast, min_periods=min_periods_s, adjust=False)
        .mean()
    )
    smoothed_abs = (
        abs(diff_close)
        .ewm(span=window_slow, min_periods=min_periods_r, adjust=False)
        .mean()
        .ewm(span=window_fast, min_periods=min_periods_s, adjust=False)
        .mean()
    )
    
    tsi = smoothed / smoothed_abs * 100
    if fillna:
        tsi = tsi.fillna(0)

    df_copy['tsi'] = tsi

    return df_copy[['tsi']]


def ultimate_oscillator(
    df: pd.DataFrame,
    high_col: str = 'high',
    low_col: str = 'low',
    close_col: str = 'close',
    window1: int = 7,
    window2: int = 14,
    window3: int = 28,
    weight1: float = 4.0,
    weight2: float = 2.0,
    weight3: float = 1.0,
    fillna: bool = False,
) -> pd.DataFrame:
    """
    Ultimate Oscillator

    The Ultimate Oscillator combines short-term, intermediate-term, and long-term 
    price action into one oscillator.

    Parameters:
    - df (pandas.DataFrame): DataFrame containing the data.
    - high_col (str): Name of the column containing high price data. Default is 'high'.
    - low_col (str): Name of the column containing low price data. Default is 'low'.
    - close_col (str): Name of the column containing close price data. Default is 'close'.
    - window1 (int): Short period. Default is 7.
    - window2 (int): Medium period. Default is 14.
    - window3 (int): Long period. Default is 28.
    - weight1 (float): Weight of short BP average for UO. Default is 4.0.
    - weight2 (float): Weight of medium BP average for UO. Default is 2.0.
    - weight3 (float): Weight of long BP average for UO. Default is 1.0.
    - fillna (bool): If True, fill nan values. Default is False.

    Call with:
        df['uo'] = bta.ultimate_oscillator(df, 'high', 'low', 'close', 7, 14, 28)['uo']

    Returns:
    - pd.DataFrame: DataFrame with 'uo' column.
    """
    df_copy = df.copy()

    close_shift = df_copy[close_col].shift(1)
    true_range = np.maximum(df_copy[high_col], close_shift) - np.minimum(df_copy[low_col], close_shift)
    buying_pressure = df_copy[close_col] - np.minimum(df_copy[low_col], close_shift)

    min_periods_s = 0 if fillna else window1
    min_periods_m = 0 if fillna else window2
    min_periods_l = 0 if fillna else window3

    avg_s = (buying_pressure.rolling(window1, min_periods=min_periods_s).sum() /
             true_range.rolling(window1, min_periods=min_periods_s).sum())
    avg_m = (buying_pressure.rolling(window2, min_periods=min_periods_m).sum() /
             true_range.rolling(window2, min_periods=min_periods_m).sum())
    avg_l = (buying_pressure.rolling(window3, min_periods=min_periods_l).sum() /
             true_range.rolling(window3, min_periods=min_periods_l).sum())

    uo = 100.0 * ((weight1 * avg_s) + (weight2 * avg_m) + (weight3 * avg_l)) / (weight1 + weight2 + weight3)
    
    if fillna:
        uo = uo.fillna(50)
    
    df_copy['uo'] = uo

    return df_copy[['uo']]


def williams_r(
    df: pd.DataFrame,
    high_col: str = 'high',
    low_col: str = 'low',
    close_col: str = 'close',
    lbp: int = 14,
    fillna: bool = False
) -> pd.DataFrame:
    """
    Williams %R

    The Williams %R is a momentum indicator that measures overbought and oversold levels.

    Inspired by: https://www.tradingview.com/script/REGZq58T-Williams-R/

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the high, low, and close columns.
    - high_col (str): Name of the column containing high price data. Default is 'high'.
    - low_col (str): Name of the column containing low price data. Default is 'low'.
    - close_col (str): Name of the column containing close price data. Default is 'close'.
    - lbp (int): Lookback period. Default is 14.
    - fillna (bool): If True, fill nan values. Default is False.

    Call with:
        df['williams_r'] = bta.williams_r(df, 'high', 'low', 'close', 14)['williams_r']

    Returns:
    - pd.DataFrame: DataFrame with 'williams_r' column.
    """
    df_copy = df.copy()

    min_periods = 0 if fillna else lbp
    highest_high = df_copy[high_col].rolling(lbp, min_periods=min_periods).max()
    lowest_low = df_copy[low_col].rolling(lbp, min_periods=min_periods).min()
    
    wr = -100 * (highest_high - df_copy[close_col]) / (highest_high - lowest_low)
    
    if fillna:
        wr = wr.fillna(-50)

    df_copy['williams_r'] = wr
    
    return df_copy[['williams_r']]

        ----- End of momentum.py -----

    docs/
        momentum.md

        ----- Start of momentum.md -----

# `momentum` - Technical Momentum Indicators

## Awesome Oscillator (AO)

### Description
The **Awesome Oscillator (AO)** is a momentum indicator used to measure market momentum by comparing the 5-period and 34-period simple moving averages (SMA) of the median price.

### Interpretation
- **AO** helps identify the strength of a market's trend. Positive values indicate bullish momentum, while negative values indicate bearish momentum.

### Usage Example
```python
df['ao'] = bta.awesome_oscillator(df, 'high', 'low', 5, 34)['ao']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the `high` and `low` columns.
- `high_col` (str): Column name for the high prices. Default is `'high'`.
- `low_col` (str): Column name for the low prices. Default is `'low'`.
- `window1` (int): Short period for the SMA. Default is `5`.
- `window2` (int): Long period for the SMA. Default is `34`.
- `fillna` (bool): If `True`, fills NaN values with `0`. Default is `False`.

### Returns
- **DataFrame**: A DataFrame with the `'ao'` column.

---

## Chande Momentum Oscillator (CMO)

### Description
The **Chande Momentum Oscillator (CMO)** measures the momentum of price changes over a specified period, developed by Tushar Chande.

### Interpretation
- **CMO** oscillates between -100 and 100. Positive values suggest upward momentum, while negative values suggest downward momentum.

### Usage Example
```python
df['cmo'] = bta.chande_momentum_oscillator(df)
df['cmo_signal'] = df['cmo'].rolling(window=10).mean()  # Using SMA for signal
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the `close` column.
- `length` (int): Lookback period for the CMO calculation. Default is `14`.

### Returns
- **DataFrame**: A DataFrame with the `'cmo'` column.

---

## Elliott Wave Oscillator (EWO)

### Description
The **Elliott Wave Oscillator (EWO)** is used to identify trends and market patterns. It is calculated as the difference between two simple moving averages (SMA), then normalized by the price.

### Interpretation
- **EWO** helps traders identify the direction of the trend based on the relationship between short-term and long-term moving averages.

### Usage Example
```python
df['ewo'] = bta.elliott_wave_oscillator(df, 'close', 5, 35)
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the specified column.
- `column` (str): The column on which EWO is calculated. Default is `'close'`.
- `sma1_period` (int): Short period for the SMA. Default is `5`.
- `sma2_period` (int): Long period for the SMA. Default is `35`.

### Returns
- **DataFrame**: A DataFrame with the `'ewo'` column.

---

## Ehlers Fisher Stochastic Center of Gravity Indicator

### Description
The **Fisher Stochastic Center of Gravity Indicator**, developed by John Ehlers, identifies potential market turning points by calculating the center of gravity of price movements.

### Interpretation
- **CG** values above zero may indicate overbought conditions, while values below zero may suggest oversold conditions.

### Usage Example
```python
fscg = bta.ehlers_fisher_stochastic_center_of_gravity(df)
df['cg'] = fscg['cg']
df['trigger'] = fscg['trigger']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing `high` and `low` columns.
- `length` (int): Lookback period for the indicator. Default is `8`.

### Returns
- **DataFrame**: A DataFrame with the `'cg'` and `'trigger'` columns.

---

## Kaufman's Adaptive Moving Average (KAMA)

### Description
The **Kaufman's Adaptive Moving Average (KAMA)** adjusts to market noise or volatility, closely following prices when price swings are small and adjusting when price swings widen.

### Interpretation
- **KAMA** helps identify the overall trend, time turning points, and filter price movements in volatile markets.

### Usage Example
```python
df['kama'] = bta.kaufmans_adaptive_moving_average(df)['kama']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the `close` column.
- `close_col` (str): Column name for the close prices. Default is `'close'`.
- `window` (int): Period for the efficiency ratio. Default is `14`.
- `pow1` (int): Period for the fastest EMA constant. Default is `2`.
- `pow2` (int): Period for the slowest EMA constant. Default is `30`.
- `fillna` (bool): If `True`, fills NaN values with the close prices. Default is `False`.

### Returns
- **DataFrame**: A DataFrame with the `'kama'` column.

Here is the extended documentation, including everything from the **MACD** function onward in the `momentum.py` module. The documentation follows the same format with descriptions, interpretations, usage examples, and parameter explanations.

---

## Moving Average Convergence Divergence (MACD)

### Description
The **MACD (Moving Average Convergence Divergence)** is a momentum indicator that shows the relationship between two moving averages of a security’s price. It is commonly used to spot trend direction and strength.

### Interpretation
- **MACD Line** (`macd`): The difference between the short-term and long-term EMAs. A positive value indicates bullish momentum, while a negative value suggests bearish momentum.
- **Signal Line** (`macd_signal`): A smoothed version of the MACD line, used to generate buy or sell signals.
- **MACD Histogram** (`macd_histogram`): The difference between the MACD line and the Signal line. Positive values suggest upward momentum, and negative values suggest downward momentum.

### Usage Example
```python
macd_result = bta.macd(df, 'close', 12, 26, 9)
df['macd'] = macd_result['macd']
df['macd_signal'] = macd_result['macd_signal']
df['macd_histogram'] = macd_result['macd_histogram']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the column to be used for calculation.
- `column` (str): The column on which MACD is to be calculated. Default is `'close'`.
- `short_window` (int): The short-term period for the EMA. Default is `12`.
- `long_window` (int): The long-term period for the EMA. Default is `26`.
- `signal_window` (int): The period for the signal EMA. Default is `9`.

### Returns
- **DataFrame**: A DataFrame with the `'macd'`, `'macd_signal'`, and `'macd_histogram'` columns.

---

## MACD Leader

### Description
The **MACD Leader** is a variation of the standard MACD that aims to provide an earlier signal using a different calculation method, focusing on faster reaction to market changes.

### Interpretation
- **MACD Leader** is used similarly to the standard MACD, but it attempts to signal trend changes earlier by using a different approach to EMA calculations.

### Usage Example
```python
df['macd_leader'] = bta.macd_leader(df, 'close')['macd_leader']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the source column.
- `src` (str): The column to use for calculations. Default is `'close'`.
- `fast_length` (int): Length for the fast EMA. Default is `12`.
- `slow_length` (int): Length for the slow EMA. Default is `26`.
- `signal_length` (int): Length for the signal EMA. Default is `9`.

### Returns
- **DataFrame**: A DataFrame with the `'macd_leader'` column.

---

## MA Streak Indicator

### Description
The **MA Streak Indicator** tracks the number of bars a given moving average is rising or falling, highlighting trends by color-coding them as positive (green) or negative (red).

### Interpretation
- **MA Streak** shows how long a moving average has been increasing or decreasing, helping to identify the strength and longevity of trends.

### Usage Example
```python
df['ma_streak'] = bta.ma_streak(df, length=10, src='close', matype=1)['ma_streak']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the data.
- `length` (int): Period for the moving average calculation. Default is `10`.
- `src` (str): The column name to use for the moving average calculation. Default is `'close'`.
- `matype` (int): Type of moving average to use. Options are:
  1 - SMA, 2 - EMA, 3 - HMA, 4 - WMA, 5 - VWMA. Default is `1`.

### Returns
- **DataFrame**: A DataFrame with the `'ma_streak'` column.

---

## Percentage Price Oscillator (PPO)

### Description
The **Percentage Price Oscillator (PPO)** is a momentum indicator similar to MACD, but it shows the percentage difference between two EMAs, which allows for better comparison across assets of varying prices.

### Interpretation
- **PPO** helps identify trend direction and momentum. The PPO histogram shows the difference between the PPO and the Signal line.

### Usage Example
```python
ppo = bta.percentage_price_oscillator(df)
df['ppo'] = ppo['ppo']
df['ppo_signal'] = ppo['ppo_signal']
df['ppo_hist'] = ppo['ppo_hist']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the close column.
- `close_col` (str): Column name for close prices. Default is `'close'`.
- `window_slow` (int): Long-term period for EMA. Default is `26`.
- `window_fast` (int): Short-term period for EMA. Default is `12`.
- `window_sign` (int): Period for the signal EMA. Default is `9`.
- `fillna` (bool): If `True`, fills NaN values with 0. Default is `False`.

### Returns
- **DataFrame**: A DataFrame with the `'ppo'`, `'ppo_signal'`, and `'ppo_hist'` columns.

---

## Percentage Volume Oscillator (PVO)

### Description
The **Percentage Volume Oscillator (PVO)** compares the percentage difference between two volume-based EMAs, helping identify trends in trading volume.

### Interpretation
- **PVO** is used to assess the strength of volume trends. A positive value suggests increased volume, while a negative value suggests lower volume.

### Usage Example
```python
pvo = bta.percentage_volume_oscillator(df)
df['pvo'] = pvo['pvo']
df['pvo_signal'] = pvo['pvo_signal']
df['pvo_hist'] = pvo['pvo_hist']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the volume column.
- `volume_col` (str): Column name for volume data. Default is `'volume'`.
- `window_slow` (int): Long-term period for EMA. Default is `26`.
- `window_fast` (int): Short-term period for EMA. Default is `12`.
- `window_sign` (int): Period for the signal EMA. Default is `9`.
- `fillna` (bool): If `True`, fills NaN values with 0. Default is `False`.

### Returns
- **DataFrame**: A DataFrame with the `'pvo'`, `'pvo_signal'`, and `'pvo_hist'` columns.

---

## Relative Momentum Index (RMI)

### Description
The **Relative Momentum Index (RMI)** applies the RSI formula to momentum rather than price, helping identify overbought or oversold conditions based on momentum.

### Interpretation
- **RMI** is similar to RSI but provides more sensitivity to momentum changes, making it useful for spotting potential trend reversals.

### Usage Example
```python
df['rmi'] = bta.relative_momentum_index(df, length=20, mom=5)['rmi']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the data.
- `length` (int): Period for the EMA calculation. Default is `20`.
- `mom` (int): Momentum period. Default is `5`.

### Returns
- **DataFrame**: A DataFrame with the `'rmi'` column.

Sure! Below is the full documentation for all the indicators starting from **Relative Momentum Index (RMI)** onward in **Markdown** format. Due to the length, I will break it into multiple parts, but it will cover everything from where we left off.

---

## Rate of Change (ROC)

### Description
The **Rate of Change (ROC)** is a momentum oscillator that measures the percentage change in price between the current price and the price n periods ago.

### Interpretation
- **ROC** values above 0 indicate upward momentum, while values below 0 indicate downward momentum.

### Usage Example
```python
df['roc'] = bta.rate_of_change(df, column='close', period=21)['roc']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the data.
- `column` (str): The column name on which ROC is applied. Default is `'close'`.
- `period` (int): Period for the ROC calculation. Default is `21`.

### Returns
- **DataFrame**: A DataFrame with the `'roc'` column.

---

## Smoothed Rate of Change (SROC)

### Description
The **Smoothed Rate of Change (SROC)** applies an exponential moving average (EMA) to the Rate of Change (ROC) to smooth out short-term fluctuations.

### Interpretation
- **SROC** provides a smoother momentum signal compared to regular ROC, making it useful for identifying longer-term trends.

### Usage Example
```python
df['sroc'] = bta.smoothed_rate_of_change(df, roclen=21, emalen=13, smooth=21)['sroc']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the data.
- `roclen` (int): Period for the ROC calculation. Default is `21`.
- `emalen` (int): Period for the EMA calculation. Default is `13`.
- `smooth` (int): Smoothing period for the ROC calculation. Default is `21`.

### Returns
- **DataFrame**: A DataFrame with the `'sroc'` column.

---

## Waddah Attar Explosion (ATR)

### Description
The **Waddah Attar Explosion (ATR)** is used to identify potential breakout opportunities by combining the MACD and Bollinger Bands with an ATR-based dead zone line.

### Interpretation
- **Waddah Attar Explosion** helps traders identify breakout situations. The **trend_up** column signals bullish conditions, while **trend_down** indicates bearish conditions.

### Usage Example
```python
wae = bta.waddah_attar_explosion_atr(df)
df['trend_up'] = wae['trend_up']
df['trend_down'] = wae['trend_down']
df['explosion_line'] = wae['explosion_line']
df['dead_zone_line'] = wae['dead_zone_line']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing `open`, `high`, `low`, and `close` columns.
- `sensitivity` (int): Sensitivity factor for the indicator. Default is `150`.
- `fast_length` (int): Length for the fast EMA. Default is `20`.
- `slow_length` (int): Length for the slow EMA. Default is `40`.
- `channel_length` (int): Length for the Bollinger Bands. Default is `20`.
- `mult` (float): Standard deviation multiplier for the Bollinger Bands. Default is `2.0`.

### Returns
- **DataFrame**: A DataFrame with `'trend_up'`, `'trend_down'`, `'explosion_line'`, and `'dead_zone_line'` columns.

---

## WaveTrend

### Description
The **WaveTrend** oscillator is used to identify overbought and oversold conditions in the market, providing insights into potential reversals or continuations of trends.

### Interpretation
- **WaveTrend** shows whether the market is overbought or oversold. It has two lines, **WT1** and **WT2**, that can be used to identify potential crossovers indicating buy or sell signals.

### Usage Example
```python
wt = bta.wave_trend(df, chlen=10, avg=21, smalen=4)
df['wt1'] = wt['wt1']
df['wt2'] = wt['wt2']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the data.
- `chlen` (int): Channel length for the EMA calculation. Default is `10`.
- `avg` (int): Average period for the EMA calculation. Default is `21`.
- `smalen` (int): Period for the SMA calculation. Default is `4`.

### Returns
- **DataFrame**: A DataFrame with `'wt1'` and `'wt2'` columns.

---

## WaveTrend Oscillator (WTO)

### Description
The **WaveTrend Oscillator (WTO)** is used to identify overbought and oversold conditions in the market by smoothing price data and analyzing trends. It combines two Exponential Moving Averages (EMAs) and measures deviations from them to produce the oscillator.

### Usage Example
```python
df['wto'] = bta.wave_trend_oscillator(df, 'close')['wavetrend']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the source column.
- `src` (str): Column to use for the oscillator calculation. Default is `'close'`.
- `n1` (int): Length for the first EMA. Default is `8`.
- `n2` (int): Length for the second EMA. Default is `12`.

### Returns
- **DataFrame**: A DataFrame with a `'wavetrend'` column representing the calculated oscillator.

---

## QQE Mod (Quantitative Qualitative Estimation Mod)

### Description
The **QQE Mod** is a technical analysis indicator that enhances the standard Relative Strength Index (RSI) by applying smoothing techniques and Bollinger Bands to generate buy and sell signals. It helps identify market trends and breakouts by smoothing out volatility.

### Usage Example
```python
qqe_mod_result = bta.qqe_mod(df, rsi_period=6, rsi_smoothing=5, qqe_factor=3, threshold=3, bollinger_length=50, bb_multiplier=0.35)
df['qqe_line'] = qqe_mod_result['qqe_line']
df['histo2'] = qqe_mod_result['histo2']
df['qqe_up'] = qqe_mod_result['qqe_up']
df['qqe_down'] = qqe_mod_result['qqe_down']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the `'close'` column.
- `rsi_period` (int): Period for RSI calculation. Default is `6`.
- `rsi_smoothing` (int): Smoothing period for RSI. Default is `5`.
- `qqe_factor` (int): Fast QQE Factor. Default is `3`.
- `threshold` (int): Threshold value for buy/sell signals. Default is `3`.
- `bollinger_length` (int): Length for Bollinger Bands calculation. Default is `50`.
- `bb_multiplier` (float): Multiplier for Bollinger Bands. Default is `0.35`.
- `rsi_period2` (int): Period for the second RSI calculation. Default is `6`.
- `rsi_smoothing2` (int): Smoothing period for the second RSI. Default is `5`.
- `qqe_factor2` (float): QQE Factor for the second QQE. Default is `1.61`.
- `threshold2` (int): Threshold value for the second QQE. Default is `3`.

### Returns
- **DataFrame**: A DataFrame with the following columns:
  - `'qqe_line'`: The QQE line.
  - `'histo2'`: The histogram showing differences in price momentum.
  - `'qqe_up'`: Signals for upward price movement.
  - `'qqe_down'`: Signals for downward price movement.

---

## Relative Strength Index (RSI)

### Description
The **Relative Strength Index (RSI)** is a momentum oscillator that measures the speed and change of price movements. It is commonly used to identify overbought or oversold conditions in the market.

### Usage Example
```python
df['rsi'] = bta.relative_strength_index(df, column='close', period=14)['rsi']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing at least the column specified for the RSI calculation.
- `column` (str): The column on which RSI is calculated. Default is `'close'`.
- `period` (int): The look-back period for RSI calculation. Default is `14`.

### Returns
- **DataFrame**: A DataFrame with a `'rsi'` column containing the calculated RSI values.

---

## Stochastic Momentum Index (SMI)

### Description
The **Stochastic Momentum Index (SMI)** is a momentum indicator developed by William Blau that can help identify trend reversal points by measuring how close the current price is to its recent price range's midpoint.

### Interpretation
- **SMI** values closer to +100 indicate overbought conditions, while values closer to -100 suggest oversold conditions.

### Usage Example
```python
df['smi'] = bta.stochastic_momentum_index(df, k_length=9, d_length=3)['smi']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing `high`, `low`, and `close` columns.
- `k_length` (int): Period for %K. Default is `9`.
- `d_length` (int): Period for %D. Default is `3`.

### Returns
- **DataFrame**: A DataFrame with the `'smi'` column.

---

## Stochastic Oscillator

### Description
The **Stochastic Oscillator** is a momentum indicator that compares the closing price of a security to its price range over a specified period. It helps identify overbought or oversold conditions by measuring the current price relative to the high-low range over a given period.

### Usage Example
```python
stoch = bta.stochastics_oscillator(df, 'high', 'low', 'close', 14, 3)
df['stoch'] = stoch['stoch']
df['stoch_signal'] = stoch['stoch_signal']
df['stoch_hist'] = stoch['stoch_hist']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the price data.
- `high_col` (str): Column name for the high prices. Default is `'high'`.
- `low_col` (str): Column name for the low prices. Default is `'low'`.
- `close_col` (str): Column name for the close prices. Default is `'close'`.
- `window` (int): Lookback period for the Stochastic Oscillator calculation. Default is `14`.
- `smooth_window` (int): Lookback period for calculating the Stochastic Signal. Default is `3`.
- `fillna` (bool): If `True`, fill NaN values. Default is `False`.

### Returns
- **DataFrame**: A DataFrame with the following columns:
  - `'stoch'`: The Stochastic %K line, representing the raw stochastic oscillator value.
  - `'stoch_signal'`: The Stochastic %D line, which is a smoothed version of %K.
  - `'stoch_hist'`: The Stochastic Histogram, which is the difference between %K and %D.

### Interpretation
- The **Stochastic Oscillator** fluctuates between 0 and 100. Values above 80 indicate overbought conditions, and values below 20 indicate oversold conditions.
- The **Stochastic Signal** (%D) is a smoothed version of the oscillator and can be used to generate buy/sell signals when it crosses above or below the %K line.
- The **Stochastic Histogram** represents the difference between the %K and %D lines, providing insight into the momentum of the trend.

---

## Stochastic RSI (StochasticRSI)

### Description
The **Stochastic RSI** is a technical analysis indicator that applies the Stochastic oscillator formula to RSI values, helping identify overbought and oversold conditions more accurately.

### Interpretation
- **Stochastic RSI** generates buy and sell signals when %K and %D lines cross, with %K above %D indicating a potential buy, and %K below %D signaling a potential sell.

### Usage Example
```python
stoch_rsi = bta.stochastic_rsi(df, length_rsi=14, length_stoch=14, smooth_k=3, smooth_d=3)
df['stoch_rsi_k'] = stoch_rsi['stoch_rsi_k']
df['stoch_rsi_d'] = stoch_rsi['stoch_rsi_d']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing a `'close'` column.
- `length_rsi` (int): Period for the RSI calculation. Default is `14`.
- `length_stoch` (int): Period for the Stochastic calculation. Default is `14`.
- `smooth_k` (int): Smoothing period for %K line. Default is `3`.
- `smooth_d` (int): Smoothing period for %D line. Default is `3`.

### Returns
- **DataFrame**: A DataFrame with `'stoch_rsi_k'` and `'stoch_rsi_d'` columns.

---

## True Strength Index (TSI)

### Description
The **True Strength Index (TSI)** shows both trend direction and overbought/oversold conditions by measuring the strength of price movements.

### Interpretation
- **TSI** above 0 indicates bullish momentum, while values below 0 suggest bearish momentum. It is often used with signal lines to confirm trends.

### Usage Example
```python
df['tsi'] = bta.true_strength_index(df, 'close', 25, 13)['tsi']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the `close` column.
- `close_col` (str): Column name for the close prices. Default is `'close'`.
- `window_slow` (int): Long period. Default is `25`.
- `window_fast` (int): Short period. Default is `13`.
- `fillna` (bool): If `True`, fills NaN values with `0`. Default is `False`.

### Returns
- **DataFrame**: A DataFrame with the `'tsi'` column.

---

## Ultimate Oscillator (UO)

### Description
The **Ultimate Oscillator (UO)** combines short-term, intermediate-term, and long-term price action into one oscillator, helping to spot potential reversals.

### Interpretation
- **UO** values above 70 suggest overbought conditions, while values

 below 30 indicate oversold conditions.

### Usage Example
```python
df['uo'] = bta.ultimate_oscillator(df, 'high', 'low', 'close', 7, 14, 28)['uo']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the `high`, `low`, and `close` columns.
- `high_col` (str): Name of the column containing high price data. Default is `'high'`.
- `low_col` (str): Name of the column containing low price data. Default is `'low'`.
- `close_col` (str): Name of the column containing close price data. Default is `'close'`.
- `window1` (int): Short period. Default is `7`.
- `window2` (int): Medium period. Default is `14`.
- `window3` (int): Long period. Default is `28`.
- `weight1` (float): Weight of short BP average. Default is `4.0`.
- `weight2` (float): Weight of medium BP average. Default is `2.0`.
- `weight3` (float): Weight of long BP average. Default is `1.0`.
- `fillna` (bool): If `True`, fills NaN values with `50`. Default is `False`.

### Returns
- **DataFrame**: A DataFrame with the `'uo'` column.

---

## Williams %R

### Description
The **Williams %R** is a momentum indicator that measures overbought and oversold levels in the market.

### Interpretation
- **Williams %R** values closer to `-100` indicate oversold conditions, while values closer to `0` suggest overbought conditions.

### Usage Example
```python
df['williams_r'] = bta.williams_r(df, 'high', 'low', 'close', 14)['williams_r']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the `high`, `low`, and `close` columns.
- `high_col` (str): Name of the column containing high price data. Default is `'high'`.
- `low_col` (str): Name of the column containing low price data. Default is `'low'`.
- `close_col` (str): Name of the column containing close price data. Default is `'close'`.
- `lbp` (int): Lookback period. Default is `14`.
- `fillna` (bool): If `True`, fills NaN values with `-50`. Default is `False`.

### Returns
- **DataFrame**: A DataFrame with the `'williams_r'` column.

        ----- End of momentum.md -----

        trend.md

        ----- Start of trend.md -----

# `trend` - Trend Indicators

## Alligator Bands

### Description
The **Alligator Indicator**, developed by Bill Williams, is used to identify trends and their direction in the market. It consists of three smoothed moving averages known as the **Jaw**, **Teeth**, and **Lips**.

### Interpretation
- **Jaw**: Represents the slowest moving average and is shifted by 8 periods to indicate long-term trends.
- **Teeth**: Represents the medium-term trend and is shifted by 5 periods.
- **Lips**: Represents the fastest moving average and is shifted by 3 periods.

### Usage Example
```python
alligator_result = bta.alligator_bands(df, 'close', 13, 8, 5, jaw_shift=8, teeth_shift=5, lips_shift=3)
df['jaw'] = alligator_result['jaw']
df['teeth'] = alligator_result['teeth']
df['lips'] = alligator_result['lips']
```

### Parameters
- `df` (pandas.DataFrame): DataFrame containing the data.
- `column` (str): The column on which the Alligator is applied. Default is `'close'`.
- `jaw_period` (int): Period for the Alligator's Jaw. Default is `13`.
- `teeth_period` (int): Period for the Alligator's Teeth. Default is `8`.
- `lips_period` (int): Period for the Alligator's Lips. Default is `5`.
- `jaw_shift` (int): Number of periods to shift the Jaw line. Default is `8`.
- `teeth_shift` (int): Number of periods to shift the Teeth line. Default is `5`.
- `lips_shift` (int): Number of periods to shift the Lips line. Default is `3`.

### Returns
- **DataFrame**: A DataFrame with `'jaw'`, `'teeth'`, and `'lips'` columns.

---

## Bollinger Trend Indicator

### Description
The **Bollinger Trend Indicator** measures the trend based on the difference between short and long Bollinger Bands, indicating the strength of the trend.

### Interpretation
- Positive values of **BBTrend** suggest a strong uptrend, while negative values indicate a downtrend.

### Usage Example
```python
df['bbtrend'] = bta.bollinger_trend(df, 'close', 20, 50, 2.0)['bbtrend']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the data.
- `column` (str): The column on which BBTrend is calculated. Default is `'close'`.
- `short_length` (int): Period for the short Bollinger Bands. Default is `20`.
- `long_length` (int): Period for the long Bollinger Bands. Default is `50`.
- `std_dev` (float): Standard deviation multiplier for the Bollinger Bands. Default is `2.0`.

### Returns
- **DataFrame**: A DataFrame with a single `'bbtrend'` column.

---

## Bollinger Trend Fast with Moving Average

### Description
This variation of the **Bollinger Trend Indicator** calculates a more responsive Bollinger Trend and applies a selectable moving average to the BBTrend result.

### Interpretation
- **BBTrend** indicates the direction of the trend, while the selected moving average can smooth the BBTrend values.

### Usage Example
```python
result = bta.bollinger_trend_fast_with_ma(df, 'close', 10, 50, 1.0, 2.0, 'SMA', 14)
df['bollinger_trend_fast'] = result['bbtrend']
df['bollinger_trend_fast_ma'] = result['bbtrend_ma']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame.
- `column` (str): The column on which BBTrend is calculated. Default is `'close'`.
- `short_length` (int): Period for the short Bollinger Bands. Default is `10`.
- `long_length` (int): Period for the long Bollinger Bands. Default is `50`.
- `short_stddev` (float): Standard deviation multiplier for short Bollinger Bands. Default is `1.0`.
- `long_stddev` (float): Standard deviation multiplier for long Bollinger Bands. Default is `2.0`.
- `ma_type` (str): Type of moving average to apply. Default is `'SMA'`.
- `ma_length` (int): Period for the moving average. Default is `14`.

### Returns
- **DataFrame**: A DataFrame with `'bbtrend'` and `'bbtrend_ma'` columns.

---

## Breakouts

### Description
The **Breakouts** function identifies **Support and Resistance (S/R)** levels and their breakouts or retests. It highlights potential trend reversals and continuation points.

### Interpretation
- **Support/Resistance Breakout**: Indicates if the price breaks through a support or resistance level.
- **Retests**: Signals whether the price retests a previously broken support or resistance level.

### Usage Example
```python
breakout = bta.breakouts(df, length=20)
df['support_level'] = breakout['support_level']
df['resistance_level'] = breakout['resistance_level']
df['support_breakout'] = breakout['support_breakout']
df['resistance_breakout'] = breakout['resistance_breakout']
df['support_retest'] = breakout['support_retest']
df['potential_support_retest'] = breakout['potential_support_retest']
df['resistance_retest'] = breakout['resistance_retest']
df['potential_resistance_retest'] = breakout['potential_resistance_retest']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the columns `'high'`, `'low'`, and `'close'`.
- `length` (int): Lookback period. Default is `20`.

### Returns
- **DataFrame**: A DataFrame with columns for support and resistance levels, breakouts, and retests.

---

## Exponential Moving Average (EMA)

### Description
The **Exponential Moving Average (EMA)** gives more weight to recent prices, making it more responsive to recent price changes compared to the Simple Moving Average (SMA).

### Interpretation
- **EMA** is used to identify trends and smooth out price action, with more emphasis on recent data points.

### Usage Example
```python
df['ema'] = bta.exponential_moving_average(df, 'close', 21)['ema']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the data.
- `column` (str): The column on which EMA is to be calculated. Default is `'close'`.
- `period` (int): The period for the EMA calculation. Default is `21`.

### Returns
- **DataFrame**: A DataFrame with the `'ema'` column.

---

## Hull Moving Average (HMA)

### Description
The **Hull Moving Average (HMA)** is a smoothed moving average designed to minimize lag while retaining responsiveness to price changes. It achieves this by using the **Weighted Moving Average (WMA)**.

### Interpretation
- **HMA** provides a faster signal than traditional moving averages and can be used to detect trends more effectively.

### Usage Example
```python
df['hma'] = bta.hull_moving_average(df, 'close', 9)['hma']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the data.
- `column` (str): The column on which HMA is to be calculated. Default is `'close'`.
- `period` (int): The period for the HMA calculation. Default is `9`.

### Returns
- **DataFrame**: A DataFrame with the `'hma'` column.

---

## Least Squares Moving Average (LSMA)

### Description
The **Least Squares Moving Average (LSMA)** fits a straight line to the price data over a specified period using the **least squares** method. This line is used to depict the direction of movement.

### Interpretation
- **LSMA** is used to identify the current trend and smooth price data by removing noise.

### Usage Example
```python
df['lsma'] = bta.least_squares_moving_average(df, 'close', 50)['lsma']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the data.
- `column` (str): The column on which LSMA is to be calculated. Default is `'close'`.
- `period` (int): The period for LSMA calculation. Default is `21`.

### Returns
- **DataFrame**: A DataFrame with the `'lsma'` column.

---

## Percent Price Channel (PPC)

### Description
The **Percent Price Channel (PPC)** calculates the percentage change of a price channel, based on the highest high and lowest low of a trailing period.

### Interpretation
- A **breakout** above the upper band indicates market strength, while a **breakout** below the lower band signals weakness. The **percent_p** value shows the current price’s position within the price channel.

### Usage Example
```python
ppc_result = bta.price_channel(df, period=20)
df['ppc_upper'] = ppc_result['ppc_upper']
df['ppc_mid'] = ppc_result['ppc_mid']
df['ppc_lower'] = ppc_result['ppc_lower']
df['percent_p'] = ppc_result['percent_p']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the data.
- `period` (int): The period for calculating the highest high and lowest low. Default is `20`.

### Returns
- **DataFrame**: A DataFrame with `'ppc_upper'`, `'ppc_mid'`, `'ppc_lower'`, and `'percent_p'` columns.

---

## Rolling Moving Average (RMA)

### Description
The **Rolling Moving Average (RMA)** is a type of **Exponential Moving Average (EMA)** that smooths data over a specified period, providing a trend-following measure.

### Interpretation
- **RMA** is used similarly to EMA, giving more weight to recent price data, and is helpful in trend identification.

### Usage Example
```python
df['rma'] = bta.rolling_moving_average(df, 'close', 14)['rma']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the data.
- `column` (str): The column on which RMA is calculated. Default is `'close'`.
- `period` (int): The period for the RMA calculation. Default is `14`.

### Returns
- **DataFrame**: A DataFrame with the `'rma'` column.

---

## Simple Moving Average (SMA)

### Description
The **Simple Moving Average (SMA)** is the unweighted mean of the previous n data points. It is used to smooth price data to identify trends.

### Interpretation
- **SMA** is used to identify the overall direction of a trend. Longer periods smooth out more short-term fluctuations.

### Usage Example
```python
df['sma'] = bta.simple_moving_average(df, 'close', 50)['sma']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the data.
- `column` (str): The column on which SMA is to be calculated. Default is `'close'`.
- `period` (int): The period for SMA calculation. Default is `21`.

### Returns
- **DataFrame**: A DataFrame with the `'sma'` column.

---

## SSL Channels

### Description
**SSL Channels** use moving averages to identify trends by calculating SSL Down and SSL Up series based on price action.

### Interpretation
- **SSL Down** and **SSL Up** signals indicate potential buy or sell conditions depending on the relationship between price and these levels.

### Usage Example
```python
ssl_result = bta.ssl_channels(df, length=10, mode='sma')
df['ssl_down'] = ssl_result['ssl_down']
df['ssl_up'] = ssl_result['ssl_up']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the data.
- `length` (int): Period for the SMA calculation. Default is `10`.
- `mode` (str): The type of moving average. Currently, only `'sma'` is supported.

### Returns
- **DataFrame**: A DataFrame with `'ssl_down'` and `'ssl_up'` columns.

---

## SSL Channels with ATR

### Description
The **SSL Channels with ATR** use the **Average True Range (ATR)** to dynamically adjust support and resistance levels, helping identify trend reversals and continuations.

### Interpretation
- The **ATR-adjusted SSL Down** and **SSL Up** provide dynamic support and resistance levels based on volatility.

### Usage Example
```python
ssl_result = bta.ssl_channels_atr(df, column='close', length=14, atr_period=7)
df['ssl_atr_down'] = ssl_result['ssl_atr_down']
df['ssl_atr_up'] = ssl_result['ssl_atr_up']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the data.
- `length` (int): Period for the SMA calculation. Default is `14`.
- `atr_period` (int): Period for the ATR calculation. Default is `7`.
- `column` (str): The column to use for moving average calculations. Default is `'close'`.

### Returns
- **DataFrame**: A DataFrame with `'ssl_atr_down'` and `'ssl_atr_up'` columns.

---

## T3 Average

### Description
The **T3 Average** is a smoothed moving average designed to reduce lag while maintaining responsiveness to price changes. It is calculated using multiple stages of **Exponential Moving Averages (EMAs)**.

### Interpretation
- The **T3 Average** offers a smooth trend-following signal that is more responsive than traditional moving averages while reducing lag.

### Usage Example
```python
df['t3_average'] = bta.t3_average(df, length=5)['t3_average']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the data.
- `length` (int): Period for the EMA calculation. Default is `5`.

### Returns
- **DataFrame**: A DataFrame with the `'t3_average'` column.

---

## Weighted Moving Average (WMA)

### Description
The **Weighted Moving Average (WMA)** gives more weight to recent data points and less weight to older data points. It is useful for tracking trends while placing emphasis on recent prices.

### Interpretation
- **WMA** can be used to identify trends similarly to other moving averages, but it reacts faster to price changes due to its weighting system.

### Usage Example
```python
df['wma'] = bta.weighted_moving_average(df, 'close', 10)['wma']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the data.
- `column` (str): The column to calculate the WMA on. Default is `'close'`.
- `period` (int): The period for the WMA calculation. Default is `10`.

### Returns
- **DataFrame**: A DataFrame with the `'wma'` column.

---

## Zero Exponential Moving Average (ZEMA)

### Description
The **Zero Exponential Moving Average (ZEMA)** is an improved version of the **Exponential Moving Average (EMA)** that reduces lag by incorporating a zero-lag component.

### Interpretation
- **ZEMA** is faster to respond to price changes compared to the regular EMA and can be used to detect trends more effectively.

### Usage Example
```python
df['zema'] = bta.zero_exponential_moving_average(df, 'close', 21)['zema']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the data.
- `column` (str): The column on which ZEMA is to be calculated. Default is `'close'`.
- `period` (int): The period for ZEMA calculation. Default is `21`.

### Returns
- **DataFrame**: A DataFrame with the `'zema'` column.

---

## Zero Lag Exponential Moving Average (ZLEMA)

### Description
The **Zero Lag Exponential Moving Average (ZLEMA)** is an **Exponential Moving Average (EMA)** that adjusts for lag, making it more responsive to recent price changes by using lagged data differences to adjust the EMA calculation.

### Interpretation
- **ZLEMA** provides a faster and more responsive trend signal by reducing the inherent lag of the EMA.

### Usage Example
```python
df['zlema'] = bta.zero_lag_exponential_moving_average(df, 'close', 21)['zlema']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the data.
- `column` (str): The column on which ZLEMA is to be calculated. Default is `'close'`.
- `period` (int): The period for ZLEMA calculation. Default is `21`.

### Returns
- **DataFrame**: A DataFrame with the `'zlema'` column.

---

        ----- End of trend.md -----

        volatility.md

        ----- Start of volatility.md -----

# `volatility` - Volatility Indicators

## Average True Range (ATR)

### Description
The **Average True Range (ATR)** is a measure of market volatility introduced by Welles Wilder in his book "New Concepts in Technical Trading Systems." It represents the average of the True Range over a given period, helping traders measure volatility.

### Usage Example
```python
df['atr'] = bta.average_true_range(df, period=14)['atr']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the `'high'`, `'low'`, and `'close'` columns.
- `period` (int): The look-back period for calculating the ATR. Default is `14`.

### Returns
- **DataFrame**: A DataFrame with a single `'atr'` column containing the Average True Range.

---

## Bollinger Bands (BBANDS)

### Description
**Bollinger Bands** are a volatility indicator developed by John Bollinger. They consist of a **middle band** (a moving average), an **upper band** (typically 2 standard deviations above the moving average), and a **lower band** (typically 2 standard deviations below the moving average).

### Usage Example
```python
bb_result = bta.bollinger_bands(df, column='close', period=20, std_dev=2, ddof=0)
df['bb_upper'] = bb_result['bb_upper']
df['bb_middle'] = bb_result['bb_middle']
df['bb_lower'] = bb_result['bb_lower']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the data.
- `column` (str): The column on which to apply the Bollinger Bands calculation. Default is `'close'`.
- `period` (int): The look-back period for calculating the moving average. Default is `20`.
- `std_dev` (float): Number of standard deviations for the upper and lower bands. Default is `2.0`.
- `ddof` (int): Degrees of freedom to use when calculating the standard deviation. Default is `0`.

### Returns
- **DataFrame**: A DataFrame with `'bb_upper'`, `'bb_middle'`, and `'bb_lower'` columns representing the Bollinger Bands.

---

## True Range (TR)

### Description
The **True Range (TR)** is a volatility indicator that measures the range of a financial instrument, taking into account any gaps from the previous day's close. It is defined as the maximum of:
- The current high minus the current low.
- The absolute value of the current high minus the previous close.
- The absolute value of the current low minus the previous close.

### Usage Example
```python
df['true_range'] = bta.true_range(df)['true_range']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing `'high'`, `'low'`, and `'close'` columns.

### Returns
- **DataFrame**: A DataFrame with a single `'true_range'` column containing the True Range.

---

## Upcoming Indicators

The following indicators are planned for future implementation:
- **Keltner Channel** (with width).
- **Donchian Channel** (with width).
- **Ulcer Index**: A volatility indicator that measures the percentage drawdown over time, often used to assess risk.

For more information, check resources such as [StockCharts - Ulcer Index](https://stockcharts.com/school/doku.php?id=chart_school:technical_indicators:ulcer_index).

---

        ----- End of volatility.md -----

        volume.md

        ----- Start of volume.md -----

# `volume` - Volume-Based Technical Indicators

## Accumulation/Distribution Index (ADI)

### Description
The **Accumulation/Distribution Index (ADI)** is a volume-based indicator that measures the cumulative flow of money into or out of a security. It uses the relationship between the price’s range (high and low) and its closing price to calculate the **Close Location Value (CLV)**.

### Usage Example
```python
df['adi'] = bta.accumulation_distribution_index(df, fillna=True)['adi']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing `'high'`, `'low'`, `'close'`, and `'volume'` columns.
- `fillna` (bool): If `True`, fill NaN values. Default is `False`.

### Returns
- **DataFrame**: A DataFrame with a single `'adi'` column.

---

## Chaikin Money Flow (CMF)

### Description
The **Chaikin Money Flow (CMF)** indicator measures the amount of Money Flow Volume over a specific period. It uses the relationship between the close price and the range (high and low) to evaluate buying or selling pressure.

### Usage Example
```python
df['cmf'] = bta.chaikin_money_flow(df, window=20, fillna=True)['cmf']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing `'high'`, `'low'`, `'close'`, and `'volume'` columns.
- `window` (int): Look-back period for the calculation. Default is `20`.
- `fillna` (bool): If `True`, fill NaN values. Default is `False`.

### Returns
- **DataFrame**: A DataFrame with a single `'cmf'` column.

---

## Ease of Movement (EoM)

### Description
The **Ease of Movement (EoM)** indicator relates the price movement of an asset to its volume, helping assess trend strength. The **Signal Ease of Movement (SEoM)** is a smoothed version of EoM, calculated using a moving average.

### Usage Example
```python
eom_df = bta.ease_of_movement(df, eom_length=14, seom_length=14, fillna=True)
df['eom'] = eom_df['eom']
df['seom'] = eom_df['seom']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing `'high'`, `'low'`, and `'volume'` columns.
- `eom_length` (int): Period for the EoM calculation. Default is `14`.
- `seom_length` (int): Period for the SEoM calculation. Default is `14`.
- `fillna` (bool): If `True`, fill NaN values. Default is `False`.

### Returns
- **DataFrame**: A DataFrame with `'eom'` and `'seom'` columns.

---

## Force Index (FI)

### Description
The **Force Index (FI)** measures the strength of price movements by combining price changes and volume. It helps illustrate the buying or selling pressure in the market.

### Usage Example
```python
df['fi'] = bta.force_index(df, window=13, fillna=True)['fi']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing `'close'` and `'volume'` columns.
- `window` (int): Period for the exponential moving average of the Force Index. Default is `13`.
- `fillna` (bool): If `True`, fill NaN values. Default is `False`.

### Returns
- **DataFrame**: A DataFrame with a single `'fi'` column.

---

## Money Flow Index (MFI)

### Description
The **Money Flow Index (MFI)** is a momentum indicator that uses both price and volume data to measure buying and selling pressure. It is often referred to as a **volume-weighted RSI**.

### Usage Example
```python
df['mfi'] = bta.money_flow_index(df, window=14, fillna=True)['mfi']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing `'high'`, `'low'`, `'close'`, and `'volume'` columns.
- `window` (int): Look-back period for the MFI calculation. Default is `14`.
- `fillna` (bool): If `True`, fill NaN values. Default is `False`.

### Returns
- **DataFrame**: A DataFrame with a single `'mfi'` column.

---

## Negative Volume Index (NVI)

### Description
The **Negative Volume Index (NVI)** accumulates the percentage rate of change in price on days when trading volume decreases compared to the previous day. It helps identify trends driven by low-volume days.

### Usage Example
```python
nvi_df = bta.negative_volume_index(df, signal_type='EMA', signal_length=255, fillna=True)
df['nvi'] = nvi_df['nvi']
df['nvi_signal'] = nvi_df['nvi_signal']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing `'close'` and `'volume'` columns.
- `signal_type` (str): Type of signal smoothing ('EMA' or 'SMA'). Default is `'EMA'`.
- `signal_length` (int): Length for the signal smoothing calculation. Default is `255`.
- `fillna` (bool): If `True`, fill NaN values. Default is `False`.

### Returns
- **DataFrame**: A DataFrame with `'nvi'` and `'nvi_signal'` columns.

---

## On Balance Volume (OBV)

### Description
The **On Balance Volume (OBV)** indicator measures buying and selling pressure by adding volume when the close price is higher than the previous close and subtracting volume when the close price is lower.

### Usage Example
```python
obv_df = bta.on_balance_volume(df, signal_type='SMA', signal_length=21, show_signal=True, fillna=True)
df['obv'] = obv_df['obv']
df['signal'] = obv_df['signal']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing `'close'` and `'volume'` columns.
- `signal_type` (str): Type of signal smoothing ('SMA' or 'EMA'). Default is `'SMA'`.
- `signal_length` (int): Period for signal calculation. Default is `21`.
- `show_signal` (bool): If `True`, calculate and return the signal line. Default is `True`.
- `fillna` (bool): If `True`, fill NaN values. Default is `False`.

### Returns
- **DataFrame**: A DataFrame with `'obv'` and `'signal'` columns.

---

## On Balance Volume Oscillator (OBV Oscillator)

### Description
The **On Balance Volume Oscillator** measures the difference between the OBV and its Exponential Moving Average (EMA). It helps identify trends and confirm price movements.

### Usage Example
```python
df['obv_oscillator'] = bta.on_balance_volume_oscillator(df, length=20, fillna=True)['obv_oscillator']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing `'close'` and `'volume'` columns.
- `length` (int): Length for the EMA calculation. Default is `20`.
- `fillna` (bool): If `True`, fill NaN values. Default is `False`.

### Returns
- **DataFrame**: A DataFrame with a single `'obv_oscillator'` column.

---

## Positive Volume Index (PVI)

### Description
The **Positive Volume Index (PVI)** accumulates the percentage rate of change in price on days when trading volume increases compared to the previous day. It helps identify trends driven by high-volume days.

### Usage Example
```python
pvi_df = bta.positive_volume_index(df, signal_type='EMA', signal_length=255, fillna=True)
df['pvi'] = pvi_df['pvi']
df['pvi_signal'] = pvi_df['pvi_signal']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing `'close'` and `'volume'` columns.
- `signal_type` (str): Type of signal smoothing ('EMA' or 'SMA'). Default is `'EMA'`.
- `signal_length` (int): Length for signal calculation. Default is `255`.
- `fillna` (bool): If `True`, fill NaN values. Default is `False`.

### Returns
- **DataFrame**: A DataFrame with `'pvi'` and `'pvi_signal'` columns.

---

## Price Volume Trend (PVT)

### Description
The **Price Volume Trend (PVT)** indicator combines price and volume to measure the strength of trends. It accumulates the volume proportional to the price movement.

### Usage Example
```python
pvt_df = bta.price_volume_trend(df, fillna=True, signal_type='EMA', signal_length=21, dropnans=True)
df['pvt'] = pvt_df['price_volume_trend']
df['pvt_signal'] = pvt_df['signal']
```

### Parameters
- `df` (p

andas.DataFrame): Input DataFrame containing `'close'` and `'volume'` columns.
- `fillna` (bool): If `True`, fill NaN values. Default is `False`.
- `smoothing_factor` (int, optional): Apply SMA smoothing to the PVT values.
- `signal_type` (str): Type of signal smoothing ('EMA' or 'SMA'). Default is `'SMA'`.
- `signal_length` (int): Length for signal calculation. Default is `21`.
- `dropnans` (bool): Drop NaN values after calculation. Default is `False`.

### Returns
- **DataFrame**: A DataFrame with `'price_volume_trend'` and `'signal'` columns.

---

## Volume Weighted Average Price (VWAP)

### Description
The **Volume Weighted Average Price (VWAP)** represents the average price a security has traded at throughout the day, based on both volume and price. It is often used to assess whether a security is trading above or below its average price.

### Usage Example
```python
df['vwap'] = bta.volume_weighted_average_price(df, window=14, fillna=True)['volume_weighted_average_price']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing `'high'`, `'low'`, `'close'`, and `'volume'` columns.
- `window` (int): The number of periods for the rolling calculation. Default is `14`.
- `fillna` (bool): If `True`, fill NaN values. Default is `False`.

### Returns
- **DataFrame**: A DataFrame with a single `'volume_weighted_average_price'` column.

---

        ----- End of volume.md -----

        candles.md

        ----- Start of candles.md -----

# `candles` - Technical Analysis Indicators

## Leledc Exhaustion Bars

### Description
The **Leledc Exhaustion Bars** are a reversal indicator that identifies potential trend reversals by looking for price exhaustion. This occurs when there is a sharp price move combined with increased volume, indicating that the current trend may be losing momentum.

### Interpretation
- **Leledc Major** (`leledc_major`): Signals major reversals in price. A value of `1` indicates a potential bullish reversal, while `-1` suggests a bearish reversal.
- **Leledc Minor** (`leledc_minor`): Signals smaller or minor reversals. A value of `1` indicates a minor bullish reversal, and `-1` indicates a minor bearish reversal.

### Usage Example
```python
exhaustion = bta.exhaustion_bars(df)
df['leledc_major'] = exhaustion['leledc_major']
df['leledc_minor'] = exhaustion['leledc_minor']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame with columns `open`, `high`, `low`, and `close`.
- `maj_qual` (int): Major quality threshold. Default is `6`.
- `maj_len` (int): Major length. Default is `30`.
- `min_qual` (int): Minor quality threshold. Default is `5`.
- `min_len` (int): Minor length. Default is `5`.
- `core_length` (int): Core length for pattern recognition. Default is `4`.

### Returns
- **DataFrame**: A DataFrame with two columns:
  - `'leledc_major'`: Major reversal signal.
  - `'leledc_minor'`: Minor reversal signal.

---

## Dynamic Leledc Exhaustion Bars

### Description
The **Dynamic Leledc Exhaustion Bars** dynamically adjust their lookback window based on market conditions. They are useful for identifying reversals in volatile markets where price behavior changes rapidly.

### Interpretation
- **Dynamic Leledc Major** (`dynamic_leledc_major`): A dynamic version of the Leledc Major that adapts to market conditions.
- **Dynamic Leledc Minor** (`dynamic_leledc_minor`): A dynamic version of the Leledc Minor that adapts to market conditions.

### Usage Example
```python
dynamic_exhaustion = bta.dynamic_exhaustion_bars(df)
df['dynamic_leledc_major'] = dynamic_exhaustion['leledc_major']
df['dynamic_leledc_minor'] = dynamic_exhaustion['leledc_minor']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame with a `close` column.
- `window` (int): Lookback window for z-score calculation. Default is `500`.

### Returns
- **DataFrame**: A DataFrame with two columns:
  - `'leledc_major'`: Dynamic major reversal signal.
  - `'leledc_minor'`: Dynamic minor reversal signal.

---

## Heiken Ashi

### Description
**Heiken Ashi** charts are a modified form of candlestick charts that smooth out price action, making it easier to identify trends. Optional pre- and post-smoothing can further refine the visual representation of the trend.

### Interpretation
- **Heiken Ashi Candles** help reduce noise and make trend-following easier. When the Heiken Ashi close is higher than the open, the market is in an uptrend, and vice versa.

### Usage Example
```python
ha_df = bta.heiken_ashi(df)
df['ha_open'] = ha_df['ha_open']
df['ha_high'] = ha_df['ha_high']
df['ha_low'] = ha_df['ha_low']
df['ha_close'] = ha_df['ha_close']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame with columns `open`, `high`, `low`, and `close`.
- `pre_smoothing_period` (int, optional): If provided, smooths data before Heiken Ashi calculations.
- `post_smoothing_period` (int, optional): If provided, smooths the Heiken Ashi values after calculation.

### Returns
- **DataFrame**: A DataFrame with four columns:
  - `'ha_open'`: Heiken Ashi open.
  - `'ha_high'`: Heiken Ashi high.
  - `'ha_low'`: Heiken Ashi low.
  - `'ha_close'`: Heiken Ashi close.

---

## Linear Regression Candles

### Description
**Linear Regression Candles** smooth out price action using a linear regression algorithm. An optional signal line can be added to indicate potential buy or sell signals based on trend strength.

### Interpretation
- **Linear Regression Candles** smooth price action, helping traders identify trends and make decisions based on the slope of the linear regression lines.
- The **Signal Line** adds a moving average of the regression candle close, which can serve as a trend confirmation.

### Usage Example
```python
lr_df = bta.linear_regression_candles(df)
df['lrc_open'] = lr_df['bopen']
df['lrc_high'] = lr_df['bhigh']
df['lrc_low'] = lr_df['blow']
df['lrc_close'] = lr_df['bclose']
df['lrc_signal'] = lr_df['signal']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame with columns `open`, `high`, `low`, and `close`.
- `linreg_length` (int): Lookback period for linear regression. Default is `11`.
- `sma_signal` (bool): If `True`, uses SMA for the signal line. If `False`, uses EMA. Default is `True`.
- `signal_length` (int): Lookback period for the signal line. Default is `11`.

### Returns
- **DataFrame**: A DataFrame with five columns:
  - `'bopen'`: Linear regression open.
  - `'bhigh'`: Linear regression high.
  - `'blow'`: Linear regression low.
  - `'bclose'`: Linear regression close.
  - `'signal'`: Signal line (SMA or EMA).


        ----- End of candles.md -----

        statistics.md

        ----- Start of statistics.md -----

# `TODO: statistics` - Statistical Indicators

## Introduction
This module contains statistical functions and technical indicators used for analyzing price movements, correlations, and distributions in financial markets.

## Pearson Correlation Coefficient

### Description
The **Pearson Correlation Coefficient** measures the linear correlation between two variables (e.g., two assets). The coefficient value ranges between -1 and +1, where:
- **+1** indicates a perfect positive correlation.
- **-1** indicates a perfect negative correlation.
- **0** indicates no correlation.

### Usage Example
```python
df['pearson_corr'] = bta.pearson_correlation(df['asset1'], df['asset2'], window=30)
```

### Parameters
- `series1` (pd.Series): First input series.
- `series2` (pd.Series): Second input series.
- `window` (int): Look-back period for calculating the rolling Pearson correlation. Default is `30`.

### Returns
- **pd.Series**: Series containing the Pearson correlation values.

---

## Spearman Rank Correlation

### Description
The **Spearman Rank Correlation** measures the strength and direction of the monotonic relationship between two ranked variables. It is less sensitive to outliers compared to the Pearson correlation and is used for non-linear relationships.

### Usage Example
```python
df['spearman_corr'] = bta.spearman_correlation(df['asset1'], df['asset2'], window=30)
```

### Parameters
- `series1` (pd.Series): First input series.
- `series2` (pd.Series): Second input series.
- `window` (int): Look-back period for calculating the rolling Spearman correlation. Default is `30`.

### Returns
- **pd.Series**: Series containing the Spearman correlation values.

---

## Covariance

### Description
**Covariance** measures the directional relationship between two variables. A positive covariance indicates that the variables tend to move together, while a negative covariance suggests they move inversely.

### Usage Example
```python
df['covariance'] = bta.covariance(df['asset1'], df['asset2'], window=30)
```

### Parameters
- `series1` (pd.Series): First input series.
- `series2` (pd.Series): Second input series.
- `window` (int): Look-back period for calculating rolling covariance. Default is `30`.

### Returns
- **pd.Series**: Series containing the covariance values.

---

## Variance

### Description
**Variance** measures the dispersion of a dataset relative to its mean. It is a common measure of volatility in financial markets. Higher variance indicates more variability in the data.

### Usage Example
```python
df['variance'] = bta.variance(df['close'], window=30)
```

### Parameters
- `series` (pd.Series): Input series (e.g., price data).
- `window` (int): Look-back period for calculating the rolling variance. Default is `30`.

### Returns
- **pd.Series**: Series containing the variance values.

---

## Standard Deviation

### Description
**Standard Deviation** is a measure of the amount of variation or dispersion in a dataset. It is the square root of variance and is commonly used to assess the volatility of asset prices.

### Usage Example
```python
df['std_dev'] = bta.standard_deviation(df['close'], window=30)
```

### Parameters
- `series` (pd.Series): Input series (e.g., price data).
- `window` (int): Look-back period for calculating the rolling standard deviation. Default is `30`.

### Returns
- **pd.Series**: Series containing the standard deviation values.

---

## Z-Score

### Description
The **Z-Score** indicates how many standard deviations a data point is from the mean of the dataset. It is used to measure how unusual or extreme a data point is relative to the distribution.

### Usage Example
```python
df['zscore'] = bta.z_score(df['close'], window=500)
```

### Parameters
- `series` (pd.Series): Input series (e.g., price data).
- `window` (int): Look-back period for calculating the rolling Z-score. Default is `500`.

### Returns
- **pd.Series**: Series containing the Z-score values.

---

## Skewness

### Description
**Skewness** measures the asymmetry of the distribution of data points. Positive skewness indicates a longer or fatter right tail, while negative skewness indicates a longer or fatter left tail.

### Usage Example
```python
df['skewness'] = bta.skewness(df['close'], window=30)
```

### Parameters
- `series` (pd.Series): Input series (e.g., price data).
- `window` (int): Look-back period for calculating rolling skewness. Default is `30`.

### Returns
- **pd.Series**: Series containing the skewness values.

---

## Kurtosis

### Description
**Kurtosis** measures the "tailedness" of the distribution of data points. High kurtosis indicates heavy tails, suggesting the presence of outliers, while low kurtosis indicates light tails.

### Usage Example
```python
df['kurtosis'] = bta.kurtosis(df['close'], window=30)
```

### Parameters
- `series` (pd.Series): Input series (e.g., price data).
- `window` (int): Look-back period for calculating rolling kurtosis. Default is `30`.

### Returns
- **pd.Series**: Series containing the kurtosis values.

---

## Rolling Beta

### Description
The **Rolling Beta** measures the sensitivity of an asset's returns to the returns of a benchmark over a rolling window. It is used to assess how much an asset's price movement is influenced by the market.

### Usage Example
```python
df['rolling_beta'] = bta.rolling_beta(df['asset'], df['benchmark'], window=30)
```

### Parameters
- `series1` (pd.Series): Series of asset returns.
- `series2` (pd.Series): Series of benchmark returns.
- `window` (int): Look-back period for calculating rolling beta. Default is `30`.

### Returns
- **pd.Series**: Series containing the rolling beta values.

---

        ----- End of statistics.md -----

        pip-package-making.md

        ----- Start of pip-package-making.md -----

## Creating the Python pip package (personal notes)

After creating and testing the code, make a Python pip package as follows:

Update the file ``setup.py`` and update version number.

In the library folder, create the package

``python3 setup.py sdist bdist_wheel``

Before uploading the package to Pypi it is wise to test the package on your system.

Load the package to the system with:

``pip install .``

After you've checked that everything is worknig correctly, then use the following command to upload to Pypi.
You'll have to install twine for this (``pip install twine`` or ``sudo apt install twine``)

When you get the error:

```
ImportError: cannot import name 'appengine' from 'requests.packages.urllib3.contrib' (/home/user/.local/lib/python3.10/site-packages/urllib3/contrib/__init__.py)
```

You should do a ``pip install --upgrade twine requests-toolbelt``.

### Before uploading

```
# Check first

twine check dist/*

# Test upload first

twine upload -r testpypi dist/*

# Upload to Pypi

twine upload dist/*
```

Note: uploading new versions requires to delete the older versions from the /dist folder.

Another option is to use the ``--skip-existing`` option like this:

```
# Testpypi
twine upload -r testpypi dist/* --skip-existing 

# ProductionPypi
twine upload -r pypi dist/* --skip-existing
```

### Uploading with 2FA enabled

First create an API token (at https://test.pypi.org/manage/account/token/).

Create a file .pypirc in your home folder (e.g. ``nano $HOME/.pypirc``)

Add the given token to the file like this:

```
[testpypi]
  username = __token__
  password =
pypi-AgENdGVzdC5weXtMjBjOS00ZjgxLWIyZDMtYWViMDAwOTk3MWZmAAIqWzMsImU3YjkzMGVmLWQzMGItNGFhYi1iNB6NZ-rSrzc8UXHRmWp5fzZwP


[pypi]
  username = __token__
  password =
pypi-AgEIcHlwaS5vcmcCJDgxYWFiYjYwLTMxYmUtNDczZC1hNjBhLTU0MDJhNmQ2NmZhMgAQ3NTAtOGVkNy0xN2U0NmU0MjEzMQFAYWNj0FcsP-Slnj9-wkEWWwQXkaw
```

Save the file and reload environment if necessary.

Now you an upload libraries without having to use the password.
        ----- End of pip-package-making.md -----

        performance.md

        ----- Start of performance.md -----

# `TODO: performance` - Performance Indicators

## Introduction
This module contains functions and technical indicators that are used to evaluate the performance of trading strategies and assets. These indicators help measure returns, volatility, and other key performance metrics.

## Sharpe Ratio

### Description
The **Sharpe Ratio** is a measure of risk-adjusted return. It compares the excess return of an asset (or portfolio) over the risk-free rate to its standard deviation. A higher Sharpe Ratio indicates better risk-adjusted performance.

### Usage Example
```python
df['sharpe_ratio'] = bta.sharpe_ratio(df, risk_free_rate=0.01, window=252)
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing asset returns in a column.
- `risk_free_rate` (float): The risk-free rate (e.g., treasury bond rate). Default is `0.01`.
- `window` (int): Look-back period for calculating the Sharpe Ratio. Default is `252` (typically used for daily data in a year).

### Returns
- **DataFrame**: A DataFrame with a single `'sharpe_ratio'` column.

---

## Sortino Ratio

### Description
The **Sortino Ratio** is a variation of the Sharpe Ratio that focuses only on downside volatility. It measures the risk-adjusted return by penalizing negative returns more than positive returns.

### Usage Example
```python
df['sortino_ratio'] = bta.sortino_ratio(df, risk_free_rate=0.01, window=252)
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing asset returns in a column.
- `risk_free_rate` (float): The risk-free rate (e.g., treasury bond rate). Default is `0.01`.
- `window` (int): Look-back period for calculating the Sortino Ratio. Default is `252`.

### Returns
- **DataFrame**: A DataFrame with a single `'sortino_ratio'` column.

---

## Maximum Drawdown (MDD)

### Description
The **Maximum Drawdown (MDD)** measures the maximum observed loss from a peak to a trough of an asset or portfolio. It is used to assess the risk of large losses.

### Usage Example
```python
df['mdd'] = bta.maximum_drawdown(df, column='close')
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing price or return data.
- `column` (str): The column to calculate the maximum drawdown on. Default is `'close'`.

### Returns
- **DataFrame**: A DataFrame with a single `'mdd'` column representing the maximum drawdown.

---

## Calmar Ratio

### Description
The **Calmar Ratio** is a performance indicator that measures the return of an asset or portfolio relative to its maximum drawdown. It is a risk-adjusted return metric that emphasizes downside risk.

### Usage Example
```python
df['calmar_ratio'] = bta.calmar_ratio(df, window=252)
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing return data.
- `window` (int): Look-back period for calculating the Calmar Ratio. Default is `252`.

### Returns
- **DataFrame**: A DataFrame with a single `'calmar_ratio'` column.

---

## Information Ratio

### Description
The **Information Ratio (IR)** compares the excess return of an asset or portfolio to a benchmark (e.g., an index) relative to the tracking error (standard deviation of excess returns). It is used to assess performance compared to a benchmark.

### Usage Example
```python
df['information_ratio'] = bta.information_ratio(df, benchmark_column='benchmark', window=252)
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing returns of the asset and the benchmark.
- `benchmark_column` (str): The column containing benchmark returns.
- `window` (int): Look-back period for calculating the Information Ratio. Default is `252`.

### Returns
- **DataFrame**: A DataFrame with a single `'information_ratio'` column.

---

## Alpha

### Description
**Alpha** measures the excess return of an asset or portfolio relative to the return predicted by the Capital Asset Pricing Model (CAPM). Positive alpha indicates outperformance, while negative alpha indicates underperformance.

### Usage Example
```python
df['alpha'] = bta.alpha(df, benchmark_column='benchmark', risk_free_rate=0.01, window=252)
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing asset and benchmark returns.
- `benchmark_column` (str): The column containing benchmark returns.
- `risk_free_rate` (float): The risk-free rate. Default is `0.01`.
- `window` (int): Look-back period for calculating Alpha. Default is `252`.

### Returns
- **DataFrame**: A DataFrame with a single `'alpha'` column.

---

## Beta

### Description
**Beta** measures the sensitivity of an asset's returns to the returns of the market (or a benchmark). A beta greater than 1 indicates that the asset is more volatile than the market, while a beta less than 1 indicates lower volatility.

### Usage Example
```python
df['beta'] = bta.beta(df, benchmark_column='benchmark', window=252)
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing asset and benchmark returns.
- `benchmark_column` (str): The column containing benchmark returns.
- `window` (int): Look-back period for calculating Beta. Default is `252`.

### Returns
- **DataFrame**: A DataFrame with a single `'beta'` column.

---

## Treynor Ratio

### Description
The **Treynor Ratio** measures the return of an asset or portfolio relative to its market risk, as measured by beta. It is similar to the Sharpe Ratio but focuses on systematic risk instead of total risk.

### Usage Example
```python
df['treynor_ratio'] = bta.treynor_ratio(df, benchmark_column='benchmark', risk_free_rate=0.01, window=252)
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing asset and benchmark returns.
- `benchmark_column` (str): The column containing benchmark returns.
- `risk_free_rate` (float): The risk-free rate. Default is `0.01`.
- `window` (int): Look-back period for calculating the Treynor Ratio. Default is `252`.

### Returns
- **DataFrame**: A DataFrame with a single `'treynor_ratio'` column.

---

## Jensen's Alpha

### Description
**Jensen's Alpha** measures the excess return of an asset or portfolio over its expected return based on the Capital Asset Pricing Model (CAPM). Positive Jensen's Alpha indicates outperformance, while negative alpha indicates underperformance.

### Usage Example
```python
df['jensens_alpha'] = bta.jensens_alpha(df, benchmark_column='benchmark', risk_free_rate=0.01, window=252)
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing asset and benchmark returns.
- `benchmark_column` (str): The column containing benchmark returns.
- `risk_free_rate` (float): The risk-free rate. Default is `0.01`.
- `window` (int): Look-back period for calculating Jensen's Alpha. Default is `252`.

### Returns
- **DataFrame**: A DataFrame with a single `'jensens_alpha'` column.

---

        ----- End of performance.md -----

        cycles.md

        ----- Start of cycles.md -----

# `TODO: cycles` - Cycles-Based Indicators

## Introduction
This module contains technical indicators that help identify cyclical behavior in financial markets. These indicators are typically used to detect repeating patterns or oscillations in the market.

## Hilbert Transform - Instantaneous Trendline

### Description
The **Hilbert Transform - Instantaneous Trendline** is used to smooth out price action and help identify the underlying trend of the market. It is based on the **Hilbert Transform**, which helps filter out noise in price data and highlights the dominant cycle.

### Usage Example
```python
df['inst_trendline'] = bta.hilbert_instantaneous_trendline(df, 'close')
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing a `'close'` column.
- `column` (str): Column to be used for the calculation. Default is `'close'`.

### Returns
- **DataFrame**: A DataFrame with a single `'inst_trendline'` column representing the smoothed trendline.

---

## Hilbert Transform - Dominant Cycle Period

### Description
The **Hilbert Transform - Dominant Cycle Period** is used to identify the dominant cycle present in the market by analyzing price data. It helps detect the most prominent periodic behavior in the market.

### Usage Example
```python
df['dominant_cycle_period'] = bta.hilbert_dominant_cycle_period(df, 'close')
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing a `'close'` column.
- `column` (str): Column to be used for the calculation. Default is `'close'`.

### Returns
- **DataFrame**: A DataFrame with a single `'dominant_cycle_period'` column representing the dominant cycle length.

---

## Hilbert Transform - Dominant Cycle Phase

### Description
The **Hilbert Transform - Dominant Cycle Phase** measures the phase of the dominant cycle in the market. It can be used to identify turning points where price action shifts from one cycle phase to another.

### Usage Example
```python
df['dominant_cycle_phase'] = bta.hilbert_dominant_cycle_phase(df, 'close')
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing a `'close'` column.
- `column` (str): Column to be used for the calculation. Default is `'close'`.

### Returns
- **DataFrame**: A DataFrame with a single `'dominant_cycle_phase'` column representing the phase of the dominant cycle.

---

## Hilbert Transform - Dominant Cycle Phase Slope

### Description
The **Hilbert Transform - Dominant Cycle Phase Slope** calculates the slope of the dominant cycle phase, which helps identify whether the cycle is accelerating or decelerating. This can be useful for detecting potential trend changes.

### Usage Example
```python
df['dominant_cycle_slope'] = bta.hilbert_dominant_cycle_phase_slope(df, 'close')
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing a `'close'` column.
- `column` (str): Column to be used for the calculation. Default is `'close'`.

### Returns
- **DataFrame**: A DataFrame with a single `'dominant_cycle_slope'` column representing the slope of the dominant cycle phase.

---

## Sinewave Indicator

### Description
The **Sinewave Indicator** is a cycle-based indicator that helps identify potential turning points in the market by measuring the oscillation between bullish and bearish phases.

### Usage Example
```python
sinewave_df = bta.sinewave(df, 'close')
df['sinewave'] = sinewave_df['sinewave']
df['lead_sinewave'] = sinewave_df['lead_sinewave']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing a `'close'` column.
- `column` (str): Column to be used for the calculation. Default is `'close'`.

### Returns
- **DataFrame**: A DataFrame with two columns:
  - `'sinewave'`: The sinewave component.
  - `'lead_sinewave'`: The leading sinewave component, which may give early warning of trend changes.

---

## Time Series Forecast

### Description
The **Time Series Forecast (TSF)** is used to forecast future prices based on past price data. It uses a linear regression model to predict future price movements based on a given look-back period.

### Usage Example
```python
df['tsf'] = bta.time_series_forecast(df, 'close', lookback=14)
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing a `'close'` column.
- `column` (str): Column to be used for the calculation. Default is `'close'`.
- `lookback` (int): Number of periods to look back for the forecast. Default is `14`.

### Returns
- **DataFrame**: A DataFrame with a single `'tsf'` column representing the forecasted price.

---

## Two-Pole Super Smoother

### Description
The **Two-Pole Super Smoother** is a smoothing filter that reduces noise in price data while maintaining responsiveness to price changes. It is particularly useful for filtering out short-term fluctuations while highlighting trends.

### Usage Example
```python
df['super_smoother'] = bta.two_pole_super_smoother(df, 'close', period=14)
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing a `'close'` column.
- `column` (str): Column to be used for the calculation. Default is `'close'`.
- `period` (int): Period for the smoothing calculation. Default is `14`.

### Returns
- **DataFrame**: A DataFrame with a single `'super_smoother'` column representing the smoothed values.

---

        ----- End of cycles.md -----

        utility.md

        ----- Start of utility.md -----

# `utility` - Utility Functions for Technical Analysis

## calculate_atr_stop_loss_take_profit

### Description
This function calculates the **take profit**, **stop loss**, and **buy price** levels based on the **ATR (Average True Range)**, signal, and changes in trading advice. It checks when the trading signal changes (e.g., from `buy` to `sell`), and sets the take profit and stop loss accordingly.

### Usage Example
```python
atr_sl_tp_df = bta.calculate_atr_stop_loss_take_profit(df, signal_column='signal')
df['takeprofit'] = atr_sl_tp_df['takeprofit']
df['stoploss'] = atr_sl_tp_df['stoploss']
df['buyprice'] = atr_sl_tp_df['buyprice']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing columns `'signal'`, `'close'`, and `'atr'`.
- `signal_column` (str): Column with buy/sell signals. Default is `'signal'`.
- `atr_column` (str): Column with ATR values. Default is `'atr'`.
- `atr_sl_mult` (float): Multiplier for stop loss based on ATR. Default is `1`.
- `atr_tp_mult` (float): Multiplier for take profit based on ATR. Default is `2`.

### Returns
- **DataFrame**: A DataFrame with columns `'takeprofit'`, `'stoploss'`, and `'buyprice'`.

---

## calculate_stop_loss_take_profit

### Description
Calculates the **stop loss**, **take profit**, and **entry price** based on customizable trade signals for both long and short trades. It uses user-defined risk/reward ratios to determine the levels for both long and short trades.

### Usage Example
```python
stop_loss_take_profit = bta.calculate_stop_loss_take_profit(df, 
                                                            signal_column='trade_signal',
                                                            long_trade_signal='long_trade', 
                                                            short_trade_signal='short_trade', 
                                                            no_trade_signal='no_trade', 
                                                            lookback_period=5, 
                                                            long_reward_ratio=2, 
                                                            short_reward_ratio=1.5, 
                                                            buffer=0.5)
df['stop_loss'] = stop_loss_take_profit['stop_loss']
df['entry_price'] = stop_loss_take_profit['entry_price']
df['take_profit'] = stop_loss_take_profit['take_profit']
df['exit_reason'] = stop_loss_take_profit['exit_reason']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing trade signals and price data.
- `signal_column` (str): Column storing trade signals. Default is `'trade_signal'`.
- `long_trade_signal` (str): Value in the signal column that represents a long trade. Default is `'long_trade'`.
- `short_trade_signal` (str): Value in the signal column that represents a short trade. Default is `'short_trade'`.
- `no_trade_signal` (str): Value in the signal column that represents no trade. Default is `'no_trade'`.
- `lookback_period` (int): Lookback period for calculating stop loss. Default is `5`.
- `long_reward_ratio` (float): Reward-risk ratio for long trades. Default is `2`.
- `short_reward_ratio` (float): Reward-risk ratio for short trades. Default is `2`.
- `buffer` (float): Buffer added to stop loss. Default is `0.0`.

### Returns
- **DataFrame**: A DataFrame with columns `'stop_loss'`, `'take_profit'`, `'entry_price'`, and `'exit_reason'`.

---

## consecutive_count

### Description
Calculates the average consecutive count of non-zero differences in an array.

### Usage Example
```python
avg_count = bta.consecutive_count(consecutive_diff)
```

### Parameters
- `consecutive_diff` (np.ndarray): Array of consecutive differences.

### Returns
- **float**: Average consecutive count, or 0 if there are fewer than two non-zero differences.

---

## first_crossed_above_second

### Description
Checks if the first series crosses above the second series.

### Usage Example
```python
df['first_crossed_above_second'] = bta.first_crossed_above_second(series1, series2)
```

### Parameters
- `series1` (pd.Series): First input series.
- `series2` (pd.Series): Second input series.

### Returns
- **pd.Series**: Boolean series where `True` indicates a crossover above.

---

## first_crossed_below_second

### Description
Checks if the first series crosses below the second series.

### Usage Example
```python
df['first_crossed_below_second'] = bta.first_crossed_below_second(series1, series2)
```

### Parameters
- `series1` (pd.Series): First input series.
- `series2` (pd.Series): Second input series.

### Returns
- **pd.Series**: Boolean series where `True` indicates a crossover below.

---

## cumulative_return

### Description
Calculates the **Cumulative Return (CR)** of a specified column.

### Usage Example
```python
df['cumulative_return'] = bta.cumulative_return(df)
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing price data.
- `column` (str): Column on which the cumulative return is calculated. Default is `'close'`.
- `fillna` (bool): If `True`, fills NaN values. Default is `False`.

### Returns
- **pd.Series**: Series of cumulative return values.

---

## daily_log_return

### Description
Calculates the **Daily Log Return (DLR)** of a specified column.

### Usage Example
```python
df['daily_log_return'] = bta.daily_log_return(df)
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing price data.
- `column` (str): Column on which the daily log return is calculated. Default is `'close'`.
- `fillna` (bool): If `True`, fills NaN values. Default is `False`.

### Returns
- **pd.Series**: Series of daily log return values.

---

## daily_return

### Description
Calculates the **Daily Return (DR)** of a specified column.

### Usage Example
```python
df['daily_return'] = bta.daily_return(df)
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing price data.
- `column` (str): Column on which the daily return is calculated. Default is `'close'`.
- `fillna` (bool): If `True`, fills NaN values. Default is `False`.

### Returns
- **pd.Series**: Series of daily return values.

---

## exhaustion_candles

### Description
Calculates **Exhaustion Candles** by dynamically adjusting major and minor quality values based on consecutive price movements.

### Usage Example
```python
maj_qual, min_qual = bta.exhaustion_candles(df, window=1, multiplier=1)
df['maj_qual'] = maj_qual
df['min_qual'] = min_qual
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing price data.
- `window` (int): Lookback window for the calculation. Default is `1`.
- `multiplier` (int): Scalar multiplier for both major and minor quality. Default is `1`.

### Returns
- **Tuple[np.ndarray, np.ndarray]**: Arrays of major and minor quality values.

---

## exhaustion_lengths

### Description
Calculates the average lengths of peaks and valleys in a price series, used to dynamically adjust exhaustion bands.

### Usage Example
```python
maj_len, min_len = bta.exhaustion_lengths(df)
df['maj_len'] = maj_len
df['min_len'] = min_len
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing `'high'` and `'low'` columns.

### Returns
- **Tuple[int, int]**: Average peak distance (major length) and average valley distance (minor length).

---

## get_min_max

### Description
Returns the minimum or maximum value between two series for each index.

### Usage Example
```python
df['min_max'] = bta.get_min_max(df['open'], df['close'], 'max')
```

### Parameters
- `series1` (pd.Series): First input series.
- `series2` (pd.Series): Second input series.
- `function` (str): Function to apply, either `'min'` or `'max'`. Default is `'min'`.

### Returns
- **pd.Series**: Series with the min or max values for each index.

---

## linear_decay

### Description
Implements a linear decay function. The value decays linearly from a starting value to an ending value over a specified time range.

### Usage Example
```python
decayed_value = bta.linear_decay(start=100, end=0, start_time=10, end_time=60, trade_time=30)
```

### Parameters
- `start` (float): Starting value.
- `end` (float): Ending value.
- `start_time` (int): Time in minutes when decay starts.
- `end_time` (int): Time in minutes when decay ends.
- `trade_time` (int): Current trade time in minutes.

### Returns
- **float**: Decayed value.

---

## linear_growth

### Description
Implements a linear growth function. The value grows linearly from a starting value to an ending value over a specified time range.

### Usage Example
```python
grown_value = bta.linear_growth(start=0, end=100, start_time=10, end_time=60, trade_time=30)
```

### Parameters
- `start` (float): Starting value.
- `end` (float): Ending value.
- `start_time` (int): Time in minutes when growth starts.
- `end_time` (int): Time in minutes when growth ends.
- `trade_time` (int): Current trade time in minutes.

### Returns
- **float**: Grown value.

---

## populate_leledc_major_minor

### Description
Populates the **Leledc Major** and **Leledc Minor** columns in a DataFrame based on major and minor quality values, as well as major and minor lengths.

### Usage Example
```python
leledc_major_minor = bta.populate_leledc_major_minor(df, maj_qual, min_qual, maj_len, min_len)
df['leledc_major'] = leledc_major_minor['leledc_major']
df['leledc_minor'] = leledc_major_minor['leledc_minor']
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame.
- `maj_qual` (np.ndarray): Array of major quality values.
- `min_qual` (np.ndarray): Array of minor quality values.
- `maj_len` (int): Major length value.
- `min_len` (int): Minor length value.

### Returns
- **pd.DataFrame**: DataFrame with `'leledc_major'` and `'leledc_minor'` columns.

---

## regression_slope

### Description
Calculates the slope of a **linear regression** line fitted to the closing prices over a specified lookback period.

### Usage Example
```python
df['slope'] = bta.regression_slope(df, lookback_period=20)
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame containing the `'close'` prices.
- `lookback_period` (int): Lookback period for the slope calculation. Default is `20`.

### Returns
- **pd.Series**: Series of regression slopes.

---

## same_length

### Description
Ensures that two arrays have the same length by padding the shorter array with `NaN` values.

### Usage Example
```python
padded_array = bta.same_length(bigger_array, shorter_array)
```

### Parameters
- `bigger` (np.ndarray): Larger array.
- `shorter` (np.ndarray): Smaller array.

### Returns
- **np.ndarray**: Shorter array padded with `NaN` values to match the length of the larger array.

---

## st_dev

### Description
Calculates the rolling **standard deviation** over a specified period.

### Usage Example
```python
df['std_dev'] = bta.st_dev(df['close'], period=14)
```

### Parameters
- `series` (pd.Series): Data series for the standard deviation calculation.
- `period` (int): Period over which to calculate the standard deviation.

### Returns
- **pd.Series**: Rolling standard deviation values.

---

## z_score

### Description
Calculates the **z-score** of a series, which indicates how far away a data point is from the mean in terms of standard deviations.

### Usage Example
```python
df['zscore'] = bta.z_score(df['close'], window=500)
```

### Parameters
- `series` (pd.Series): Input series.
- `window` (int): Lookback window for calculating the mean and standard deviation. Default is `500`.

### Returns
- **pd.Series**: Z-score series.

---

## drop_na

### Description
Drops rows with `NaN` values and replaces extremely large numbers and zeros in numeric columns with `NaN` before dropping them.

### Usage Example
```python
df_cleaned = bta.drop_na(df)
```

### Parameters
- `df` (pandas.DataFrame): Input DataFrame.

### Returns
- **pd.DataFrame**: DataFrame with `NaN` values removed and extreme values handled.

---

        ----- End of utility.md -----

