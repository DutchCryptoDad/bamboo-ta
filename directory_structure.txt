## Project Structure
The project is organized into the following directories:
```
./
│   ├── bamboo_ta/
│   └── requirements.txt
│   └── setup.py
│   └── test copy.py
│   └── prompts.md
│   ├── bamboo_ta/
│   │   └── __init__.py
│   │   └── statistics.py
│   │   └── performance.py
│   │   └── candles.py
│   │   └── volume.py
│   │   └── trend.py
│   │   └── utility.py
│   │   └── momentum.py
│   │   └── cycles.py
│   │   └── bamboo_ta.py
│   │   └── volatility.py
```

Detailed File Contents:

./
    requirements.txt

    ----- Start of requirements.txt -----

ta
numpy
pandas
pandas_ta

    ----- End of requirements.txt -----

    setup.py

    ----- Start of setup.py -----

from setuptools import setup, find_packages
import os

here = os.path.abspath(os.path.dirname(__file__))

VERSION = '0.0.6'
DESCRIPTION = 'TA library for Pandas'

with open("README.md", "r") as f:
    LONG_DESCRIPTION = f.read()

# Setting up
setup(
    name="bamboo-ta",
    version=VERSION,
    author="DutchCryptoDad (DCD)",
    author_email="<dutchcryptodad@gmail.com>",
    url="https://github.com/DutchCryptoDad/bamboo-ta",
    description=DESCRIPTION,
    long_description_content_type="text/markdown",
    long_description=LONG_DESCRIPTION,
    packages=find_packages(),
    keywords=['python', 'pandas', 'numpy',
              'trading', 'indicator', 'technical analysis'],
    classifiers=[
        "Development Status :: 1 - Planning",
        "Intended Audience :: Developers",
        "Programming Language :: Python :: 3",
        "Operating System :: Unix",
        "Operating System :: MacOS :: MacOS X",
        "Operating System :: Microsoft :: Windows",
    ],
    install_requires=['pandas', 'numpy'],
    extras_require={
        "def": ["pytest", "twine"],
    },
    python_requres=">=3.10",
)

    ----- End of setup.py -----

    test copy.py

    ----- Start of test copy.py -----

# -*- coding: utf-8 -*-
# Import necessary libraries
# Importeer necessary libraries
import bamboo_ta.bamboo_ta as bta
#import pandas_ta as pta
import pandas as pd
from pandas import DataFrame
import numpy as np

# Create dataframe
# create dataframe and read the json data in the datasets directory
df = pd.read_json("./BTC_USDT-1d.json")
# name the columns that are loaded into the dataframe
df.columns = ['date', 'open', 'high', 'low', 'close', 'volume']
# the date column consists of unix time in milliseconds, so this command changes this data into human readable form.
df['date'] = (pd.to_datetime(df['date'], unit='ms'))
# ========================================

# TREND CALCULATIONS

# # Simple Moving Average
# df['sma'] = bta.SMA(df, "close", 50)  # correct
# # Exponential Moving Average
# df['ema'] = bta.EMA(df, "close", 50)  # correct
# # Least squares moving average
# df['lsma'] = bta.LSMA(df, "close", 50)  # correct

# RESULTS:
#            date      open      high       low     close        volume         sma           ema          lsma
# 1967 2023-01-05  16850.36  16879.82  16753.00  16831.85  163473.56641  16793.0500  17123.708932  16908.227482
# 1968 2023-01-06  16831.85  17041.00  16679.00  16950.65  207401.28415  16798.2118  17116.922308  16916.445059
# 1969 2023-01-07  16950.31  16981.91  16908.00  16943.57  104526.56880  16803.0742  17110.124178  16923.821224
# 1970 2023-01-08  16943.83  17176.99  16911.00  17127.83  135155.89695  16811.6172  17110.818524  16944.941788
# 1971 2023-01-09  17127.83  17398.80  17104.66  17178.26  266211.52723  16829.5778  17113.463288  16952.155035

# # VOLATILITY CALCULATIONS
# bb_result = bta.BollingerBands(df, "close", 21, 2, 0)
# df['bb_upper'] = bb_result['BB_upper']
# df['bb_middle'] = bb_result['BB_middle']
# df['bb_lower'] = bb_result['BB_lower']


# # Based on Pandas TA
# lng = 21
# dev = 2

# df['bb_upper'] = pta.bbands(close=df['close'], length=lng,
#                             std=dev, mamode=None, offset=None)[f'BBU_{lng}_{dev}.0']
# df['bb_middle'] = pta.bbands(close=df['close'], length=lng,
#                              std=dev, mamode=None, offset=None)[f'BBM_{lng}_{dev}.0']
# df['bb_lower'] = pta.bbands(close=df['close'], length=lng,
#                             std=dev, mamode=None, offset=None)[f'BBL_{lng}_{dev}.0']

# RESULT OF BOLLINGER CHECKS:
# python test.py
#            date      open      high       low     close        volume      BB_upper     BB_middle      BB_lower      bb_upper     bb_middle      bb_lower
# 1967 2023-01-05  16850.36  16879.82  16753.00  16831.85  163473.56641  16976.289552  16722.740000  16469.190448  16976.289552  16722.740000  16469.190448
# 1968 2023-01-06  16831.85  17041.00  16679.00  16950.65  207401.28415  17005.670681  16737.908095  16470.145510  17005.670681  16737.908095  16470.145510
# 1969 2023-01-07  16950.31  16981.91  16908.00  16943.57  104526.56880  17027.316671  16745.862857  16464.409044  17027.316671  16745.862857  16464.409044
# 1970 2023-01-08  16943.83  17176.99  16911.00  17127.83  135155.89695  17089.406121  16764.416190  16439.426259  17089.406121  16764.416190  16439.426259
# 1971 2023-01-09  17127.83  17398.80  17104.66  17178.26  266211.52723  17135.923174  16799.624762  16463.326350  17135.923174  16799.624762  16463.326350


# MOMENTUM INDICATORS

# # RSI
# df['rsi'] = bta.RSI(df, "close", 14)
# df['p_rsi'] = pta.rsi(close=df['close'], length=14)

#  /bamboo-ta on  main ≡  ~5
# ➜  python test.py
#            date      open      high       low     close        volume        rsi      p_rsi
# 1967 2023-01-05  16850.36  16879.82  16753.00  16831.85  163473.56641  50.071524  50.071524
# 1968 2023-01-06  16831.85  17041.00  16679.00  16950.65  207401.28415  53.243658  53.243658
# 1969 2023-01-07  16950.31  16981.91  16908.00  16943.57  104526.56880  53.027433  53.027433
# 1970 2023-01-08  16943.83  17176.99  16911.00  17127.83  135155.89695  57.827520  57.827520
# 1971 2023-01-09  17127.83  17398.80  17104.66  17178.26  266211.52723  59.060593  59.060593

# MACD
# macd_result = bta.MACD(df, "close", 12, 26, 9)
# df['macd'] = macd_result['MACD']
# df['macd_signal'] = macd_result['MACD_signal']
# df['macd_histogram'] = macd_result['MACD_histogram']

# # Pandas MACD
# pta.macd(close=df['close'], fast=None, slow=None,
#          signal=None, offset=None).tail(5)
# df['P_macd'] = pta.macd(close=df['close'], fast=None,
#                         slow=None, signal=None, offset=None)['MACD_12_26_9']
# df['P_macs'] = pta.macd(close=df['close'], fast=None,
#                         slow=None, signal=None, offset=None)['MACDs_12_26_9']
# df['P_macdh'] = pta.macd(close=df['close'], fast=None,
#                          slow=None, signal=None, offset=None)['MACDh_12_26_9']

#  /bamboo-ta on  main ≡  ~13
# ➜  python test.py
#            date      open      high       low     close        volume       macd  macd_signal  macd_histogram     P_macd      P_macs    P_macdh
# 1967 2023-01-05  16850.36  16879.82  16753.00  16831.85  163473.56641 -83.250482  -111.409248       28.158766 -83.250482 -111.409248  28.158766
# 1968 2023-01-06  16831.85  17041.00  16679.00  16950.65  207401.28415 -60.071674  -101.141734       41.070059 -60.071674 -101.141734  41.070059
# 1969 2023-01-07  16950.31  16981.91  16908.00  16943.57  104526.56880 -41.791848   -89.271757       47.479908 -41.791848  -89.271757  47.479908
# 1970 2023-01-08  16943.83  17176.99  16911.00  17127.83  135155.89695 -12.294984   -73.876402       61.581418 -12.294984  -73.876402  61.581418
# 1971 2023-01-09  17127.83  17398.80  17104.66  17178.26  266211.52723  14.978115   -56.105499       71.083614  14.978115  -56.105499  71.083614

# supertrend_result = bta.SuperTrend(df, "close", 7, 3.0, 0)
# df['supertrend'] = supertrend_result['ST_trend']
# df['supertrend_d'] = supertrend_result['ST_direction']
# df['supertrend_l'] = supertrend_result['ST_long']
# df['supertrend_s'] = supertrend_result['ST_short']

# # Using Pandas TA
# # Supertrend is 1 where close is above supertrend (bullish), and -1 if close is below supertrend (bearish).

# st_length = 7
# st_mult = 3.0

# df['st'] = pta.supertrend(high=df['high'], low=df['low'], close=df['close'],
#                           length=st_length, multiplier=st_mult)[f'SUPERT_{st_length}_{st_mult}']
# df['std'] = pta.supertrend(high=df['high'], low=df['low'], close=df['close'],
#                            length=st_length, multiplier=st_mult)[f'SUPERTd_{st_length}_{st_mult}']
# df['stl'] = pta.supertrend(high=df['high'], low=df['low'], close=df['close'],
#                            length=st_length, multiplier=st_mult)[f'SUPERTl_{st_length}_{st_mult}']
# df['sts'] = pta.supertrend(high=df['high'], low=df['low'], close=df['close'],
#                            length=st_length, multiplier=st_mult)[f'SUPERTs_{st_length}_{st_mult}']

# df['wma'] = bta.WMA(df, "close", 50)
# df['hma'] = bta.HMA(df, "close", 50)
# df['zlema'] = bta.ZLEMA(df, "close", 50)

# ➜  python test.py
#            date      open      high       low     close        volume         sma           wma           hma         zlema
# 1967 2023-01-05  16850.36  16879.82  16753.00  16831.85  163473.56641  16793.0500  16831.442494  16689.219892  16590.685184
# 1968 2023-01-06  16831.85  17041.00  16679.00  16950.65  207401.28415  16798.2118  16837.622886  16676.593601  16572.485765
# 1969 2023-01-07  16950.31  16981.91  16908.00  16943.57  104526.56880  16803.0742  16843.323208  16672.061953  16553.329069
# 1970 2023-01-08  16943.83  17176.99  16911.00  17127.83  135155.89695  16811.6172  16856.058729  16680.025132  16566.897341
# 1971 2023-01-09  17127.83  17398.80  17104.66  17178.26  266211.52723  16829.5778  16870.436878  16700.310344  16612.289602

# df['ewo'] = bta.EWO(df, "close", 5, 35)

# ➜  python test.py
#            date      open      high       low     close        volume       ewo
# 1967 2023-01-05  16850.36  16879.82  16753.00  16831.85  163473.56641 -1.075050
# 1968 2023-01-06  16831.85  17041.00  16679.00  16950.65  207401.28415 -0.649598
# 1969 2023-01-07  16950.31  16981.91  16908.00  16943.57  104526.56880 -0.340181
# 1970 2023-01-08  16943.83  17176.99  16911.00  17127.83  135155.89695  0.188342
# 1971 2023-01-09  17127.83  17398.80  17104.66  17178.26  266211.52723  0.534305


# ha_result = bta.HeikinAshi(
#     df, pre_smoothing_period=14, post_smoothing_period=14)
# df['HA_Open'] = ha_result['HA_Open']
# df['HA_High'] = ha_result['HA_High']
# df['HA_Low'] = ha_result['HA_Low']
# df['HA_Close'] = ha_result['HA_Close']

# #  /bamboo-ta on  main ≡  ~2
# # ➜  python test.py
# #            date      open      high       low     close        volume    HA_Close       HA_Open   HA_High        HA_Low
# # 1967 2023-01-05  16850.36  16879.82  16753.00  16831.85  163473.56641  16828.7575  16721.877756  16879.82  16721.877756
# # 1968 2023-01-06  16831.85  17041.00  16679.00  16950.65  207401.28415  16875.6250  16775.317628  17041.00  16679.000000
# # 1969 2023-01-07  16950.31  16981.91  16908.00  16943.57  104526.56880  16945.9475  16825.471314  16981.91  16825.471314
# # 1970 2023-01-08  16943.83  17176.99  16911.00  17127.83  135155.89695  17039.9125  16885.709407  17176.99  16885.709407
# # 1971 2023-01-09  17127.83  17398.80  17104.66  17178.26  266211.52723  17202.3875  16962.810954  17398.80  16962.810954

# ➜  python test.py
#            date      open      high       low     close        volume       HA_Open       HA_High        HA_Low      HA_Close
# 1967 2023-01-05  16850.36  16879.82  16753.00  16831.85  163473.56641  16828.347559  16955.448586  16642.252201  16801.965683
# 1968 2023-01-06  16831.85  17041.00  16679.00  16950.65  207401.28415  16815.156621  16945.774718  16639.259120  16795.707645
# 1969 2023-01-07  16950.31  16981.91  16908.00  16943.57  104526.56880  16805.432133  16939.150974  16641.788599  16793.678094
# 1970 2023-01-08  16943.83  17176.99  16911.00  17127.83  135155.89695  16799.555114  16938.404055  16648.474500  16796.531177
# 1971 2023-01-09  17127.83  17398.80  17104.66  17178.26  266211.52723  16798.043145  16946.027853  16661.606318  16805.889382

# lr_df = bta.LinRegCandles(df, sma_signal=True)

# # After calling, the following columns can be extracted:
# df['LRC_Open'] = lr_df['bopen']
# df['LRC_High'] = lr_df['bhigh']
# df['LRC_Low'] = lr_df['blow']
# df['LRC_Close'] = lr_df['bclose']
# df['LRC_Signal'] = lr_df['signal']

#  /bamboo-ta on  main ≡  ~2
# ➜  python test.py
#            date      open      high       low     close        volume      LRC_Open      LRC_High       LRC_Low     LRC_Close    LRC_Signal
# 1967 2023-01-05  16850.36  16879.82  16753.00  16831.85  163473.56641  16648.707727  16794.727273  16597.960000  16718.946364  16680.307975
# 1968 2023-01-06  16831.85  17041.00  16679.00  16950.65  207401.28415  16719.063636  16899.244091  16676.039091  16842.977727  16676.179628
# 1969 2023-01-07  16950.31  16981.91  16908.00  16943.57  104526.56880  16842.992273  16985.721364  16795.958182  16924.602727  16683.688719
# 1970 2023-01-08  16943.83  17176.99  16911.00  17127.83  135155.89695  16924.666364  17099.740455  16879.386818  17025.155455  16707.076570
# 1971 2023-01-09  17127.83  17398.80  17104.66  17178.26  266211.52723  17025.216364  17244.566364  17008.464091  17131.032273  16744.021033

# alligator_result = bta.AlligatorBands(df, "close", 13, 8, 5)
# df['jaw'] = alligator_result['jaw']
# df['teeth'] = alligator_result['teeth']
# df['lips'] = alligator_result['lips']
# alligator_result = bta.AlligatorBands(
#     df, "close", 13, 8, 5, jaw_shift=8, teeth_shift=5, lips_shift=3)
# df['jaw'] = alligator_result['jaw']
# df['teeth'] = alligator_result['teeth']
# df['lips'] = alligator_result['lips']
# # Print stuff
# print(df.tail(7))


# df['BBTrend'] = bta.BollingerTrend(df, "close", 20, 50, 2.0)

# BollingerTrendFast = bta.BollingerTrendFastWithMA(df, column="close", short_length=10, long_length=50, short_stddev=1.0, long_stddev=2.0, ma_type="SMA", ma_length=14)
# df['BollingerTrendFast'] = BollingerTrendFast['BBTrend']
# df['BollingerTrendFastMA'] = BollingerTrendFast['BBTrendMA']


# WAE = bta.Waddah_Attar_Explosion(df)
# df['trend_up'] = WAE['trend_up']
# df['trend_down'] = WAE['trend_down']
# df['explosion_line'] = WAE['explosion_line']
# df['dead_zone_line'] = WAE['dead_zone_line']

# df['MACD_Leader'] = bta.MACD_Leader(df, 'close')
# df['CMO'] = bta.CMO(df)['cmo']
# df['CMO_Signal'] = df['CMO'].rolling(window=10).mean().round(2)  # Using SMA for signal
# df['Wavetrend'] = bta.WaveTrend_Oscillator(df, 'close')

# df['IFT'] = bta.Inverse_Fisher_Transform(df, rsi_length=5, rsi_smoothing=9)

# qqe_mod = bta.QQE_Mod(df)
# df['QQE_Line'] = qqe_mod['QQE_Line']
# df['Histo2'] = qqe_mod['Histo2']
# df['QQE_Up'] = qqe_mod['QQE_Up']
# df['QQE_Down'] = qqe_mod['QQE_Down']

# df['OBV_Oscillator'] = bta.OBV_Oscillator(df)

# fisher = bta.Fisher_cg(df)
# df['fisher_cg'] = fisher['fisher_cg']
# df['fisher_sig'] = fisher['fisher_sig']

# breakout = bta.Breakouts(df)
# df['support_level'] = breakout['support_level']
# df['resistance_level'] = breakout['resistance_level']
# df['support_breakout'] = breakout['support_breakout']
# df['resistance_breakout'] = breakout['resistance_breakout']
# df['support_retest'] = breakout['support_retest']
# df['potential_support_retest'] = breakout['potential_support_retest']
# df['resistance_retest'] = breakout['resistance_retest']
# df['potential_resistance_retest'] = breakout['potential_resistance_retest']

# pin = bta.Pinbar(df)
# df['pinbar_sell'] = pin['pinbar_sell']
# df['pinbar_buy'] = pin['pinbar_buy']

# smi = bta.SMI_Momentum(df)
# # df['smi'] = smi['smi']

# exhaustion = bta.Exhaustion_Bars(df)
# df['leledc_major'] = exhaustion['leledc_major']
# df['leledc_minor'] = exhaustion['leledc_minor']

# dynamic_exhaustion = bta.Dynamic_Exhaustion_Bars(df)
# df['dynamic_leledc_major'] = dynamic_exhaustion['leledc_major']
# df['dynamic_leledc_minor'] = dynamic_exhaustion['leledc_minor']


# wt1, wt2 = bta.WaveTrend(df, chlen=10, avg=21, smalen=4)
# df['wt1'] = wt1
# df['wt2'] = wt2

# ssl_down, ssl_up = bta.SSLChannels(df, length=10, mode='sma')
# df['ssl_down'] = ssl_down
# df['ssl_up'] = ssl_up

# ssl_down, ssl_up = bta.SSLChannelsATR(df, length=7)
# df['ssl_atr_down'] = ssl_down
# df['ssl_atr_up'] = ssl_up

# upper, rangema, lower = bta.PCC(df, period=20, mult=2)
# df['pcc_upper'] = upper
# df['pcc_rangema'] = rangema
# df['pcc_lower'] = lower

# df['sroc'] = bta.SROC(df, roclen=21, emalen=13, smooth=21)

# df['roc'] = bta.ROC(df, column='close', period=21)

# df['t3_average'] = bta.T3(df, length=5)

# df['mastreak'] = bta.MAStreak(df, period=4, column='close')

# df['rmi'] = bta.RMI(df, length=20, mom=5)

# df['zema'] = bta.ZEMA(df, period=21, column='close')

# print(df.tail(25))

### Indicatormin
# import pandas as pd
# import numpy as np

# # Sample data
# data = {
#     'high': [1, 2, 3, 4, 5],
#     'low': [0.5, 1.5, 2.5, 3.5, 4.5],
#     'close': [0.8, 1.8, 2.8, 3.8, 4.8]
# }
# df = pd.DataFrame(data)
# df['prev_close'] = df['close'].shift(1)

# # Instantiate IndicatorMixin
# indicator = bta.IndicatorMixin()

# # Test _check_fillna
# series = pd.Series([np.nan, 2, np.nan, 4, 5])
# indicator._fillna = True
# filled_series = indicator._check_fillna(series, value=0)
# print("Filled series:")
# print(filled_series)

# # Test _true_range
# true_range = indicator._true_range(df['high'], df['low'], df['prev_close'])
# print("True Range:")
# print(true_range)


# ## DropNA function
# # Sample data with NaNs
# data_with_nans = {
#     'A': [1, 2, np.nan, 4, 5],
#     'B': [5, 4, np.nan, 2, 1],
#     'C': [np.nan, 2, 3, np.nan, 5]
# }
# df_with_nans = pd.DataFrame(data_with_nans)

# # Test dropna function
# cleaned_df = bta.dropna(df_with_nans)
# print("DataFrame after dropna:")
# print(cleaned_df)

###SMA Example
# # Sample series
# series = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])

# # Test _sma function
# sma_series = bta._sma(series, periods=3)
# print("Simple Moving Average:")
# print(sma_series)

# # Sample series
# series = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])

# # Test _ema function
# ema_series = _ema(series, periods=3)
# print("Exponential Moving Average:")
# print(ema_series)


# ## GetMinMax
# # Sample series
# series1 = pd.Series([1, 2, 3, 4, 5])
# series2 = pd.Series([5, 4, 3, 2, 1])

# # Test _get_min_max function for min
# min_series = bta.get_min_max(series1, series2, function="min")
# print("Min of series1 and series2:")
# print(min_series)

# # Test _get_min_max function for max
# max_series = bta.get_min_max(series1, series2, function="max")
# print("Max of series1 and series2:")
# print(max_series)

# df['tsi'] = bta.TSI(df['close'], 25, 13)
# df['uo'] = bta.UltimateOscillator(df['high'], df['low'], df['close'], 7, 14, 28)
# stoch = bta.StochasticsOscillator(df, 'high', 'low', 'close', 14, 3)
# df['stoch'] = stoch['stoch']
# df['stoch_signal'] = stoch['stoch_signal']
# df['stoch_hist'] = stoch['stoch_hist']
# df['williams_r'] = bta.WilliamsR(df['high'], df['low'], df['close'], 14)

# stoch_rsi = bta.StochRSI(df, 'close', 14, 3, 3)
# df['stoch_rsi'] = stoch_rsi['stoch_rsi']
# df['stoch_rsi_k'] = stoch_rsi['stoch_rsi_k']
# df['stoch_rsi_d'] = stoch_rsi['stoch_rsi_d']

# df['kama'] = bta.KAMA(df['close'], 10, 2, 30)
# df['ao'] = bta.AwesomeOscillator(df['high'], df['low'], 5, 34)
# pvo = bta.PVO(df)
# df['pvo'] = pvo['pvo']
# df['pvo_signal'] = pvo['pvo_signal']
# df['pvo_hist'] = pvo['pvo_hist']
# pvo = bta.PVO(df)
# df['pvo'] = pvo['pvo']
# df['pvo_signal'] = pvo['pvo_signal']
# df['pvo_hist'] = pvo['pvo_hist']
# ppo = bta.PPO(df)
# df['ppo'] = ppo['ppo']
# df['ppo_signal'] = ppo['ppo_signal']
# df['ppo_hist'] = ppo['ppo_hist']

# cr = bta.Cumulative_Return(df)
# df['cumulative_return'] = cr

# dlr = bta.Daily_Log_Return(df)
# df['daily_log_return'] = dlr

# dr = bta.Daily_Return(df)
# df['daily_return'] = dr

# min_max_series = bta.get_min_max(series1, series2, function)
# df['min_max'] = min_max_series

# ema = bta._ema(series, periods)
# df['ema'] = ema

# sma = _sma(series, periods)
# df['sma'] = sma

# dropna = bta.dropna(df)

# zscore = bta.ZScore(series)
# df['zscore'] = zscore

# tr = bta.True_Range(df)
# df['true_range'] = tr

# padded_array = SameLength(bigger, shorter)

# leledc_major_minor = populate_leledc_major_minor(df, maj_qual, min_qual, maj_len, min_len)

# grown_value = Linear_Growth(start, end, start_time, end_time, trade_time)

# count = Consecutive_Count(consecutive_diff)

# maj_len, min_len = bta.Calculate_Exhaustion_Lengths(df)
# df['maj_len'] = maj_len
# df['min_len'] = min_len

# maj_qual, min_qual = bta.Calculate_Exhaustion_Candles(df, window=3, multiplier=2)
# df['maj_qual'] = maj_qual
# df['min_qual'] = min_qual

# Example usage:
# df = pd.DataFrame({'close': [1, 2, 3, 2, 1, 2, 3]})
# window = 3
# multiplier = 2
# maj_qual, min_qual = bta.Calculate_Exhaustion_Candles(df, window, multiplier)
# df['maj_qual'] = maj_qual
# df['min_qual'] = min_qual

# atr = bta.ATR(df)
# df['atr'] = atr

# adi = bta.Accumulation_Distribution_Index(high=df['high'], low=df['low'], close=df['close'], volume=df['volume'], fillna=True)
# df['adi'] = adi

# cmf_df = bta.Chaikin_Money_Flow(df, src_cols=('high', 'low', 'close', 'volume'), window=20, fillna=True)
# df['cmf'] = cmf_df['cmf']

# eom_df = bta.Ease_Of_Movement(df, src_cols=('high', 'low', 'volume'), window=14, fillna=True)
# df['eom'] = eom_df['eom']

# seom_df = bta.Sma_Ease_Of_Movement(df, src_cols=('high', 'low', 'volume'), window=14, fillna=True)
# df['seom'] = seom_df['seom']

# fi_df = bta.Force_Index(df, src_cols=('close', 'volume'), window=13, fillna=True)
# df['fi'] = fi_df['fi']

# mfi_df = bta.Money_Flow_Index(df, src_cols=('high', 'low', 'close', 'volume'), window=14, fillna=True)
# df['mfi'] = mfi_df['mfi']

# nvi_df = bta.Negative_Volume_Index(df, src_cols=('close', 'volume'), fillna=True)
# df['nvi'] = nvi_df['nvi']


# obv_df = bta.On_Balance_Volume(df, src_cols=('close', 'volume'), fillna=True)
# df['obv'] = obv_df['obv']


# obv_osc_df = bta.OBV_Oscillator(df, src_cols=('close', 'volume'), channel=10, average=21, fillna=True)
# df['OBV_Oscillator'] = obv_osc_df['OBV_Oscillator']

# vpt_df =bta.Volume_Price_Trend(df, src_cols=('close', 'volume'), fillna=True, smoothing_factor=10, dropnans=True)
# df['Volume_Price_Trend'] = vpt_df['Volume_Price_Trend']

# vwap_df = bta.Volume_Weighted_Average_Price(df, src_cols=('high', 'low', 'close', 'volume'), window=14, fillna=True)
# df['Volume_Weighted_Average_Price'] = vwap_df['Volume_Weighted_Average_Price']

### After refactoring:

# exhaustion = bta.Exhaustion_Bars(df)
# df['leledc_major'] = exhaustion['leledc_major']
# df['leledc_minor'] = exhaustion['leledc_minor']

# dynamic_exhaustion = bta.Dynamic_Exhaustion_Bars(df)
# df['dynamic_leledc_major'] = dynamic_exhaustion['leledc_major']
# df['dynamic_leledc_minor'] = dynamic_exhaustion['leledc_minor']

# pin = bta.Pinbar(df)
# df['pinbar_sell'] = pin['pinbar_sell']
# df['pinbar_buy'] = pin['pinbar_buy']

# ha_df = bta.HeikinAshi(df)
# df['ha_close'] = ha_df['ha_close']
# df['ha_open'] = ha_df['ha_open']
# df['ha_high'] = ha_df['ha_high']
# df['ha_low'] = ha_df['ha_low']

# lr_df = bta.LinRegCandles(df)
# df['lrc_open'] = lr_df['bopen']
# df['lrc_high'] = lr_df['bhigh']
# df['lrc_low'] = lr_df['blow']
# df['lrc_close'] = lr_df['bclose']
# df['lrc_signal'] = lr_df['signal']

# df['ao'] = bta.AwesomeOscillator(df['high'], df['low'], 5, 34)
df['ao'] = bta.awesome_oscillator(df['high'], df['low'], 5, 34)

print(df.tail(25))


    ----- End of test copy.py -----

    prompts.md

    ----- Start of prompts.md -----

GPT Prompt:
1. You are a developer with extensive knowledge of Python and Pinescript. You have this project where you are converting Pinscripts into Python functions so that you can use these in a library for further data analysis in python. The project structure and code of the Python code will follow. After that wait for further instructions about the pinescript to convert. Is that understood?

2. The following pinsecript should be converted into a python function. If this pinescript is depending on other indicators from other libraries (e.g. pandas-ta), do not use that, but instead create additional functions that will take care of the missing indicators. If the indicators are already available in the given project, then use these indicators. Is this clear?

3. Further instructions based on output GPT.

GPT prompt

1. You are a developer with extensive knowledge of Python and Technical Indicators in Trading. You enherited a project where trading technical analsis indicators are programmed in a TA library with Python functions. However you noticed that the previous programmer was very inconsistent in its programming and functions are build in different ways. Your task is to refactor the code so that all the functions have the same building style, input method, calculation method and output method. Also watch for redundant code and if detected solve this too by pointing to the correct funtion.
The project structure and code of the Python code will follow next. After that wait for further instructions about the definitive way each function should be build for consistency.
Is that understood?

2. The code should be refactored into the same format style as previously mentioned. 
Please be extra aware of the naming convention of the functions, the way the descriptions are written, including the "call with:" example and the way the output is provided by means of the df_copy method and all the dataframe column names should be in lowercase, and keep the output limited to two decimals behind the comma or .. 
Please use the same function style and buildup, inputs and output style, example in the description like "call with" and more from the next example I will provide you next. So format to match the desired style and including a brief description of the indicator's purpose and functionality, with lowercase column names and limiting the output to two decimal places, ensure consistency in how single-column indicators are handled. After this prompt I will provide you with the different modules that have to be refactored.
Is this clear?

3. Here is the example function:

def Waddah_Attar_Explosion(df, sensitivity=150, fast_length=20, slow_length=40, channel_length=20, mult=2.0):
   '''
    Waddah Attar Explosion Indicator

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain columns: 'open', 'high', 'low', and 'close'.
    - sensitivity (int): Sensitivity factor for the indicator. Default is 150.
    - fast_length (int): Length for the fast EMA. Default is 20.
    - slow_length (int): Length for the slow EMA. Default is 40.
    - channel_length (int): Length for the Bollinger Bands. Default is 20.
    - mult (float): Standard deviation multiplier for the Bollinger Bands. Default is 2.0.

    Call with:
        WAE = bta.Waddah_Attar_Explosion(df)
        df['trend_up'] = WAE['trend_up']
        df['trend_down'] = WAE['trend_down']
        df['explosion_line'] = WAE['explosion_line']
        df['dead_zone_line'] = WAE['dead_zone_line']

    Returns:
    - pd.DataFrame: DataFrame with 'trend_up', 'trend_down', 'explosion_line', and 'dead_zone_line' columns.
    '''
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['open', 'high', 'low', 'close']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # print("DataFrame columns:", df.columns)  # Debug print
    # print("First few rows of the DataFrame:\n", df.head())  # Debug print

    # Calculate DEAD_ZONE
    dead_zone = RMA(TR(df), 100) * 3.7
    # print("DEAD_ZONE calculated")  # Debug print

    # Calculate MACD
    macd_fast = EMA(df, 'close', fast_length)
    macd_slow = EMA(df, 'close', slow_length)
    macd_diff = macd_fast - macd_slow
    t1 = (macd_diff - macd_diff.shift(1)) * sensitivity
    # print("MACD and t1 calculated")  # Debug print

    # Calculate Bollinger Bands
    bb = BollingerBands(df, column='close', period=channel_length, std_dev=mult)
    e1 = bb['BB_upper'] - bb['BB_lower']
    # print("Bollinger Bands calculated")  # Debug print

    trend_up = np.where(t1 >= 0, t1, 0)
    trend_down = np.where(t1 < 0, -t1, 0)

    df_copy['trend_up'] = trend_up.round(2)
    df_copy['trend_down'] = trend_down.round(2)
    df_copy['explosion_line'] = e1.round(2)
    df_copy['dead_zone_line'] = dead_zone.round(2)

    return df_copy[['trend_up', 'trend_down', 'explosion_line', 'dead_zone_line']]


GPT Prompt:
1. You are a developer with extensive knowledge of Python and Technical Indicators in Trading. You have this project where you are converting Third party Python code into your own TA library with Python functions so that you can use these within your own library in a consequent and familiar way for further data analysis in python. The project structure and code of the Python code will follow. After that wait for further instructions about the third party Python code to convert. Is that understood?

2. The following third party python should be converted into the same format as my own functions  and should also be added to their consequitive modules. Please check first if they already exist, if they do, then ignore these (but say that you will not create these). If the third party Python code is depending on other libraries (e.g. pandas-ta), do not use these external libraries, but instead create additional functions that will take care of the missing functions or indicators. If these dependend functions alreaty exist in your own project, then use those instead. Please be extra aware of the naming convention of these functions, the way the descriptions are written, including the "call with:" example and the way the output is provided by means of the df_copy method. 

3. Further instructions based on output GPT.


GPT Prompt:
1. I have a Readme file that is part of a complete python programm. It contains the descriptions of functions that are in the submoduled. However I have added more functions to these modules and I would like to recreate this Readme section so that it also contains the added funtions. In other words the Readme file is updated with the most current situation. 

I can give you the current modules Readme section now and later the complete contents of all other modules so that you can update the Readme section with this. Do you understand?


1. I now have a competely different question concerning the Readme file I have for this modules library. Can you help me with this too?


2. The original Readme file looks like this, but it now misses a lot of new functions we added to the different modules. Please rewrite this section with the information I give you in the next prompt. There you should extract the functions from the modules and add these to the Readme section in the same original style. Do you understand?

This is the original Readme section:

3. Further instructions based on output GPT.

ChatGPT prompt for refactoring:





[python] Here is an overview of the instructions used to refactor the code, ensuring consistency and clarity across all functions:

### Instructions for Refactoring the Code:

1. **Function Name and Description**:
   - Follow PEP-8 naming conventions.
   - Include a descriptive docstring detailing the function's purpose, parameters, usage example, and return values.
   - Start the docstring with a brief description of the indicator's purpose and functionality.

2. **Parameters**:
   - Clearly define parameters with default values where appropriate.
   - Explain each parameter in the docstring, including the data type and purpose.

3. **Input Validation**:
   - Ensure the input DataFrame contains the required columns.
   - Raise a `KeyError` if any required columns are missing.

4. **Calculations**:
   - Perform calculations step-by-step, with clear comments if necessary.
   - Use appropriate methods for moving averages (e.g., rolling mean for SMA, exponential weighted mean for EMA).

5. **Output**:
   - Return a DataFrame containing the new indicator columns.
   - Ensure all DataFrame column names are in lowercase.
   - Limit the output values to two decimal places using `.round(2)`.

6. **Example Calls**:
   - Include example calls in the docstring, showing how to use the function.
   - Demonstrate how to add the new columns to the original DataFrame.

### Example of a Refactored Function:

#### Heikin Ashi (HA) with Optional Pre and Post Smoothing:

```python
def heikin_ashi(df, pre_smoothing_period=None, post_smoothing_period=None):
    """
    Heikin Ashi (HA) with Optional Pre and Post Smoothing

    Heikin Ashi is a type of price chart that shares some characteristics with candlestick charts but differs due to the values used to plot them. 
    This modified version allows for optional smoothing of the original data before the Heikin Ashi calculation and/or smoothing of the Heikin Ashi values themselves, 
    aiming to provide a more refined and smoother representation of price action, making it easier to identify the trend.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain columns: 'open', 'high', 'low', and 'close'.
    - pre_smoothing_period (int, optional): Period for EMA pre-smoothing of the original data. If provided, original price bars are smoothed before Heikin Ashi calculations.
    - post_smoothing_period (int, optional): Period for EMA post-smoothing of Heikin Ashi values. If provided, Heikin Ashi values are smoothed post calculations.

    Call with:
        ha_df = bta.heikin_ashi(df)
        df['ha_close'] = ha_df['ha_close']
        df['ha_open'] = ha_df['ha_open']
        df['ha_high'] = ha_df['ha_high']
        df['ha_low'] = ha_df['ha_low']

    Returns:
    - pd.DataFrame: DataFrame with 'ha_open', 'ha_high', 'ha_low', and 'ha_close' columns.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['open', 'high', 'low', 'close']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # If pre-smoothing is required
    if pre_smoothing_period:
        df_copy['open'] = ema(df_copy, 'open', pre_smoothing_period)
        df_copy['close'] = ema(df_copy, 'close', pre_smoothing_period)
        df_copy['high'] = ema(df_copy, 'high', pre_smoothing_period)
        df_copy['low'] = ema(df_copy, 'low', pre_smoothing_period)

    # Regular Heikin Ashi calculations
    df_copy['ha_close'] = (df_copy['open'] + df_copy['high'] +
                           df_copy['low'] + df_copy['close']) / 4
    df_copy.reset_index(inplace=True)
    ha_open = [(df_copy['open'][0] + df_copy['close'][0]) / 2]
    [ha_open.append((ha_open[i] + df_copy['ha_close'].values[i]) / 2)
     for i in range(0, len(df_copy) - 1)]
    df_copy['ha_open'] = ha_open
    df_copy.set_index('index', inplace=True)
    df_copy['ha_high'] = df_copy[['ha_open', 'ha_close', 'high']].max(axis=1)
    df_copy['ha_low'] = df_copy[['ha_open', 'ha_close', 'low']].min(axis=1)

    # If post-smoothing is required
    if post_smoothing_period:
        df_copy['ha_open'] = ema(df_copy, 'ha_open', post_smoothing_period)
        df_copy['ha_high'] = ema(df_copy, 'ha_high', post_smoothing_period)
        df_copy['ha_low'] = ema(df_copy, 'ha_low', post_smoothing_period)
        df_copy['ha_close'] = ema(df_copy, 'ha_close', post_smoothing_period)

    # Limit to two decimal places
    df_copy['ha_open'] = df_copy['ha_open'].round(2)
    df_copy['ha_high'] = df_copy['ha_high'].round(2)
    df_copy['ha_low'] = df_copy['ha_low'].round(2)
    df_copy['ha_close'] = df_copy['ha_close'].round(2)

    return df_copy[['ha_open', 'ha_high', 'ha_low', 'ha_close']]
```

#### Awesome Oscillator (AO):

```python
def awesome_oscillator(df, window1=5, window2=34, fillna=False):
    """
    Awesome Oscillator (AO)

    The Awesome Oscillator is a momentum indicator used to measure market momentum.
    It is calculated by subtracting a 34-period simple moving average (SMA) of the
    median price from a 5-period SMA of the median price.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain columns: 'high' and 'low'.
    - window1 (int, optional): Short period. Default is 5.
    - window2 (int, optional): Long period. Default is 34.
    - fillna (bool, optional): If True, fill nan values with 0. Default is False.

    Call with:
        df['ao'] = bta.awesome_oscillator(df)

    Returns:
    - pd.DataFrame: DataFrame with 'ao' column.
    """
    df_copy = df.copy()

    median_price = 0.5 * (df['high'] + df['low'])
    min_periods_s = 0 if fillna else window1
    min_periods_l = 0 if fillna else window2
    df_copy['ao'] = (
        median_price.rolling(window1, min_periods=min_periods_s).mean()
        - median_price.rolling(window2, min_periods=min_periods_l).mean()
    )
    if fillna:
        df_copy['ao'] = df_copy['ao'].fillna(0)

    df_copy['ao'] = df_copy['ao'].round(2)
    return df_copy[['ao']]
```

#### Chande Momentum Oscillator (CMO):

```python
def chande_momentum_oscillator(df, length=14):
    """
    Chande Momentum Oscillator (CMO)

    The Chande Momentum Oscillator (CMO) is a technical momentum indicator developed by Tushar Chande. 
    It measures the amount that an asset's price has changed over a specified period of time.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the 'close' column.
    - length (int): Length for the CMO calculation. Default is 14.

    Call with:
        df['cmo'] = bta.chande_momentum_oscillator(df)

    For Signal line:
        df['cmo_signal'] = df['cmo'].rolling(window=10).mean().round(2)  # Using SMA for signal

    Returns:
    - pd.DataFrame: DataFrame with 'cmo' column.
    """
    df_copy = df.copy()

    mom = df['close'].diff()
    pos_mom = mom.where(mom > 0, 0)
    neg_mom = -mom.where(mom < 0, 0)
    sm1 = pos_mom.rolling(window=length).sum()
    sm2 = neg_mom.rolling(window=length).sum()
    df_copy['cmo'] = 100 * (sm1 - sm2) / (sm1 + sm2)

    df_copy['cmo'] = df_copy['cmo'].round(2)
    return df_copy[['cmo']]
```

### General Refactoring Steps:

1. **Rename Functions and Columns to Lowercase**:
   - Ensure function names and DataFrame columns are in lowercase.

2. **Add Detailed Descriptions**:
   - Add a brief description of the indicator's purpose at the start of the docstring.
   - Include parameters, usage examples, and return types in the docstring.

3. **Ensure Consistent Output Format**:
   - Ensure that all functions return a DataFrame with the new indicator columns.
   - Limit numeric output to two decimal places using `.round(2)`.

By following these steps, you can ensure that all functions are refactored consistently, making it easier to maintain and understand the code in the future


# Another refactoring prompt:
Sure! Here is a comprehensive prompt you can use to repeat this refactoring exercise in the future:

---

**Refactoring Prompt for Trading Technical Analysis Indicators**

### Objective:
Refactor the code for trading technical analysis indicators to ensure consistency in function structure, input methods, calculation methods, and output methods. Pay special attention to naming conventions, descriptions, and formatting. All functions should return a DataFrame with the new indicator columns, and all column names should be in lowercase. Numeric outputs should be limited to two decimal places.

### Instructions:

1. **Function Name and Description**:
   - Follow PEP-8 naming conventions (e.g., `snake_case` for function names).
   - Include a descriptive docstring detailing the function's purpose, parameters, usage example, and return values.
   - Start the docstring with a brief description of the indicator's purpose and functionality.

2. **Parameters**:
   - Clearly define parameters with default values where appropriate.
   - Explain each parameter in the docstring, including the data type and purpose.

3. **Input Validation**:
   - Ensure the input DataFrame contains the required columns.
   - Raise a `KeyError` if any required columns are missing.

4. **Calculations**:
   - Perform calculations step-by-step, with clear comments if necessary.
   - Use appropriate methods for moving averages (e.g., rolling mean for SMA, exponential weighted mean for EMA).

5. **Output**:
   - Return a DataFrame containing the new indicator columns.
   - Ensure all DataFrame column names are in lowercase.
   - Limit the output values to two decimal places using `.round(2)`.

6. **Example Calls**:
   - Include example calls in the docstring, showing how to use the function.
   - Demonstrate how to add the new columns to the original DataFrame.

### Example Refactored Function:

#### Heikin Ashi (HA) with Optional Pre and Post Smoothing:

```python
def heikin_ashi(df, pre_smoothing_period=None, post_smoothing_period=None):
    """
    Heikin Ashi (HA) with Optional Pre and Post Smoothing

    Heikin Ashi is a type of price chart that shares some characteristics with candlestick charts but differs due to the values used to plot them. 
    This modified version allows for optional smoothing of the original data before the Heikin Ashi calculation and/or smoothing of the Heikin Ashi values themselves, 
    aiming to provide a more refined and smoother representation of price action, making it easier to identify the trend.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain columns: 'open', 'high', 'low', and 'close'.
    - pre_smoothing_period (int, optional): Period for EMA pre-smoothing of the original data. If provided, original price bars are smoothed before Heikin Ashi calculations.
    - post_smoothing_period (int, optional): Period for EMA post-smoothing of Heikin Ashi values. If provided, Heikin Ashi values are smoothed post calculations.

    Call with:
        ha_df = bta.heikin_ashi(df)
        df['ha_close'] = ha_df['ha_close']
        df['ha_open'] = ha_df['ha_open']
        df['ha_high'] = ha_df['ha_high']
        df['ha_low'] = ha_df['ha_low']

    Returns:
    - pd.DataFrame: DataFrame with 'ha_open', 'ha_high', 'ha_low', and 'ha_close' columns.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['open', 'high', 'low', 'close']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # If pre-smoothing is required
    if pre_smoothing_period:
        df_copy['open'] = ema(df_copy, 'open', pre_smoothing_period)
        df_copy['close'] = ema(df_copy, 'close', pre_smoothing_period)
        df_copy['high'] = ema(df_copy, 'high', pre_smoothing_period)
        df_copy['low'] = ema(df_copy, 'low', pre_smoothing_period)

    # Regular Heikin Ashi calculations
    df_copy['ha_close'] = (df_copy['open'] + df_copy['high'] +
                           df_copy['low'] + df_copy['close']) / 4
    df_copy.reset_index(inplace=True)
    ha_open = [(df_copy['open'][0] + df_copy['close'][0]) / 2]
    [ha_open.append((ha_open[i] + df_copy['ha_close'].values[i]) / 2)
     for i in range(0, len(df_copy) - 1)]
    df_copy['ha_open'] = ha_open
    df_copy.set_index('index', inplace=True)
    df_copy['ha_high'] = df_copy[['ha_open', 'ha_close', 'high']].max(axis=1)
    df_copy['ha_low'] = df_copy[['ha_open', 'ha_close', 'low']].min(axis=1)

    # If post-smoothing is required
    if post_smoothing_period:
        df_copy['ha_open'] = ema(df_copy, 'ha_open', post_smoothing_period)
        df_copy['ha_high'] = ema(df_copy, 'ha_high', post_smoothing_period)
        df_copy['ha_low'] = ema(df_copy, 'ha_low', post_smoothing_period)
        df_copy['ha_close'] = ema(df_copy, 'ha_close', post_smoothing_period)

    # Limit to two decimal places
    df_copy['ha_open'] = df_copy['ha_open'].round(2)
    df_copy['ha_high'] = df_copy['ha_high'].round(2)
    df_copy['ha_low'] = df_copy['ha_low'].round(2)
    df_copy['ha_close'] = df_copy['ha_close'].round(2)

    return df_copy[['ha_open', 'ha_high', 'ha_low', 'ha_close']]
```

#### Awesome Oscillator (AO):

```python
def awesome_oscillator(df, window1=5, window2=34, fillna=False):
    """
    Awesome Oscillator (AO)

    The Awesome Oscillator is a momentum indicator used to measure market momentum.
    It is calculated by subtracting a 34-period simple moving average (SMA) of the
    median price from a 5-period SMA of the median price.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain columns: 'high' and 'low'.
    - window1 (int, optional): Short period. Default is 5.
    - window2 (int, optional): Long period. Default is 34.
    - fillna (bool, optional): If True, fill nan values with 0. Default is False.

    Call with:
        df['ao'] = bta.awesome_oscillator(df)

    Returns:
    - pd.DataFrame: DataFrame with 'ao' column.
    """
    df_copy = df.copy()

    median_price = 0.5 * (df['high'] + df['low'])
    min_periods_s = 0 if fillna else window1
    min_periods_l = 0 if fillna else window2
    df_copy['ao'] = (
        median_price.rolling(window1, min_periods=min_periods_s).mean()
        - median_price.rolling(window2, min_periods=min_periods_l).mean()
    )
    if fillna:
        df_copy['ao'] = df_copy['ao'].fillna(0)

    df_copy['ao'] = df_copy['ao'].round(2)
    return df_copy[['ao']]
```

#### Chande Momentum Oscillator (CMO):

```python
def chande_momentum_oscillator(df, length=14):
    """
    Chande Momentum Oscillator (CMO)

    The Chande Momentum Oscillator (CMO) is a technical momentum indicator developed by Tushar Chande. 
    It measures the amount that an asset's price has changed over a specified period of time.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the 'close' column.
    - length (int): Length for the CMO calculation. Default is 14.

    Call with:
        df['cmo'] = bta.chande_momentum_oscillator(df)

    For Signal line:
        df['cmo_signal'] = df['cmo'].rolling(window=10).mean().round(2)  # Using SMA for signal

    Returns:
    - pd.DataFrame: DataFrame with 'cmo' column.
    """
    df_copy = df.copy()

    mom = df['close'].diff()
    pos_mom = mom.where(mom > 0, 0)
    neg_mom = -mom.where(mom < 0, 0)
    sm1 = pos_mom.rolling(window=length).sum()
    sm2 = neg_mom.rolling(window=length).sum()
    df_copy['cmo'] = 100 * (sm1 - sm2) / (sm1 + sm2)

    df_copy['cmo'] = df_copy['cmo'].round(2)
    return df_copy[['cmo']]
```

### General Refactoring Steps:

1. **Rename Functions and Columns to Lowercase**:
   - Ensure function names and DataFrame columns are in lowercase.

2. **Add Detailed Descriptions**:
   - Add a brief description of the indicator's purpose at the start of the docstring.
   - Include parameters

, usage examples, and return types in the docstring.

3. **Ensure Consistent Output Format**:
   - Ensure that all functions return a DataFrame with the new indicator columns.
   - Limit numeric output to two decimal places using `.round(2)`.

By following these steps and examples, you can ensure that all functions are refactored consistently, making it easier to maintain and understand the code in the future.

---

Feel free to adjust the prompt and instructions as needed for your specific requirements.


    ----- End of prompts.md -----

    bamboo_ta/
        __init__.py

        ----- Start of __init__.py -----

# -*- coding: utf-8 -*-
from bamboo_ta.bamboo_ta import *
import numpy as np
from pandas import DataFrame
import pandas as pd

name = "bamboo_ta"
"""
.. moduleauthor:: DutchCryptoDad
"""

        ----- End of __init__.py -----

        statistics.py

        ----- Start of statistics.py -----

# -*- coding: utf-8 -*-
import numpy as np
import pandas as pd
from .bamboo_ta import *

        ----- End of statistics.py -----

        performance.py

        ----- Start of performance.py -----

# -*- coding: utf-8 -*-
import numpy as np
import pandas as pd
from .bamboo_ta import *

        ----- End of performance.py -----

        candles.py

        ----- Start of candles.py -----

# -*- coding: utf-8 -*-
import numpy as np
import pandas as pd
from .bamboo_ta import *
from .trend import *
from .utility import *
from.momentum import *


def Exhaustion_Bars(df, maj_qual=6, maj_len=12, min_qual=6, min_len=12, core_length=4):
    """
    Leledc Exhaustion Bars
    
    Infamous S/R Reversal Indicator

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'open', 'high', 'low', and 'close' columns.
    - maj_qual (int): Major quality parameter. Default is 6.
    - maj_len (int): Major length parameter. Default is 12.
    - min_qual (int): Minor quality parameter. Default is 6.
    - min_len (int): Minor length parameter. Default is 12.
    - core_length (int): Core length parameter. Default is 4.

    Call with:
        exhaustion = bta.Exhaustion_Bars(df)
        df['leledc_major'] = exhaustion['leledc_major']
        df['leledc_minor'] = exhaustion['leledc_minor']

    Returns:
    - pd.DataFrame: DataFrame with 'leledc_major' and 'leledc_minor' columns.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['open', 'high', 'low', 'close']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    bindex_maj, sindex_maj, trend_maj = 0, 0, 0
    bindex_min, sindex_min = 0, 0

    for i in range(len(df_copy)):
        close = df_copy['close'][i]

        if i < 1 or i - core_length < 0:
            df_copy.loc[i, 'leledc_major'] = np.nan
            df_copy.loc[i, 'leledc_minor'] = 0
            continue

        bindex_maj, sindex_maj = np.nan_to_num(bindex_maj), np.nan_to_num(sindex_maj)
        bindex_min, sindex_min = np.nan_to_num(bindex_min), np.nan_to_num(sindex_min)

        if close > df_copy['close'][i - core_length]:
            bindex_maj += 1
            bindex_min += 1
        elif close < df_copy['close'][i - core_length]:
            sindex_maj += 1
            sindex_min += 1

        update_major = False
        if bindex_maj > maj_qual and close < df_copy['open'][i] and df_copy['high'][i] >= df_copy['high'][i - maj_len:i].max():
            bindex_maj, trend_maj, update_major = 0, 1, True
        elif sindex_maj > maj_qual and close > df_copy['open'][i] and df_copy['low'][i] <= df_copy['low'][i - maj_len:i].min():
            sindex_maj, trend_maj, update_major = 0, -1, True

        df_copy.loc[i, 'leledc_major'] = trend_maj if update_major else np.nan if trend_maj == 0 else trend_maj

        if bindex_min > min_qual and close < df_copy['open'][i] and df_copy['high'][i] >= df_copy['high'][i - min_len:i].max():
            bindex_min = 0
            df_copy.loc[i, 'leledc_minor'] = -1
        elif sindex_min > min_qual and close > df_copy['open'][i] and df_copy['low'][i] <= df_copy['low'][i - min_len:i].min():
            sindex_min = 0
            df_copy.loc[i, 'leledc_minor'] = 1
        else:
            df_copy.loc[i, 'leledc_minor'] = 0

    return df_copy[['leledc_major', 'leledc_minor']]


def Dynamic_Exhaustion_Bars(df, window=500):
    """
    Dynamic Leledc Exhaustion Bars
    The lookback length and exhaustion bars adjust dynamically to the market conditions.

    This indicator dynamically adjusts the lookback length and the exhaustion bars based on the market's behavior,
    helping to identify potential reversals and trend strength.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the 'close' column.
    - window (int): Lookback window for z-score calculation. Default is 500.

    Call with:
        dynamic_exhaustion = bta.Dynamic_Exhaustion_Bars(df)
        df['dynamic_leledc_major'] = dynamic_exhaustion['leledc_major']
        df['dynamic_leledc_minor'] = dynamic_exhaustion['leledc_minor']

    Returns:
    - pd.DataFrame: DataFrame with 'leledc_major' and 'leledc_minor' columns.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['close']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    df_copy['close_pct_change'] = df_copy['close'].pct_change()
    df_copy['pct_change_zscore'] = ZScore(df_copy['close_pct_change'], window)
    df_copy['pct_change_zscore_smoothed'] = df_copy['pct_change_zscore'].rolling(window=3).mean()
    df_copy['pct_change_zscore_smoothed'] = df_copy['pct_change_zscore_smoothed'].fillna(1.0)

    zscore = df_copy['pct_change_zscore_smoothed'].to_numpy()
    zscore_multi = np.maximum(np.minimum(5.0 - zscore * 2, 5.0), 1.5)

    maj_qual, min_qual = Calculate_Exhaustion_Candles(df_copy, window, zscore_multi)
    
    df_copy['maj_qual'] = maj_qual
    df_copy['min_qual'] = min_qual

    maj_len, min_len = Calculate_Exhaustion_Lengths(df_copy)
    
    df_copy['maj_len'] = maj_len
    df_copy['min_len'] = min_len

    df_copy = populate_leledc_major_minor(df_copy, maj_qual, min_qual, maj_len, min_len)

    return df_copy[['leledc_major', 'leledc_minor']]


def Pinbar(df, smi=None):
    """
    Pinbar - Price Action Indicator

    Pinbars are an easy but sure indication of incoming price reversal.
    Signal confirmation with SMI (Stochastic Momentum Index) can enhance the accuracy of the signals.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'high', 'low', and 'close' columns.
    - smi (pandas.Series, optional): Optional Series for SMI. If not provided, it will be calculated internally.

    Call with:
        pin = bta.Pinbar(df)
        df['pinbar_sell'] = pin['pinbar_sell']
        df['pinbar_buy'] = pin['pinbar_buy']

    Returns:
    - pd.DataFrame: DataFrame with 'pinbar_sell' and 'pinbar_buy' columns populated.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['high', 'low', 'close']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    low = df_copy['low']
    high = df_copy['high']
    close = df_copy['close']
    
    tr = True_Range(df_copy)
    
    if smi is None:
        df_copy = SMI_Momentum(df_copy)
        smi = df_copy['smi']
    
    df_copy['pinbar_sell'] = (
        (high < high.shift(1)) &
        (close < high - (tr * 2 / 3)) &
        (smi < smi.shift(1)) &
        (smi.shift(1) > 40) &
        (smi.shift(1) < smi.shift(2))
    )

    df_copy['pinbar_buy'] = (
        (low > low.shift(1)) &
        (close > low + (tr * 2 / 3)) &
        (smi.shift(1) < -40) &
        (smi > smi.shift(1)) &
        (smi.shift(1) > smi.shift(2))
    )
    
    return df_copy[['pinbar_sell', 'pinbar_buy']]


def HeikinAshi(df, pre_smoothing_period=None, post_smoothing_period=None):
    """
    Heikin Ashi (HA) with Optional Pre and Post Smoothing

    Heikin Ashi is a type of price chart that shares some characteristics with candlestick charts but differs due to the values used to plot them. 
    This modified version allows for optional smoothing of the original data before the Heikin Ashi calculation and/or smoothing of the Heikin Ashi values themselves, 
    aiming to provide a more refined and smoother representation of price action, making it easier to identify the trend.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain columns: 'open', 'high', 'low', and 'close'.
    - pre_smoothing_period (int, optional): Period for EMA pre-smoothing of the original data. If provided, original price bars are smoothed before Heikin Ashi calculations.
    - post_smoothing_period (int, optional): Period for EMA post-smoothing of Heikin Ashi values. If provided, Heikin Ashi values are smoothed post calculations.

    Call with:
        ha_df = bta.HeikinAshi(df)
        df['ha_close'] = ha_df['ha_close']
        df['ha_open'] = ha_df['ha_open']
        df['ha_high'] = ha_df['ha_high']
        df['ha_low'] = ha_df['ha_low']

    Returns:
    - pd.DataFrame: DataFrame with 'ha_open', 'ha_high', 'ha_low', and 'ha_close' columns.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['open', 'high', 'low', 'close']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # If pre-smoothing is required
    if pre_smoothing_period:
        df_copy['open'] = EMA(df_copy, 'open', pre_smoothing_period)
        df_copy['close'] = EMA(df_copy, 'close', pre_smoothing_period)
        df_copy['high'] = EMA(df_copy, 'high', pre_smoothing_period)
        df_copy['low'] = EMA(df_copy, 'low', pre_smoothing_period)

    # Regular Heikin Ashi calculations
    df_copy['ha_close'] = (df_copy['open'] + df_copy['high'] +
                           df_copy['low'] + df_copy['close']) / 4
    df_copy.reset_index(inplace=True)
    ha_open = [(df_copy['open'][0] + df_copy['close'][0]) / 2]
    [ha_open.append((ha_open[i] + df_copy['ha_close'].values[i]) / 2)
     for i in range(0, len(df_copy) - 1)]
    df_copy['ha_open'] = ha_open
    df_copy.set_index('index', inplace=True)
    df_copy['ha_high'] = df_copy[['ha_open', 'ha_close', 'high']].max(axis=1)
    df_copy['ha_low'] = df_copy[['ha_open', 'ha_close', 'low']].min(axis=1)

    # If post-smoothing is required
    if post_smoothing_period:
        df_copy['ha_open'] = EMA(df_copy, 'ha_open', post_smoothing_period)
        df_copy['ha_high'] = EMA(df_copy, 'ha_high', post_smoothing_period)
        df_copy['ha_low'] = EMA(df_copy, 'ha_low', post_smoothing_period)
        df_copy['ha_close'] = EMA(df_copy, 'ha_close', post_smoothing_period)

    # Limit to two decimal places
    df_copy['ha_open'] = df_copy['ha_open'].round(2)
    df_copy['ha_high'] = df_copy['ha_high'].round(2)
    df_copy['ha_low'] = df_copy['ha_low'].round(2)
    df_copy['ha_close'] = df_copy['ha_close'].round(2)

    return df_copy[['ha_open', 'ha_high', 'ha_low', 'ha_close']]


def LinRegCandles(df, linreg_length=11, sma_signal=True, signal_length=11):
    """
    Linear Regression Candles with Optional Signal Line

    The Linear Regression Candles transform the traditional OHLC bars using a linear regression algorithm, 
    providing a smoothed representation of price action. The function also provides an optional signal line, 
    which can be either an SMA or an EMA of the Linear Regression Candle close. This signal line can help to 
    identify trends and potential trading signals.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain columns: 'open', 'high', 'low', and 'close'.
    - linreg_length (int, optional): Period for linear regression calculation. Default is 11.
    - sma_signal (bool, optional): If True, uses SMA for the signal line. If False, uses EMA. Default is True.
    - signal_length (int, optional): Period for the moving average signal line. Default is 11.

    Call with:
        lr_df = bta.LinRegCandles(df)
        df['lrc_open'] = lr_df['bopen']
        df['lrc_high'] = lr_df['bhigh']
        df['lrc_low'] = lr_df['blow']
        df['lrc_close'] = lr_df['bclose']
        df['lrc_signal'] = lr_df['signal']

    Returns:
    - pd.DataFrame: DataFrame with 'bopen', 'bhigh', 'blow', 'bclose' as the Linear Regression Candles, and 'signal' as the signal line.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['open', 'high', 'low', 'close']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # Calculate linear regression coefficients for open, high, low, and close
    df_copy['bopen'] = df_copy['open'].rolling(window=linreg_length).apply(
        lambda x: np.polyfit(np.arange(len(x)), x, 1)[1] + np.polyfit(np.arange(len(x)), x, 1)[0] * (len(x) - 1),
        raw=True
    )

    df_copy['bhigh'] = df_copy['high'].rolling(window=linreg_length).apply(
        lambda x: np.polyfit(np.arange(len(x)), x, 1)[1] + np.polyfit(np.arange(len(x)), x, 1)[0] * (len(x) - 1),
        raw=True
    )

    df_copy['blow'] = df_copy['low'].rolling(window=linreg_length).apply(
        lambda x: np.polyfit(np.arange(len(x)), x, 1)[1] + np.polyfit(np.arange(len(x)), x, 1)[0] * (len(x) - 1),
        raw=True
    )

    df_copy['bclose'] = df_copy['close'].rolling(window=linreg_length).apply(
        lambda x: np.polyfit(np.arange(len(x)), x, 1)[1] + np.polyfit(np.arange(len(x)), x, 1)[0] * (len(x) - 1),
        raw=True
    )

    # Calculate the signal line using SMA or EMA
    if sma_signal:
        df_copy['signal'] = df_copy['bclose'].rolling(window=signal_length).mean()
    else:
        df_copy['signal'] = df_copy['bclose'].ewm(span=signal_length, adjust=False).mean()

    # Limit to two decimal places
    df_copy['bopen'] = df_copy['bopen'].round(2)
    df_copy['bhigh'] = df_copy['bhigh'].round(2)
    df_copy['blow'] = df_copy['blow'].round(2)
    df_copy['bclose'] = df_copy['bclose'].round(2)
    df_copy['signal'] = df_copy['signal'].round(2)

    return df_copy[['bopen', 'bhigh', 'blow', 'bclose', 'signal']]

        ----- End of candles.py -----

        volume.py

        ----- Start of volume.py -----

# -*- coding: utf-8 -*-
import numpy as np
import pandas as pd
from .bamboo_ta import *
from .trend import EMA


def Accumulation_Distribution_Index(df, src_cols=('high', 'low', 'close', 'volume'), fillna=False):
    """
    Accumulation/Distribution Index (ADI)
    Acts as a leading indicator of price movements.
    
    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'high', 'low', 'close', and 'volume' columns.
    - src_cols (tuple): Tuple containing column names for 'high', 'low', 'close', and 'volume'. Default is ('high', 'low', 'close', 'volume').
    - fillna (bool): if True, fill nan values.

    Call with:
        adi_df = Accumulation_Distribution_Index(df, src_cols=('high', 'low', 'close', 'volume'), fillna=True)
        df['adi'] = adi_df['adi']

    Returns:
    - pd.DataFrame: DataFrame with 'adi' column.
    """
    high_col, low_col, close_col, volume_col = src_cols
    df_copy = df.copy()

    # Calculate the ADI values
    clv = ((df_copy[close_col] - df_copy[low_col]) - (df_copy[high_col] - df_copy[close_col])) / (df_copy[high_col] - df_copy[low_col])
    clv = clv.fillna(0.0)  # float division by zero
    adi = clv * df_copy[volume_col]
    adi = adi.cumsum()
    if fillna:
        adi = adi.fillna(0)

    df_copy['adi'] = adi

    return df_copy[['adi']]


def Chaikin_Money_Flow(df, src_cols=('high', 'low', 'close', 'volume'), window=20, fillna=False):
    """
    Chaikin Money Flow (CMF)
    Measures the amount of Money Flow Volume over a specific period.
    
    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'high', 'low', 'close', and 'volume' columns.
    - src_cols (tuple): Tuple containing column names for 'high', 'low', 'close', and 'volume'. Default is ('high', 'low', 'close', 'volume').
    - window (int): n period.
    - fillna (bool): if True, fill nan values.

    Call with:
        cmf_df = Chaikin_Money_Flow(df, src_cols=('high', 'low', 'close', 'volume'), window=20, fillna=True)
        df['cmf'] = cmf_df['cmf']

    Returns:
    - pd.DataFrame: DataFrame with 'cmf' column.
    """
    high_col, low_col, close_col, volume_col = src_cols
    df_copy = df.copy()

    # Calculate the CMF values
    mfv = ((df_copy[close_col] - df_copy[low_col]) - (df_copy[high_col] - df_copy[close_col])) / (df_copy[high_col] - df_copy[low_col])
    mfv = mfv.fillna(0.0)  # float division by zero
    mfv *= df_copy[volume_col]
    min_periods = 0 if fillna else window
    cmf = mfv.rolling(window, min_periods=min_periods).sum() / df_copy[volume_col].rolling(window, min_periods=min_periods).sum()
    if fillna:
        cmf = cmf.fillna(0)

    df_copy['cmf'] = cmf

    return df_copy[['cmf']]


def Ease_Of_Movement(df, src_cols=('high', 'low', 'volume'), window=14, fillna=False):
    """
    Ease of movement (EoM, EMV)
    Relates an asset's price change to its volume and is useful for assessing trend strength.
    
    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'high', 'low', and 'volume' columns.
    - src_cols (tuple): Tuple containing column names for 'high', 'low', and 'volume'. Default is ('high', 'low', 'volume').
    - window (int): n period.
    - fillna (bool): if True, fill nan values.

    Call with:
        eom_df = Ease_Of_Movement(df, src_cols=('high', 'low', 'volume'), window=14, fillna=True)
        df['eom'] = eom_df['eom']

    Returns:
    - pd.DataFrame: DataFrame with 'eom' column.
    """
    high_col, low_col, volume_col = src_cols
    df_copy = df.copy()

    # Calculate the Ease of Movement values
    emv = ((df_copy[high_col].diff(1) + df_copy[low_col].diff(1)) * (df_copy[high_col] - df_copy[low_col])) / (2 * df_copy[volume_col])
    emv *= 100000000
    if fillna:
        emv = emv.fillna(0)

    df_copy['eom'] = emv

    return df_copy[['eom']]


def Sma_Ease_Of_Movement(df, src_cols=('high', 'low', 'volume'), window=14, fillna=False):
    """
    Signal Ease of movement (EoM, EMV)
    
    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'high', 'low', and 'volume' columns.
    - src_cols (tuple): Tuple containing column names for 'high', 'low', and 'volume'. Default is ('high', 'low', 'volume').
    - window (int): n period.
    - fillna (bool): if True, fill nan values.

    Call with:
        seom_df = Sma_Ease_Of_Movement(df, src_cols=('high', 'low', 'volume'), window=14, fillna=True)
        df['seom'] = seom_df['seom']

    Returns:
    - pd.DataFrame: DataFrame with 'seom' column.
    """
    emv_df = Ease_Of_Movement(df, src_cols=src_cols, window=window, fillna=fillna)
    min_periods = 0 if fillna else window
    sma_emv = emv_df['eom'].rolling(window, min_periods=min_periods).mean()
    if fillna:
        sma_emv = sma_emv.fillna(0)

    df_copy = df.copy()
    df_copy['seom'] = sma_emv

    return df_copy[['seom']]


def Force_Index(df, src_cols=('close', 'volume'), window=13, fillna=False):
    """
    Force Index (FI)
    Illustrates how strong the actual buying or selling pressure is.
    
    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'close' and 'volume' columns.
    - src_cols (tuple): Tuple containing column names for 'close' and 'volume'. Default is ('close', 'volume').
    - window (int): n period.
    - fillna (bool): if True, fill nan values.

    Call with:
        fi_df = Force_Index(df, src_cols=('close', 'volume'), window=13, fillna=True)
        df['fi'] = fi_df['fi']

    Returns:
    - pd.DataFrame: DataFrame with 'fi' column.
    """
    close_col, volume_col = src_cols
    df_copy = df.copy()

    # Calculate the Force Index values
    fi = (df_copy[close_col] - df_copy[close_col].shift(1)) * df_copy[volume_col]
    fi_ema = fi.ewm(span=window, adjust=False).mean()
    if fillna:
        fi_ema = fi_ema.fillna(0)

    df_copy['fi'] = fi_ema

    return df_copy[['fi']]


def Money_Flow_Index(df, src_cols=('high', 'low', 'close', 'volume'), window=14, fillna=False):
    """
    Money Flow Index (MFI)
    Uses both price and volume to measure buying and selling pressure.
    
    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'high', 'low', 'close', and 'volume' columns.
    - src_cols (tuple): Tuple containing column names for 'high', 'low', 'close', and 'volume'. Default is ('high', 'low', 'close', 'volume').
    - window (int): n period.
    - fillna (bool): if True, fill nan values.

    Call with:
        mfi_df = Money_Flow_Index(df, src_cols=('high', 'low', 'close', 'volume'), window=14, fillna=True)
        df['mfi'] = mfi_df['mfi']

    Returns:
    - pd.DataFrame: DataFrame with 'mfi' column.
    """
    high_col, low_col, close_col, volume_col = src_cols
    df_copy = df.copy()

    # Calculate typical price
    typical_price = (df_copy[high_col] + df_copy[low_col] + df_copy[close_col]) / 3.0
    up_down = np.where(
        typical_price > typical_price.shift(1),
        1,
        np.where(typical_price < typical_price.shift(1), -1, 0)
    )
    mfr = typical_price * df_copy[volume_col] * up_down

    # Calculate positive and negative money flow
    min_periods = 0 if fillna else window
    n_positive_mf = mfr.rolling(window, min_periods=min_periods).apply(
        lambda x: np.sum(np.where(x >= 0.0, x, 0.0)), raw=True
    )
    n_negative_mf = abs(mfr.rolling(window, min_periods=min_periods).apply(
        lambda x: np.sum(np.where(x < 0.0, x, 0.0)), raw=True
    ))

    # Calculate Money Flow Index
    mfi = n_positive_mf / n_negative_mf
    mfi = 100 - (100 / (1 + mfi))
    if fillna:
        mfi = mfi.fillna(50)

    df_copy['mfi'] = mfi

    return df_copy[['mfi']]


def Negative_Volume_Index(df, src_cols=('close', 'volume'), fillna=False):
    """
    Negative Volume Index (NVI)
    Uses volume changes to decide when the smart money is active.
    
    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'close' and 'volume' columns.
    - src_cols (tuple): Tuple containing column names for 'close' and 'volume'. Default is ('close', 'volume').
    - fillna (bool): if True, fill nan values.

    Call with:
        nvi_df = Negative_Volume_Index(df, src_cols=('close', 'volume'), fillna=True)
        df['nvi'] = nvi_df['nvi']

    Returns:
    - pd.DataFrame: DataFrame with 'nvi' column.
    """
    close_col, volume_col = src_cols
    df_copy = df.copy()

    # Calculate price change and volume decrease
    price_change = df_copy[close_col].pct_change()
    vol_decrease = df_copy[volume_col].shift(1) > df_copy[volume_col]

    # Initialize NVI series
    nvi = pd.Series(data=np.nan, index=df_copy.index, dtype="float64", name="nvi")
    nvi.iloc[0] = 1000

    # Calculate NVI
    for i in range(1, len(nvi)):
        if vol_decrease.iloc[i]:
            nvi.iloc[i] = nvi.iloc[i - 1] * (1.0 + price_change.iloc[i])
        else:
            nvi.iloc[i] = nvi.iloc[i - 1]

    if fillna:
        nvi = nvi.fillna(1000)

    df_copy['nvi'] = nvi

    return df_copy[['nvi']]


def On_Balance_Volume(df, src_cols=('close', 'volume'), fillna=False):
    """
    On-balance volume (OBV)
    Relates price and volume in the stock market. OBV is based on a cumulative total volume.
    
    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'close' and 'volume' columns.
    - src_cols (tuple): Tuple containing column names for 'close' and 'volume'. Default is ('close', 'volume').
    - fillna (bool): if True, fill nan values.

    Call with:
        obv_df = On_Balance_Volume(df, src_cols=('close', 'volume'), fillna=True)
        df['obv'] = obv_df['obv']

    Returns:
    - pd.DataFrame: DataFrame with 'obv' column.
    """
    close_col, volume_col = src_cols
    df_copy = df.copy()

    # Calculate OBV
    obv = np.where(df_copy[close_col] < df_copy[close_col].shift(1), -df_copy[volume_col], df_copy[volume_col])
    obv = pd.Series(obv, index=df_copy.index).cumsum()

    if fillna:
        obv = obv.fillna(0)

    df_copy['obv'] = obv

    return df_copy[['obv']]


def OBV_Oscillator(df, src_cols=('close', 'volume'), channel=10, average=21, fillna=False):
    """
    On Balance Volume (OBV) Oscillator

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'close' and 'volume' columns.
    - src_cols (tuple): Tuple containing column names for 'close' and 'volume'. Default is ('close', 'volume').
    - channel (int): OBV Channel Length. Default is 10.
    - average (int): OBV Average Length. Default is 21.
    - fillna (bool): If True, fill nan values.

    Call with:
        obv_osc_df = OBV_Oscillator(df, src_cols=('close', 'volume'), channel=10, average=21, fillna=True)
        df['OBV_Oscillator'] = obv_osc_df['OBV_Oscillator']

    Returns:
    - pd.DataFrame: DataFrame with 'OBV_Oscillator' column.
    """
    close_col, volume_col = src_cols
    df_copy = df.copy()

    # Calculate OBV
    df_copy['change'] = df_copy[close_col].diff()
    df_copy['OBV'] = np.where(df_copy['change'] > 0, df_copy[volume_col] * df_copy['change'], 
                              np.where(df_copy['change'] < 0, df_copy[volume_col] * df_copy['change'], 0))
    df_copy['OBV'] = df_copy['OBV'].cumsum()

    # Calculate OBV Oscillator
    ema_obv_channel = df_copy['OBV'].ewm(span=channel, adjust=False).mean()
    ema_abs_obv_channel = (df_copy['OBV'] - ema_obv_channel).abs().ewm(span=channel, adjust=False).mean()
    df_copy['OBV_Oscillator'] = ((df_copy['OBV'] - ema_obv_channel) / (0.015 * ema_abs_obv_channel)).ewm(span=average, adjust=False).mean()

    if fillna:
        df_copy['OBV_Oscillator'] = df_copy['OBV_Oscillator'].fillna(0)

    return df_copy[['OBV_Oscillator']]


def Volume_Price_Trend(df, src_cols=('close', 'volume'), fillna=False, smoothing_factor=None, dropnans=False):
    """
    Volume-price trend (VPT)
    Based on cumulative volume that adds or subtracts a multiple of the percentage change in share price trend.

    Call with:
        vpt_df = Volume_Price_Trend(df, src_cols=('close', 'volume'), fillna=True, smoothing_factor=10, dropnans=True)
        df['Volume_Price_Trend'] = vpt_df['Volume_Price_Trend']

    Args:
        df (pd.DataFrame): Input DataFrame which should contain 'close' and 'volume' columns.
        src_cols (tuple): Tuple containing column names for 'close' and 'volume'. Default is ('close', 'volume').
        fillna (bool): If True, fill nan values.
        smoothing_factor (int, optional): Will smooth VPT implementation with SMA.
        dropnans (bool): Drop nans after indicator calculated.

    Returns:
        pd.DataFrame: DataFrame with 'Volume_Price_Trend' column.
    """
    close_col, volume_col = src_cols
    df_copy = df.copy()

    vpt = (df_copy[close_col].pct_change() * df_copy[volume_col]).cumsum()
    if smoothing_factor:
        min_periods = 0 if fillna else smoothing_factor
        vpt = vpt.rolling(smoothing_factor, min_periods=min_periods).mean()
    if dropnans:
        vpt = vpt.dropna()
    if fillna:
        vpt = vpt.fillna(0)

    df_copy['Volume_Price_Trend'] = vpt
    return df_copy[['Volume_Price_Trend']]


def Volume_Weighted_Average_Price(df, src_cols=('high', 'low', 'close', 'volume'), window=14, fillna=False):
    """
    Volume Weighted Average Price (VWAP)
    Equals the dollar value of all trading periods divided by the total trading volume for the current day.

    Call with:
        vwap_df = Volume_Weighted_Average_Price(df, src_cols=('high', 'low', 'close', 'volume'), window=14, fillna=True)
        df['Volume_Weighted_Average_Price'] = vwap_df['Volume_Weighted_Average_Price']

    Args:
        df (pd.DataFrame): Input DataFrame which should contain 'high', 'low', 'close', and 'volume' columns.
        src_cols (tuple): Tuple containing column names for 'high', 'low', 'close', and 'volume'. Default is ('high', 'low', 'close', 'volume').
        window (int): n period.
        fillna (bool): If True, fill nan values.

    Returns:
        pd.DataFrame: DataFrame with 'Volume_Weighted_Average_Price' column.
    """
    high_col, low_col, close_col, volume_col = src_cols
    df_copy = df.copy()

    typical_price = (df_copy[high_col] + df_copy[low_col] + df_copy[close_col]) / 3.0
    typical_price_volume = typical_price * df_copy[volume_col]

    min_periods = 0 if fillna else window
    total_pv = typical_price_volume.rolling(window, min_periods=min_periods).sum()
    total_volume = df_copy[volume_col].rolling(window, min_periods=min_periods).sum()

    vwap = total_pv / total_volume
    if fillna:
        vwap = vwap.fillna(0)

    df_copy['Volume_Weighted_Average_Price'] = vwap
    return df_copy[['Volume_Weighted_Average_Price']]

        ----- End of volume.py -----

        trend.py

        ----- Start of trend.py -----

# -*- coding: utf-8 -*-
from pandas import DataFrame
import math
import numpy as np
import pandas as pd
# from .bamboo_ta import *
from .volatility import BollingerBands
# from .trend import SMA, EMA, LSMA, HMA, WMA
from .utility import *

def AlligatorBands(df, column="close", jaw_period=13, teeth_period=8, lips_period=5, jaw_shift=8, teeth_shift=5, lips_shift=3):
    """
    Bill Williams Alligator Indicator

    Call with:
        alligator_result = bta.AlligatorBands(df, "high", 13, 8, 5, jaw_shift=8, teeth_shift=5, lips_shift=3)
        df['jaw'] = alligator_result['jaw']
        df['teeth'] = alligator_result['teeth']
        df['lips'] = alligator_result['lips']

    Args:
    df (pd.DataFrame): DataFrame containing the data.
    column (str): The column name on which the Alligator is to be applied. Default is "close".
    jaw_period (int): Period for the Alligator's Jaw (blue line). Default is 13.
    teeth_period (int): Period for the Alligator's Teeth (red line). Default is 8.
    lips_period (int): Period for the Alligator's Lips (green line). Default is 5.
    jaw_shift (int): Number of periods to shift the Jaw line into the future. Default is 8.
    teeth_shift (int): Number of periods to shift the Teeth line into the future. Default is 5.
    lips_shift (int): Number of periods to shift the Lips line into the future. Default is 3.

    Returns:
    pd.DataFrame: DataFrame with 'jaw', 'teeth', and 'lips' columns added, optionally shifted into the future.
    """

    df['jaw'] = df[column].rolling(window=jaw_period).mean().shift(jaw_shift)
    df['teeth'] = df[column].rolling(
        window=teeth_period).mean().shift(teeth_shift)
    df['lips'] = df[column].rolling(
        window=lips_period).mean().shift(lips_shift)

    return df[['jaw', 'teeth', 'lips']]


def BollingerTrend(df, column="close", short_length=20, long_length=50, std_dev=2.0):
    """
    Bollinger Trend Indicator

    Call with:
        df['BBTrend'] = bta.BollingerTrend(df, "close", 20, 50, 2.0)

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the column specified.
    - column (str): The column on which BBTrend is to be calculated. Default is "close".
    - short_length (int): The period for the short Bollinger Bands. Default is 20.
    - long_length (int): The period for the long Bollinger Bands. Default is 50.
    - stddev (float): The standard deviation multiplier for the Bollinger Bands. Default is 2.0.

    Returns:
    - pandas.Series: A series of BBTrend values.
    """
    # Calculate short Bollinger Bands
    short_bb = BollingerBands(df, column=column, period=short_length, std_dev=std_dev)
    short_middle = short_bb['BB_middle']
    short_upper = short_bb['BB_upper']
    short_lower = short_bb['BB_lower']

    # Calculate long Bollinger Bands
    long_bb = BollingerBands(df, column=column, period=long_length, std_dev=std_dev)
    long_middle = long_bb['BB_middle']
    long_upper = long_bb['BB_upper']
    long_lower = long_bb['BB_lower']

    # Calculate BBTrend
    bbtrend = (np.abs(short_lower - long_lower) - np.abs(short_upper - long_upper)) / short_middle * 100
    bbtrend = bbtrend.round(2)
    
    return bbtrend


def BollingerTrendFastWithMA(df, column="close", short_length=10, long_length=50, short_stddev=1.0, long_stddev=2.0, ma_type="SMA", ma_length=14):
    """
    Bollinger Trend Indicator with selectable Moving Average

    This function calculates the Bollinger Trend (BBTrend) and applies a selected moving average to the BBTrend.

    Usage:
        BollingerTrendFast = bta.BollingerTrendFastWithMA(df, column="close", short_length=10, long_length=50, short_stddev=1.0, long_stddev=2.0, ma_type="SMA", ma_length=14)
        
        df['BollingerTrendFast'] = BollingerTrendFast['BBTrend']
        df['BollingerTrendFastMA'] = BollingerTrendFast['BBTrendMA']

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the column specified.
    - column (str): The column on which BBTrend is to be calculated. Default is "close".
    - short_length (int): The period for the short Bollinger Bands. Default is 10.
    - long_length (int): The period for the long Bollinger Bands. Default is 50.
    - short_stddev (float): The standard deviation multiplier for the short Bollinger Bands. Default is 1.0.
    - long_stddev (float): The standard deviation multiplier for the long Bollinger Bands. Default is 2.0.
    - ma_type (str): The type of moving average to use ("SMA", "EMA", "LSMA", "HMA", "WMA"). Default is "SMA".
    - ma_length (int): The period for the moving average. Default is 14.

    Returns:
    - pandas.DataFrame: DataFrame with 'BBTrend' and 'MA' columns.
    
    Example:
        result = BollingerTrendWithMA(df, column="close", short_length=10, long_length=50, short_stddev=1.0, long_stddev=2.0, ma_type="SMA", ma_length=14)
        df['BBTrend'] = result['BBTrend']
        df['MA'] = result['MA']
    """

    # Calculate short Bollinger Bands
    short_bb = BollingerBands(df, column=column, period=short_length, std_dev=short_stddev)
    short_middle = short_bb['BB_middle']
    short_upper = short_bb['BB_upper']
    short_lower = short_bb['BB_lower']

    # Calculate long Bollinger Bands
    long_bb = BollingerBands(df, column=column, period=long_length, std_dev=long_stddev)
    long_middle = long_bb['BB_middle']
    long_upper = long_bb['BB_upper']
    long_lower = long_bb['BB_lower']

    # Calculate BBTrend
    bbtrend = (np.abs(short_lower - long_lower) - np.abs(short_upper - long_upper)) / short_middle * 100
    bbtrend = bbtrend.round(2)

    # Select and calculate the moving average
    if ma_type == "SMA":
        ma = SMA(df.assign(BBTrend=bbtrend), column="BBTrend", period=ma_length)
    elif ma_type == "EMA":
        ma = EMA(df.assign(BBTrend=bbtrend), column="BBTrend", period=ma_length)
    elif ma_type == "LSMA":
        ma = LSMA(df.assign(BBTrend=bbtrend), column="BBTrend", period=ma_length)
    elif ma_type == "HMA":
        ma = HMA(df.assign(BBTrend=bbtrend), column="BBTrend", period=ma_length)
    elif ma_type == "WMA":
        ma = WMA(df.assign(BBTrend=bbtrend), column="BBTrend", period=ma_length)
    else:
        raise ValueError("Unsupported moving average type")

    # Returning as DataFrame
    result = df.copy()
    result['BBTrend'] = bbtrend.round(2)
    result['BBTrendMA'] = ma.round(2)

    return result[['BBTrend', 'BBTrendMA']]


def Breakouts(df, length=20):
    """ 
    S/R Breakouts and Retests

    Makes it easy to work with Support and Resistance.
    Find Retests, Breakouts and the next levels.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'high', 'low', and 'close' columns.
    - length (int): Lookback period.

    Call with:
        breakout = bta.Breakouts(df)
        df['support_level'] = breakout['support_level']
        df['resistance_level'] = breakout['resistance_level']
        df['support_breakout'] = breakout['support_breakout']
        df['resistance_breakout'] = breakout['resistance_breakout']
        df['support_retest'] = breakout['support_retest']
        df['potential_support_retest'] = breakout['potential_support_retest']
        df['resistance_retest'] = breakout['resistance_retest']
        df['potential_resistance_retest'] = breakout['potential_resistance_retest']

    Returns:
    - pd.DataFrame: DataFrame with event columns populated.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['high', 'low', 'close']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    high = df_copy['high']
    low = df_copy['low']
    close = df_copy['close']

    pl = low.rolling(window=length*2+1).min()
    ph = high.rolling(window=length*2+1).max()
    
    s_yLoc = low.shift(length + 1).where(low.shift(length + 1) > low.shift(length - 1), low.shift(length - 1))
    r_yLoc = high.shift(length + 1).where(high.shift(length + 1) > high.shift(length - 1), high.shift(length + 1))

    cu = close < s_yLoc.shift(length)
    co = close > r_yLoc.shift(length)

    s1 = (high >= s_yLoc.shift(length)) & (close <= pl.shift(length))
    s2 = (high >= s_yLoc.shift(length)) & (close >= pl.shift(length)) & (close <= s_yLoc.shift(length))
    s3 = (high >= pl.shift(length)) & (high <= s_yLoc.shift(length))
    s4 = (high >= pl.shift(length)) & (high <= s_yLoc.shift(length)) & (close < pl.shift(length))

    r1 = (low <= r_yLoc.shift(length)) & (close >= ph.shift(length))
    r2 = (low <= r_yLoc.shift(length)) & (close <= ph.shift(length)) & (close >= r_yLoc.shift(length))
    r3 = (low <= ph.shift(length)) & (low >= r_yLoc.shift(length))
    r4 = (low <= ph.shift(length)) & (low >= r_yLoc.shift(length)) & (close > ph.shift(length))

    df_copy['support_level'] = pl.diff().where(pl.diff().notna())
    df_copy['resistance_level'] = ph.diff().where(ph.diff().notna())
    
    df_copy['support_level'] = df_copy['support_level'].combine_first(df_copy['support_level'].shift())
    df_copy['resistance_level'] = df_copy['resistance_level'].combine_first(df_copy['resistance_level'].shift())
    
    df_copy['support_breakout'] = cu
    df_copy['resistance_breakout'] = co
    df_copy['support_retest'] = s1 | s2 | s3 | s4
    df_copy['potential_support_retest'] = s1 | s2 | s3
    df_copy['resistance_retest'] = r1 | r2 | r3 | r4
    df_copy['potential_resistance_retest'] = r1 | r2 | r3
    
    return df_copy[['support_level', 'resistance_level', 'support_breakout', 'resistance_breakout', 'support_retest', 'potential_support_retest', 'resistance_retest', 'potential_resistance_retest']]


def EMA(df, column="close", period=21):
    """
    Exponential Moving Average (EMA)

    Call with:
        df['ema'] = bta.EMA(df, "close", 50)

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the column specified.
    - column (str): The column on which EMA is to be calculated. Default is "close".
    - period (int): The period over which EMA is to be calculated. Default is 30.

    Returns:
    - pandas.Series: A series of EMA values.

    Description:
    The Exponential Moving Average gives more weight to recent prices and thus reacts more quickly to price changes than the Simple Moving Average.
    """

    ema = df[column].ewm(span=period, adjust=False).mean()
    
    return ema


def HMA(df, column="close", period=9):
    """
    Hull Moving Average (HMA)

    Call with:
        df['hma'] = bta.HMA(df, "close", 9)

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the column specified.
    - column (str): The column on which HMA is to be calculated. Default is "close".
    - period (int): The period over which HMA is to be calculated. Default is 9.

    Returns:
    - pandas.Series: A series of HMA values.

    Description:
    Hull Moving Average (HMA) is an improved moving average, responsive and with minimal lag. It involves the combination of WMA (Weighted Moving Average) with different periods.
    """

    # We're assuming that WMA is defined in the same file and thus is accessible here.
    half_length = math.floor(period / 2)
    sqrt_length = math.floor(math.sqrt(period))

    wma_half = WMA(df, column=column, period=half_length)
    wma_full = WMA(df, column=column, period=period)

    h = 2 * wma_half - wma_full
    h_df = DataFrame(h, columns=[column])
    hma = WMA(h_df, column=column, period=sqrt_length)

    return hma


def LSMA(df, column="close", period=21):
    """
    Least Squares Moving Average (LSMA)

    Call with:
        df['lsma'] = bta.LSMA(df, "close", 50)

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the column specified.
    - column (str): The column on which LSMA is to be calculated. Default is "close".
    - period (int): The period over which LSMA is to be calculated. Default is 21.

    Returns:
    - pandas.Series: A series of LSMA values.

    Description:
    LSMA uses linear regression to compute the trend of the data over a specified period. It fits a straight line to the data points using the method of least squares to depict the direction of movement.
    """
    lsma_values = []

    for i in range(period - 1, len(df)):
        # Extract the most recent N df points
        subset = df.iloc[i + 1 - period:i + 1]

        # Perform linear regression to fit a line
        x = np.arange(len(subset))
        y = subset[column].values
        slope, intercept = np.polyfit(x, y, 1)

        # Calculate the LSMA value using the linear equation
        lsma = intercept + slope * (period - 1)
        lsma_values.append(lsma)

    lsma = pd.Series(lsma_values, index=df.index[period - 1:])

    return lsma


def PCC(df, period=20, mult=2):
    """
    Percent Change Channel (PCC)
    PCC is like KC unless it uses percentage changes in price to set channel distance.
    https://www.tradingview.com/script/6wwAWXA1-MA-Streak-Change-Channel/

    Call with:
        upper, rangema, lower = bta.PCC(df, period=20, mult=2)
        df['pcc_upper'] = upper
        df['pcc_rangema'] = rangema
        df['pcc_lower'] = lower

    Args:
    df (pd.DataFrame): DataFrame containing the data.
    period (int): Period for the ZEMA calculation. Default is 20.
    mult (int): Multiplier for the range. Default is 2.

    Returns:
    tuple: Upper, RangeMA, and Lower bands as Series.
    """
    df_copy = df.copy()

    df_copy['previous_close'] = df_copy['close'].shift()
    df_copy['close_change'] = (df_copy['close'] - df_copy['previous_close']) / df_copy['previous_close'] * 100
    df_copy['high_change'] = (df_copy['high'] - df_copy['close']) / df_copy['close'] * 100
    df_copy['low_change'] = (df_copy['low'] - df_copy['close']) / df_copy['close'] * 100
    df_copy['delta'] = df_copy['high_change'] - df_copy['low_change']
    mid = ZEMA(df_copy, period, 'close_change')
    rangema = ZEMA(df_copy, period, 'delta')
    upper = mid + rangema * mult
    lower = mid - rangema * mult
    
    return upper, rangema, lower


def RMA(series, period):
    """
    Relative Moving Average (RMA) calculation.
    
    Parameters:
    - series (pandas.Series): Input series on which RMA is to be calculated.
    - period (int): The period over which RMA is to be calculated.
    
    Returns:
    - pandas.Series: A series of RMA values.
    """
    return series.ewm(alpha=1/period, adjust=False).mean()


def SMA(df, column="close", period=21):
    """
    Simple Moving Average (SMA)

    Call with:
        df['sma'] = bta.SMA(df, "close", 50)

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the column specified.
    - column (str): The column on which SMA is to be calculated. Default is "close".
    - period (int): The period over which SMA is to be calculated. Default is 30.

    Returns:
    - pandas.Series: A series of SMA values.

    Description:
    The Simple Moving Average is the unweighted mean of the previous 'period' data points.
    """

    sma = df[column].rolling(window=period).mean()
    
    return sma


def SSLChannels(df, length=10, mode='sma'):
    """
    SSL Channels
    Source: https://www.tradingview.com/script/xzIoaIJC-SSL-channel/
    Source: https://github.com/freqtrade/technical/blob/master/technical/indicators/indicators.py#L1025

    Call with:
        ssl_down, ssl_up = bta.SSLChannels(df, length=10, mode='sma')
        df['ssl_down'] = ssl_down
        df['ssl_up'] = ssl_up

    Args:
    df (pd.DataFrame): DataFrame containing the data.
    length (int): Period for the SMA calculation. Default is 10.
    mode (str): Type of moving average to use. Currently only 'sma' is supported.

    Returns:
    tuple: SSL Down and SSL Up series.
    """
    df_copy = df.copy()

    if mode not in ('sma'):
        raise ValueError(f"Mode {mode} not supported yet")
    
    df_copy['smaHigh'] = df_copy['high'].rolling(length).mean()
    df_copy['smaLow'] = df_copy['low'].rolling(length).mean()
    df_copy['hlv'] = np.where(df_copy['close'] > df_copy['smaHigh'], 1,
                              np.where(df_copy['close'] < df_copy['smaLow'], -1, np.NAN))
    df_copy['hlv'] = df_copy['hlv'].ffill()
    df_copy['sslDown'] = np.where(df_copy['hlv'] < 0, df_copy['smaHigh'], df_copy['smaLow'])
    df_copy['sslUp'] = np.where(df_copy['hlv'] < 0, df_copy['smaLow'], df_copy['smaHigh'])

    return df_copy['sslDown'], df_copy['sslUp']


def SSLChannelsATR(df, length=7):
    """
    SSL Channels with ATR
    SSL Channels with ATR: https://www.tradingview.com/script/SKHqWzql-SSL-ATR-channel/

    Call with:
        ssl_down, ssl_up = bta.SSLChannelsATR(df, length=7)
        df['ssl_atr_down'] = ssl_down
        df['ssl_atr_up'] = ssl_up

    Args:
    df (pd.DataFrame): DataFrame containing the data.
    length (int): Period for the SMA calculation. Default is 7.

    Returns:
    tuple: SSL Down and SSL Up series.
    """
    df_copy = df.copy()

    df_copy['ATR'] = ATR(df_copy, period=14)
    df_copy['smaHigh'] = df_copy['high'].rolling(length).mean() + df_copy['ATR']
    df_copy['smaLow'] = df_copy['low'].rolling(length).mean() - df_copy['ATR']
    df_copy['hlv'] = np.where(df_copy['close'] > df_copy['smaHigh'], 1, np.where(df_copy['close'] < df_copy['smaLow'], -1, np.NAN))
    df_copy['hlv'] = df_copy['hlv'].ffill()
    df_copy['sslDown'] = np.where(df_copy['hlv'] < 0, df_copy['smaHigh'], df_copy['smaLow'])
    df_copy['sslUp'] = np.where(df_copy['hlv'] < 0, df_copy['smaLow'], df_copy['smaHigh'])
    
    return df_copy['sslDown'], df_copy['sslUp']


def STDEV(series, period):
    """
    Calculate the standard deviation over a specified period.

    Parameters:
    - series (pd.Series): The data series to calculate the standard deviation for.
    - period (int): The period over which to calculate the standard deviation.

    Returns:
    - pd.Series: The standard deviation of the series.
    """
    return series.rolling(window=period).std()


def T3(df, length=5):
    """
    T3 Average by HPotter
    https://www.tradingview.com/script/qzoC9H1I-T3-Average/

    Call with:
        df['t3_average'] = bta.T3(df, length=5)

    Args:
    df (pd.DataFrame): DataFrame containing the data.
    length (int): Period for the EMA calculation. Default is 5.

    Returns:
    pd.Series: Series of T3 Average values.
    """
    df_copy = df.copy()

    df_copy['xe1'] = EMA(df_copy, column='close', period=length)
    df_copy['xe2'] = EMA(df_copy, column='xe1', period=length)
    df_copy['xe3'] = EMA(df_copy, column='xe2', period=length)
    df_copy['xe4'] = EMA(df_copy, column='xe3', period=length)
    df_copy['xe5'] = EMA(df_copy, column='xe4', period=length)
    df_copy['xe6'] = EMA(df_copy, column='xe5', period=length)
    
    b = 0.7
    c1 = -b*b*b
    c2 = 3*b*b+3*b*b*b
    c3 = -6*b*b-3*b-3*b*b*b
    c4 = 1+3*b+b*b*b+3*b*b
    
    df_copy['T3Average'] = c1 * df_copy['xe6'] + c2 * df_copy['xe5'] + c3 * df_copy['xe4'] + c4 * df_copy['xe3']
    
    return df_copy['T3Average']


def WMA(df, column="close", period=9):
    """
    TradingView-Style Weighted Moving Average (WMA)

    Call with:
        df['wma'] = bta.WMA(df, "close", 9)

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the column specified.
    - column (str): The column on which WMA is to be calculated. Default is "close".
    - period (int): The period over which WMA is to be calculated. Default is 9.

    Returns:
    - pandas.Series: A series of WMA values.

    Description:
    The Weighted Moving Average assigns weights linearly. The most recent data gets the highest weight.
    """
    weights = range(1, period + 1)
    numerator = df[column].rolling(window=period).apply(
        lambda x: sum(weights * x), raw=True)
    denominator = sum(weights)

    wma = numerator / denominator
    
    return wma


def ZEMA(df, period, column='close'):
    """
    Zero Lag Exponential Moving Average (ZEMA)
    Source: https://github.com/freqtrade/technical/blob/master/technical/indicators/overlap_studies.py#L79
    Modified slightly to use ta.EMA instead of technical ema

    Call with:
        df['zema'] = bta.ZEMA(df, period=21, column='close')

    Args:
    df (pd.DataFrame): DataFrame containing the data.
    period (int): Period for the EMA calculation.
    column (str): The column name on which the ZEMA is to be applied. Default is "close".

    Returns:
    pd.Series: Series of ZEMA values.
    """
    df_copy = df.copy()

    df_copy['ema1'] = EMA(df_copy, column=column, period=period)
    df_copy['ema2'] = EMA(df_copy, column='ema1', period=period)
    df_copy['d'] = df_copy['ema1'] - df_copy['ema2']
    df_copy['zema'] = df_copy['ema1'] + df_copy['d']
    
    return df_copy['zema']


def ZLEMA(df, column="close", period=21):
    """
    Zero Lag Exponential Moving Average (ZLEMA)

    Call with:
        df['zlema'] = bta.ZLEMA(df, "close", 21)

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the column specified.
    - column (str): The column on which ZLEMA is to be calculated. Default is "close".
    - period (int): The period over which ZLEMA is to be calculated. Default is 21.

    Returns:
    - pandas.Series: A series of ZLEMA values.

    Description:
    Zero Lag Exponential Moving Average (ZLEMA) is an EMA that adjusts for lag, making it more responsive to recent price changes. It uses lagged data differences to adjust the EMA calculation, thereby supposedly removing the inherent lag of EMA.
    """
    lag = int((period - 1) / 2)

    # Calculating the adjusted data series
    ema_data = df[column] + (df[column] - df[column].shift(lag))

    # Computing the EMA of the adjusted data series
    zlema = ema_data.ewm(span=period, adjust=False).mean()

    return zlema



        ----- End of trend.py -----

        utility.py

        ----- Start of utility.py -----

# -*- coding: utf-8 -*-
import math
import numpy as np
import pandas as pd
from .bamboo_ta import *
from scipy.signal import argrelextrema


def Calculate_Exhaustion_Lengths(df):
    """
    Calculate the average length of peaks and valleys to adjust the exhaustion bands dynamically
    
    Parameters:
    - df (pandas.DataFrame): Input DataFrame.

    Call with:
        maj_len, min_len = Calculate_Exhaustion_Lengths(df)
        df['maj_len'] = maj_len
        df['min_len'] = min_len

    Returns:
    - int, int: Average peak distance and average valley distance.
    """
    high_indices = argrelextrema(df['high'].to_numpy(), np.greater)[0]
    low_indices = argrelextrema(df['low'].to_numpy(), np.less)[0]

    if len(high_indices) < 2 or len(low_indices) < 2:
        return 0, 0

    avg_peak_distance = np.mean(np.diff(high_indices))
    std_peak_distance = np.std(np.diff(high_indices))
    avg_valley_distance = np.mean(np.diff(low_indices))
    std_valley_distance = np.std(np.diff(low_indices))

    maj_len = int(avg_peak_distance + std_peak_distance)
    min_len = int(avg_valley_distance + std_valley_distance)

    return maj_len, min_len


def Calculate_Exhaustion_Candles(df, window=1, multiplier=1):
    """
    Calculate the average consecutive length of ups and downs to adjust the exhaustion bands dynamically
    
    Parameters:
    - df (pandas.DataFrame): Input DataFrame.
    - window (int): Lookback window for calculation.
    - multiplier (int or np.ndarray): Scalar or array of multipliers.

    Call with:
        maj_qual, min_qual = Calculate_Exhaustion_Candles(df, window, multiplier)
        df['maj_qual'] = maj_qual
        df['min_qual'] = min_qual

    Returns:
    - np.ndarray, np.ndarray: Arrays of major and minor quality values.
    """
    consecutive_diff = np.sign(df['close'].diff())
    maj_qual = np.zeros(len(df))
    min_qual = np.zeros(len(df))

    # Ensure multiplier is an array
    if isinstance(multiplier, (int, float)):
        multiplier = np.full(len(df), multiplier)
    elif isinstance(multiplier, np.ndarray) and multiplier.shape[0] != len(df):
        raise ValueError("Length of multiplier array must match the length of the DataFrame")

    for i in range(len(df)):
        idx_range = consecutive_diff[i - window + 1:i + 1] if i >= window else consecutive_diff[:i + 1]
        avg_consecutive = Consecutive_Count(idx_range)
        if isinstance(avg_consecutive, np.ndarray):
            avg_consecutive = avg_consecutive.item()
        maj_qual[i] = int(avg_consecutive * (3 * multiplier[i])) if not np.isnan(avg_consecutive) else 0
        min_qual[i] = int(avg_consecutive * (3 * multiplier[i])) if not np.isnan(avg_consecutive) else 0

    return maj_qual, min_qual

def Consecutive_Count(consecutive_diff):
    """
    Calculate the average consecutive count of non-zero differences
    
    Parameters:
    - consecutive_diff (np.ndarray): Array of consecutive differences.

    Returns:
    - float: Average consecutive count.
    """
    non_zero_diff = np.where(consecutive_diff != 0)[0]
    if len(non_zero_diff) < 2:
        return 0
    return np.mean(np.abs(np.diff(non_zero_diff)))


def Linear_Decay(start: float, end: float, start_time: int, end_time: int, trade_time: int) -> float:
    """
    Simple linear decay function. Decays from start to end after end_time minutes (starts after start_time minutes)

    Parameters:
    - start (float): Starting value.
    - end (float): Ending value.
    - start_time (int): Start time in minutes.
    - end_time (int): End time in minutes.
    - trade_time (int): Current trade time in minutes.

    Call with:
        decayed_value = Linear_Decay(start, end, start_time, end_time, trade_time)

    Returns:
    - float: Decayed value.
    """
    time = max(0, trade_time - start_time)
    rate = (start - end) / (end_time - start_time)
    return max(end, start - (rate * time))


def Linear_Growth(start: float, end: float, start_time: int, end_time: int, trade_time: int) -> float:
    """
    Simple linear growth function. Grows from start to end after end_time minutes (starts after start_time minutes)

    Parameters:
    - start (float): Starting value.
    - end (float): Ending value.
    - start_time (int): Start time in minutes.
    - end_time (int): End time in minutes.
    - trade_time (int): Current trade time in minutes.

    Call with:
        grown_value = Linear_Growth(start, end, start_time, end_time, trade_time)

    Returns:
    - float: Grown value.
    """
    time = max(0, trade_time - start_time)
    rate = (end - start) / (end_time - start_time)
    return min(end, start + (rate * time))


def populate_leledc_major_minor(df, maj_qual, min_qual, maj_len, min_len):
    """
    Populate Leledc Major and Minor columns

    Parameters:
    - df (pandas.DataFrame): Input DataFrame.
    - maj_qual (np.ndarray): Array of major quality values.
    - min_qual (np.ndarray): Array of minor quality values.
    - maj_len (int): Major length value.
    - min_len (int): Minor length value.

    Call with:
        leledc_major_minor = populate_leledc_major_minor(df, maj_qual, min_qual, maj_len, min_len)

    Returns:
    - pd.DataFrame: DataFrame with populated columns.
    """
    df_copy = df.copy()
    bindex_maj, sindex_maj, trend_maj = 0, 0, 0
    bindex_min, sindex_min = 0, 0

    df_copy['leledc_major'] = np.nan
    df_copy['leledc_minor'] = 0

    for i in range(1, len(df_copy)):
        close = df_copy['close'][i]
        short_length = i if i < 4 else 4

        if close > df_copy['close'][i - short_length]:
            bindex_maj += 1
            bindex_min += 1
        elif close < df_copy['close'][i - short_length]:
            sindex_maj += 1
            sindex_min += 1

        update_major = False
        if bindex_maj > maj_qual[i] and close < df_copy['open'][i] and df_copy['high'][i] >= df_copy['high'][i - maj_len:i].max():
            bindex_maj, trend_maj, update_major = 0, 1, True
        elif sindex_maj > maj_qual[i] and close > df_copy['open'][i] and df_copy['low'][i] <= df_copy['low'][i - maj_len:i].min():
            sindex_maj, trend_maj, update_major = 0, -1, True

        df_copy.at[i, 'leledc_major'] = trend_maj if update_major else np.nan if trend_maj == 0 else trend_maj
        if bindex_min > min_qual[i] and close < df_copy['open'][i] and df_copy['high'][i] >= df_copy['high'][i - min_len:i].max():
            bindex_min = 0
            df_copy.at[i, 'leledc_minor'] = -1
        elif sindex_min > min_qual[i] and close > df_copy['open'][i] and df_copy['low'][i] <= df_copy['low'][i - min_len:i].min():
            sindex_min = 0
            df_copy.at[i, 'leledc_minor'] = 1
        else:
            df_copy.at[i, 'leledc_minor'] = 0

    return df_copy


def SameLength(bigger, shorter):
    """
    Ensures the shorter array has the same length as the bigger array by padding with NaN values.

    Parameters:
    - bigger (np.ndarray): The array with the larger size.
    - shorter (np.ndarray): The array with the smaller size.

    Call with:
        padded_array = SameLength(bigger, shorter)

    Returns:
    - np.ndarray: The shorter array padded with NaN values to match the size of the bigger array.
    """
    return np.concatenate((np.full((bigger.shape[0] - shorter.shape[0]), np.nan), shorter))


def ZScore(series, window=500):
    """
    Calculate the z-score of a series.

    Parameters:
    - series (pd.Series): Input series.
    - window (int): Lookback window for mean and standard deviation calculation.

    Call with:
        zscore = ZScore(series)
        df['zscore'] = zscore

    Returns:
    - pd.Series: Z-score series.
    """
    mean = series.rolling(window=window, min_periods=1).mean()
    std = series.rolling(window=window, min_periods=1).std(ddof=0)
    zscore = (series - mean) / std
    zscore = zscore.fillna(0)  # Fill NaN values with 0 to avoid issues with calculations

    return zscore


class IndicatorMixin:
    """Util mixin indicator class"""

    _fillna = False

    def _check_fillna(self, series: pd.Series, value: int = 0) -> pd.Series:
        """Check if fillna flag is True.

        Parameters:
        - series (pandas.Series): Calculated indicator series.
        - value (int): Value to fill gaps; if -1 fill values using 'backfill' mode.

        Returns:
        - pd.Series: New feature generated.
        """
        if self._fillna:
            series_output = series.copy(deep=False)
            series_output = series_output.replace([np.inf, -np.inf], np.nan)
            if isinstance(value, int) and value == -1:
                series = series_output.ffill().bfill()
            else:
                series = series_output.ffill().fillna(value)
        return series

    @staticmethod
    def _true_range(high: pd.Series, low: pd.Series, prev_close: pd.Series) -> pd.Series:
        tr1 = high - low
        tr2 = (high - prev_close).abs()
        tr3 = (low - prev_close).abs()
        true_range = pd.DataFrame(data={"tr1": tr1, "tr2": tr2, "tr3": tr3}).max(axis=1)
        return true_range


def dropna(df: pd.DataFrame) -> pd.DataFrame:
    """
    Drop rows with 'NaN' values

    Parameters:
    - df (pandas.DataFrame): Input DataFrame.

    Call with:
        dropna = dropna(df)

    Returns:
    - pd.DataFrame: DataFrame without NaN values.
    """
    df = df.copy()
    number_cols = df.select_dtypes(include=np.number).columns.tolist()
    df[number_cols] = df[number_cols][df[number_cols] < math.exp(709)]  # big number
    df[number_cols] = df[number_cols][df[number_cols] != 0.0]
    df = df.dropna()
    return df


def _sma(series, periods: int, fillna: bool = False):
    """
    Simple Moving Average (SMA)

    Parameters:
    - series (pd.Series): Input series.
    - periods (int): Period for SMA calculation.
    - fillna (bool): If True, fill NaN values. Default is False.

    Call with:
        sma = _sma(series, periods)
        df['sma'] = sma

    Returns:
    - pd.Series: Series of SMA values.
    """
    min_periods = 0 if fillna else periods
    return series.rolling(window=periods, min_periods=min_periods).mean()


def _ema(series, periods: int, fillna: bool = False):
    """
    Exponential Moving Average (EMA)

    Parameters:
    - series (pd.Series): Input series.
    - periods (int): Period for EMA calculation.
    - fillna (bool): If True, fill NaN values. Default is False.

    Call with:
        ema = _ema(series, periods)
        df['ema'] = ema

    Returns:
    - pd.Series: Series of EMA values.
    """
    min_periods = 0 if fillna else periods
    return series.ewm(span=periods, min_periods=min_periods, adjust=False).mean()


def get_min_max(series1: pd.Series, series2: pd.Series, function: str = "min"):
    """
    Find min or max value between two lists for each index

    Parameters:
    - series1 (pd.Series): First input series.
    - series2 (pd.Series): Second input series.
    - function (str): Function to apply ("min" or "max"). Default is "min".

    Call with:
        min_max_series = get_min_max(series1, series2, function)
        df['min_max'] = min_max_series

    Returns:
    - pd.Series: Series with min or max values for each index.
    """
    series1 = np.array(series1)
    series2 = np.array(series2)
    if function == "min":
        output = np.amin([series1, series2], axis=0)
    elif function == "max":
        output = np.amax([series1, series2], axis=0)
    else:
        raise ValueError('"function" variable value should be "min" or "max"')

    return pd.Series(output)


def Daily_Return(df, column="close", fillna=False):
    """
    Daily Return (DR)

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the specified column.
    - column (str): The column on which the daily return is to be calculated. Default is "close".
    - fillna (bool): If True, fill nan values. Default is False.

    Call with:
        dr = Daily_Return(df)
        df['daily_return'] = dr

    Returns:
    - pd.Series: Series of daily return values.
    """
    df_copy = df.copy()
    df_copy['d_ret'] = (df_copy[column] / df_copy[column].shift(1)) - 1
    df_copy['d_ret'] *= 100
    if fillna:
        df_copy['d_ret'] = df_copy['d_ret'].fillna(0)
    return df_copy['d_ret'].rename("d_ret")


def Daily_Log_Return(df, column="close", fillna=False):
    """
    Daily Log Return (DLR)

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the specified column.
    - column (str): The column on which the daily log return is to be calculated. Default is "close".
    - fillna (bool): If True, fill nan values. Default is False.

    Call with:
        dlr = Daily_Log_Return(df)
        df['daily_log_return'] = dlr

    Returns:
    - pd.Series: Series of daily log return values.
    """
    df_copy = df.copy()
    df_copy['d_logret'] = pd.Series(np.log(df_copy[column])).diff()
    df_copy['d_logret'] *= 100
    if fillna:
        df_copy['d_logret'] = df_copy['d_logret'].fillna(0)
    return df_copy['d_logret'].rename("d_logret")


def Cumulative_Return(df, column="close", fillna=False):
    """
    Cumulative Return (CR)

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the specified column.
    - column (str): The column on which the cumulative return is to be calculated. Default is "close".
    - fillna (bool): If True, fill nan values. Default is False.

    Call with:
        cr = Cumulative_Return(df)
        df['cumulative_return'] = cr

    Returns:
    - pd.Series: Series of cumulative return values.
    """
    df_copy = df.copy()
    df_copy['cum_ret'] = (df_copy[column] / df_copy[column].iloc[0]) - 1
    df_copy['cum_ret'] *= 100
    if fillna:
        df_copy['cum_ret'] = df_copy['cum_ret'].fillna(-1)
    return df_copy['cum_ret'].rename("cum_ret")

        ----- End of utility.py -----

        momentum.py

        ----- Start of momentum.py -----

# -*- coding: utf-8 -*-
import numpy as np
import pandas as pd
from .bamboo_ta import *
from .trend import *
from .volatility import *
from .utility import *


def Awesome_Oscillator(df, window1=5, window2=34, fillna=False):
    """
    Awesome Oscillator (AO)

    The Awesome Oscillator is a momentum indicator used to measure market momentum.
    It is calculated by subtracting a 34-period simple moving average (SMA) of the
    median price from a 5-period SMA of the median price.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain columns: 'high' and 'low'.
    - window1 (int, optional): Short period. Default is 5.
    - window2 (int, optional): Long period. Default is 34.
    - fillna (bool, optional): If True, fill nan values with 0. Default is False.

    Call with:
        df['ao'] = bta.Awesome_Oscillator(df)

    Returns:
    - pd.DataFrame: DataFrame with 'ao' column.
    """
    df_copy = df.copy()

    median_price = 0.5 * (df['high'] + df['low'])
    min_periods_s = 0 if fillna else window1
    min_periods_l = 0 if fillna else window2
    df_copy['ao'] = (
        median_price.rolling(window1, min_periods=min_periods_s).mean()
        - median_price.rolling(window2, min_periods=min_periods_l).mean()
    )
    if fillna:
        df_copy['ao'] = df_copy['ao'].fillna(0)

    df_copy['ao'] = df_copy['ao'].round(2)
    return df_copy[['ao']]


def Chande_Momentum_Oscillator(df, length=14):
    """
    Chande Momentum Oscillator (CMO)

    The Chande Momentum Oscillator (CMO) is a technical momentum indicator developed by Tushar Chande. 
    It measures the amount that an asset's price has changed over a specified period of time.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the 'close' column.
    - length (int): Length for the CMO calculation. Default is 14.

    Call with:
        df['cmo'] = bta.Chande_Momentum_Oscillator(df)

    For Signal line:
        df['cmo_signal'] = df['cmo'].rolling(window=10).mean().round(2)  # Using SMA for signal

    Returns:
    - pd.DataFrame: DataFrame with 'cmo' column.
    """
    df_copy = df.copy()

    mom = df['close'].diff()
    pos_mom = mom.where(mom > 0, 0)
    neg_mom = -mom.where(mom < 0, 0)
    sm1 = pos_mom.rolling(window=length).sum()
    sm2 = neg_mom.rolling(window=length).sum()
    df_copy['cmo'] = 100 * (sm1 - sm2) / (sm1 + sm2)

    df_copy['cmo'] = df_copy['cmo'].round(2)
    return df_copy[['cmo']]


def Elliott_Wave_Oscillator(df, column="close", sma1_period=5, sma2_period=35):
    """
    Elliott Wave Oscillator (EWO)

    The Elliott Wave Oscillator (EWO) is a specific tool to help you identify the trend and the overall market pattern to assist in finding future trading opportunities.
    It is derived by calculating the difference between a short and long period simple moving average, then normalizing the result with the close price.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the column specified.
    - column (str): The column on which EWO is to be calculated. Default is "close".
    - sma1_period (int): The period for the shorter SMA used in EWO calculation. Default is 5.
    - sma2_period (int): The period for the longer SMA used in EWO calculation. Default is 35.

    Call with:
        df['ewo'] = bta.Elliott_Wave_Oscillator(df, "close", 5, 35)

    Returns:
    - pd.DataFrame: DataFrame with 'ewo' column.
    """
    df_copy = df.copy()

    sma1 = df[column].rolling(window=sma1_period).mean()
    sma2 = df[column].rolling(window=sma2_period).mean()
    df_copy['ewo'] = ((sma1 - sma2) / df[column] * 100).round(2)

    return df_copy[['ewo']]


def Fisher_Center_Of_Gravity(df, length=20, min_period=10):
    """
    Fisher Stochastic Center of Gravity

    Original Pinescript by dasanc
    https://tradingview.com/script/5BT3a9mJ-Fisher-Stochastic-Center-of-Gravity/

    The Fisher Stochastic Center of Gravity is an indicator that aims to identify the center of gravity of the market.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'high' and 'low' columns.
    - length (int): Lookback period. Default is 20.
    - min_period (int): Minimum lookback period. Default is 10.

    Call with:
        fisher = bta.Fisher_Center_Of_Gravity(df)
        df['fisher_cg'] = fisher['fisher_cg']
        df['fisher_sig'] = fisher['fisher_sig']

    Returns:
    - pd.DataFrame: DataFrame with 'fisher_cg' and 'fisher_sig' columns populated.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['high', 'low']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    df_copy['hl2'] = (df_copy['high'] + df_copy['low']) / 2

    if length < min_period:
        length = min_period

    num = sum((1 + i) * df_copy['hl2'].shift(i) for i in range(length))
    denom = sum(df_copy['hl2'].shift(i) for i in range(length))

    cg = -num / denom + (length + 1) / 2
    max_cg = cg.rolling(window=length).max()
    min_cg = cg.rolling(window=length).min()

    value1 = np.where(max_cg != min_cg, (cg - min_cg) / (max_cg - min_cg), 0)
    value2 = (4 * value1 + 3 * np.roll(value1, 1) + 2 * np.roll(value1, 2) + np.roll(value1, 3)) / 10
    value3 = 0.5 * np.log((1 + 1.98 * (value2 - 0.5)) / (1 - 1.98 * (value2 - 0.5)))

    df_copy['fisher_cg'] = pd.Series(value3, index=df_copy.index).round(2)  # Center of Gravity
    df_copy['fisher_sig'] = df_copy['fisher_cg'].shift(1).round(2)  # Signal / Trigger

    return df_copy[['fisher_cg', 'fisher_sig']]


def Inverse_Fisher_Transform(df, src='close', rsi_length=10, rsi_smoothing=5, e_value=2.71):
    """
    Inverse Fisher Transform

    The Inverse Fisher Transform is a technical indicator used to amplify price movements and identify potential buy and sell signals.
    It applies an inverse Fisher transform to a smoothed RSI to highlight changes in price momentum.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the 'close' column.
    - src (str): Source column to calculate the indicator. Default is 'close'.
    - rsi_length (int): Length for the RSI calculation. Default is 10.
    - rsi_smoothing (int): Length for the RSI smoothing (EMA). Default is 5.
    - e_value (float): E value for the inverse fisher transform. Default is 2.71.

    Call with:
        df['ift'] = bta.Inverse_Fisher_Transform(df)['ift']

    Use additional levels in your dataframe for 
        # Add horizontal levels
        df['level_1_35'] = 1.35
        df['level_0_5'] = 0.5
        df['level_0'] = 0
        df['level_minus_0_5'] = -0.5
        df['level_minus_1'] = -1

    Returns:
    - pd.DataFrame: DataFrame with 'ift' column.
    """
    df_copy = df.copy()

    # Calculate RSI values
    rsi_values = RSI(df, column=src, period=rsi_length)
    
    # Smooth RSI values with EMA
    rsi_ema_values = EMA(df.assign(rsi_values=rsi_values), 'rsi_values', rsi_smoothing)
    
    # Apply Inverse Fisher Transform
    inv_fisher = (np.exp(2.0 * (rsi_ema_values - 50) * 0.1) - 1) / (np.exp(2.0 * (rsi_ema_values - 50) * 0.1) + 1)

    df_copy['ift'] = inv_fisher.round(2)
    
    return df_copy[['ift']]


def Kaufmans_Adaptive_Moving_Average(
    df: pd.DataFrame,
    close_col: str = 'close',
    window: int = 10,
    pow1: int = 2,
    pow2: int = 30,
    fillna: bool = False,
) -> pd.DataFrame:
    """
    Kaufman's Adaptive Moving Average (KAMA)

    Moving average designed to account for market noise or volatility. KAMA
    will closely follow prices when the price swings are relatively small and
    the noise is low. KAMA will adjust when the price swings widen and follow
    prices from a greater distance. This trend-following indicator can be
    used to identify the overall trend, time turning points and filter price
    movements.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the 'close' column.
    - close_col (str): Column name for the close prices. Default is 'close'.
    - window (int): Number of periods for the efficiency ratio. Default is 10.
    - pow1 (int): Number of periods for the fastest EMA constant. Default is 2.
    - pow2 (int): Number of periods for the slowest EMA constant. Default is 30.
    - fillna (bool): If True, fill nan values with the close prices. Default is False.

    Call with:
        df['kama'] = bta.Kaufmans_Adaptive_Moving_Average(df)['kama']

    Returns:
    - pd.DataFrame: DataFrame with 'kama' column.
    """
    close = df[close_col]
    close_values = close.values
    vol = pd.Series(abs(close - np.roll(close, 1)))

    min_periods = 0 if fillna else window
    er_num = abs(close_values - np.roll(close_values, window))
    er_den = vol.rolling(window, min_periods=min_periods).sum()
    efficiency_ratio = np.divide(
        er_num, er_den, out=np.zeros_like(er_num), where=er_den != 0
    )

    smoothing_constant = (
        (
            efficiency_ratio * (2.0 / (pow1 + 1) - 2.0 / (pow2 + 1.0))
            + 2 / (pow2 + 1.0)
        )
        ** 2.0
    ).values

    kama = np.zeros(smoothing_constant.size)
    len_kama = len(kama)
    first_value = True

    for i in range(len_kama):
        if np.isnan(smoothing_constant[i]):
            kama[i] = np.nan
        elif first_value:
            kama[i] = close_values[i]
            first_value = False
        else:
            kama[i] = kama[i - 1] + smoothing_constant[i] * (
                close_values[i] - kama[i - 1]
            )
    
    kama_series = pd.Series(kama, index=close.index).round(2)
    if fillna:
        kama_series = kama_series.fillna(close)

    df_copy = df.copy()
    df_copy['kama'] = kama_series

    return df_copy[['kama']]


def macd(df, column="close", short_window=12, long_window=26, signal_window=9):
    """
    Moving Average Convergence Divergence (MACD)

    MACD is a trend-following momentum indicator that shows the relationship between two moving averages of a security’s price.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the "close" column.
    - column (str): The column on which MACD is to be calculated. Default is "close".
    - short_window (int): The short-term period for EMA. Default is 12.
    - long_window (int): The long-term period for EMA. Default is 26.
    - signal_window (int): The signal line period for EMA. Default is 9.

    Call with:
        macd_result = bta.macd(df, "close", 12, 26, 9)
        df['macd'] = macd_result['macd']
        df['macd_signal'] = macd_result['macd_signal']
        df['macd_histogram'] = macd_result['macd_histogram']

    Returns:
    - pd.DataFrame: DataFrame with 'macd', 'macd_signal', and 'macd_histogram' columns.
    """
    short_ema = EMA(df, column=column, period=short_window)
    long_ema = EMA(df, column=column, period=long_window)
    macd = short_ema - long_ema
    signal = macd.ewm(span=signal_window, adjust=False).mean()
    histogram = macd - signal

    df_copy = df.copy()
    df_copy['macd'] = macd.round(2)
    df_copy['macd_signal'] = signal.round(2)
    df_copy['macd_histogram'] = histogram.round(2)

    return df_copy[['macd', 'macd_signal', 'macd_histogram']]


def MACD_Leader(df, src='close', fast_length=12, slow_length=26, signal_length=9):
    """
    MACD Leader

    The MACD Leader is a variation of the standard MACD that aims to provide an earlier signal by using a different calculation method.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the source column.
    - src (str): The column to use for calculations. Default is 'close'.
    - fast_length (int): Length for the fast EMA. Default is 12.
    - slow_length (int): Length for the slow EMA. Default is 26.
    - signal_length (int): Length for the signal EMA. Default is 9.

    Call with:
        df['macd_leader'] = bta.MACD_Leader(df, 'close')

    Returns:
    - pd.DataFrame: DataFrame with 'macd_leader' column.
    """
    src_series = df[src]
    sema = EMA(df.assign(src_series=src_series), 'src_series', fast_length)
    lema = EMA(df.assign(src_series=src_series), 'src_series', slow_length)
    i1 = sema + EMA(df.assign(diff=src_series - sema), 'diff', fast_length)
    i2 = lema + EMA(df.assign(diff=src_series - lema), 'diff', slow_length)
    macd_leader = ((i1 - i2) / 10) * 100

    df_copy = df.copy()
    df_copy['macd_leader'] = macd_leader.round(2)
    
    return df_copy[['macd_leader']]


def MA_Streak(df, period=4, column='close'):
    """
    MA Streak

    Port of: https://www.tradingview.com/script/Yq1z7cIv-MA-Streak-Can-Show-When-a-Run-Is-Getting-Long-in-the-Tooth/

    The MA Streak indicator shows the length of consecutive periods where the moving average is increasing or decreasing.

    Parameters:
    - df (pd.DataFrame): DataFrame containing the data.
    - period (int): Period for the ZEMA calculation. Default is 4.
    - column (str): The column name on which the ZEMA is to be applied. Default is "close".

    Call with:
        df['mastreak'] = bta.MA_Streak(df, period=4, column='close')['mastreak']

    Returns:
    - pd.DataFrame: DataFrame with 'mastreak' column.
    """
    df_copy = df.copy()

    avgval = ZEMA(df_copy, period, column)
    arr = np.diff(avgval)
    pos = np.clip(arr, 0, 1).astype(bool).cumsum()
    neg = np.clip(arr, -1, 0).astype(bool).cumsum()
    streak = np.where(arr >= 0, pos - np.maximum.accumulate(np.where(arr <= 0, pos, 0)),
                      -neg + np.maximum.accumulate(np.where(arr >= 0, neg, 0)))

    streak_series = SameLength(df_copy['close'], streak)
    df_copy['mastreak'] = streak_series.round(2)
    
    return df_copy[['mastreak']]


def Percentage_Price_Oscillator(
    df: pd.DataFrame,
    close_col: str = 'close',
    window_slow: int = 26,
    window_fast: int = 12,
    window_sign: int = 9,
    fillna: bool = False
) -> pd.DataFrame:
    """
    Percentage Price Oscillator (PPO) Combined Function

    This function calculates and returns the PPO, PPO Signal, and PPO Histogram values.

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the close column.
    - close_col (str): Name of the column containing close price data. Default is 'close'.
    - window_slow (int): n period long-term. Default is 26.
    - window_fast (int): n period short-term. Default is 12.
    - window_sign (int): n period to signal. Default is 9.
    - fillna (bool): if True, fill nan values. Default is False.

    Call with:
        ppo = bta.Percentage_Price_Oscillator(df)
        df['ppo'] = ppo['ppo']
        df['ppo_signal'] = ppo['ppo_signal']
        df['ppo_hist'] = ppo['ppo_hist']

    Returns:
    - pd.DataFrame: DataFrame with columns ['ppo', 'ppo_signal', 'ppo_hist'].
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    if close_col not in df.columns:
        raise KeyError(f"DataFrame must contain '{close_col}' column")

    close = df_copy[close_col]

    # Calculate EMA
    emafast = close.ewm(span=window_fast, adjust=False).mean()
    emaslow = close.ewm(span=window_slow, adjust=False).mean()
    ppo = ((emafast - emaslow) / emaslow) * 100

    ppo_signal = ppo.ewm(span=window_sign, adjust=False).mean()
    ppo_hist = ppo - ppo_signal

    if fillna:
        ppo = ppo.fillna(0)
        ppo_signal = ppo_signal.fillna(0)
        ppo_hist = ppo_hist.fillna(0)

    df_copy['ppo'] = ppo.round(2)
    df_copy['ppo_signal'] = ppo_signal.round(2)
    df_copy['ppo_hist'] = ppo_hist.round(2)

    return df_copy[['ppo', 'ppo_signal', 'ppo_hist']]


def PVO(
    df: pd.DataFrame,
    volume_col: str = 'volume',
    window_slow: int = 26,
    window_fast: int = 12,
    window_sign: int = 9,
    fillna: bool = False
) -> pd.DataFrame:
    """
    Percentage Volume Oscillator (PVO) Combined Function
    
    This function calculates and returns the PVO, PVO Signal, and PVO Histogram values.

    Call with:
        pvo = bta.PVO(df)
        df['pvo'] = pvo['pvo']
        df['pvo_signal'] = pvo['pvo_signal']
        df['pvo_hist'] = pvo['pvo_hist']

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the volume column.
    - volume_col (str): Name of the column containing volume data.
    - window_slow (int): n period long-term.
    - window_fast (int): n period short-term.
    - window_sign (int): n period to signal.
    - fillna (bool): if True, fill nan values.

    Returns:
    - pd.DataFrame: DataFrame with columns ['pvo', 'pvo_signal', 'pvo_hist'].
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    if volume_col not in df.columns:
        raise KeyError(f"DataFrame must contain '{volume_col}' column")

    volume = df_copy[volume_col]

    # Calculate EMA
    emafast = volume.ewm(span=window_fast, adjust=False).mean()
    emaslow = volume.ewm(span=window_slow, adjust=False).mean()
    pvo = ((emafast - emaslow) / emaslow) * 100

    pvo_signal = pvo.ewm(span=window_sign, adjust=False).mean()
    pvo_hist = pvo - pvo_signal

    if fillna:
        pvo = pvo.fillna(0)
        pvo_signal = pvo_signal.fillna(0)
        pvo_hist = pvo_hist.fillna(0)

    df_copy['pvo'] = pvo
    df_copy['pvo_signal'] = pvo_signal
    df_copy['pvo_hist'] = pvo_hist

    return df_copy[['pvo', 'pvo_signal', 'pvo_hist']]


def RMI(df, length=20, mom=5):
    """
    Relative Momentum Index (RMI)
    Source: https://github.com/freqtrade/technical/blob/master/technical/indicators/indicators.py#L912

    Call with:
        df['rmi'] = bta.RMI(df, length=20, mom=5)

    Args:
    df (pd.DataFrame): DataFrame containing the data.
    length (int): Period for the EMA calculation. Default is 20.
    mom (int): Momentum period. Default is 5.

    Returns:
    pd.Series: Series of RMI values.
    """
    df_copy = df.copy()

    df_copy['maxup'] = (df_copy['close'] - df_copy['close'].shift(mom)).clip(lower=0)
    df_copy['maxdown'] = (df_copy['close'].shift(mom) - df_copy['close']).clip(lower=0)
    df_copy.fillna(0, inplace=True)
    df_copy["emaInc"] = EMA(df_copy, column='maxup', period=length)
    df_copy["emaDec"] = EMA(df_copy, column='maxdown', period=length)
    df_copy['RMI'] = np.where(df_copy['emaDec'] == 0, 0, 100 - 100 / (1 + df_copy["emaInc"] / df_copy["emaDec"]))
    
    return df_copy['RMI']


def ROC(df, column='close', period=21):
    """
    Rate of Change (ROC)

    Call with:
        df['roc'] = bta.ROC(df, column='close', period=21)

    Args:
    df (pd.DataFrame): DataFrame containing the data.
    column (str): The column name on which the ROC is to be applied. Default is "close".
    period (int): Period for the ROC calculation. Default is 21.

    Returns:
    pd.Series: Series of ROC values.
    """
    df_copy = df.copy()

    df_copy['roc'] = df_copy[column].diff(period) / df_copy[column].shift(period) * 100
    
    return df_copy['roc']


def SROC(df, roclen=21, emalen=13, smooth=21):
    """
    Smoothed Rate of Change (SROC)

    Call with:
        df['sroc'] = bta.SROC(df, roclen=21, emalen=13, smooth=21)

    Args:
    df (pd.DataFrame): DataFrame containing the data.
    roclen (int): Period for the ROC calculation. Default is 21.
    emalen (int): Period for the EMA calculation. Default is 13.
    smooth (int): Smoothing period for the ROC calculation. Default is 21.

    Returns:
    pd.Series: Series of SROC values.
    """
    df_copy = df.copy()

    roc = ROC(df_copy, column='close', period=roclen)
    ema = EMA(df_copy, column='close', period=emalen)
    sroc = ROC(pd.DataFrame(ema), column='close', period=smooth)
    
    return sroc


def Waddah_Attar_Explosion(df, sensitivity=150, fast_length=20, slow_length=40, channel_length=20, mult=2.0):
    """
    Waddah Attar Explosion Indicator

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain columns: 'open', 'high', 'low', and 'close'.
    - sensitivity (int): Sensitivity factor for the indicator. Default is 150.
    - fast_length (int): Length for the fast EMA. Default is 20.
    - slow_length (int): Length for the slow EMA. Default is 40.
    - channel_length (int): Length for the Bollinger Bands. Default is 20.
    - mult (float): Standard deviation multiplier for the Bollinger Bands. Default is 2.0.

    Call with:
        WAE = bta.Waddah_Attar_Explosion(df)
        df['trend_up'] = WAE['trend_up']
        df['trend_down'] = WAE['trend_down']
        df['explosion_line'] = WAE['explosion_line']
        df['dead_zone_line'] = WAE['dead_zone_line']

    Returns:
    - pd.DataFrame: DataFrame with 'trend_up', 'trend_down', 'explosion_line', and 'dead_zone_line' columns.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['open', 'high', 'low', 'close']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    # print("DataFrame columns:", df.columns)  # Debug print
    # print("First few rows of the DataFrame:\n", df.head())  # Debug print

    # Calculate DEAD_ZONE
    dead_zone = RMA(TR(df), 100) * 3.7
    # print("DEAD_ZONE calculated")  # Debug print

    # Calculate MACD
    macd_fast = EMA(df, 'close', fast_length)
    macd_slow = EMA(df, 'close', slow_length)
    macd_diff = macd_fast - macd_slow
    t1 = (macd_diff - macd_diff.shift(1)) * sensitivity
    # print("MACD and t1 calculated")  # Debug print

    # Calculate Bollinger Bands
    bb = BollingerBands(df, column='close', period=channel_length, std_dev=mult)
    e1 = bb['BB_upper'] - bb['BB_lower']
    # print("Bollinger Bands calculated")  # Debug print

    trend_up = np.where(t1 >= 0, t1, 0)
    trend_down = np.where(t1 < 0, -t1, 0)

    df_copy['trend_up'] = trend_up.round(2)
    df_copy['trend_down'] = trend_down.round(2)
    df_copy['explosion_line'] = e1.round(2)
    df_copy['dead_zone_line'] = dead_zone.round(2)

    return df_copy[['trend_up', 'trend_down', 'explosion_line', 'dead_zone_line']]


def WaveTrend(df, chlen=10, avg=21, smalen=4):
    """
    WaveTrend Oscillator by LazyBear
    https://www.tradingview.com/script/2KE8wTuF-Indicator-WaveTrend-Oscillator-WT/

    Call with:
        wt1, wt2 = bta.WaveTrend(df, chlen=10, avg=21, smalen=4)
        df['wt1'] = wt1
        df['wt2'] = wt2

    Args:
    df (pd.DataFrame): DataFrame containing the data.
    chlen (int): Channel length for the EMA calculation. Default is 10.
    avg (int): Average period for the EMA calculation. Default is 21.
    smalen (int): Period for the SMA calculation. Default is 4.

    Returns:
    tuple: WaveTrend 1 and WaveTrend 2 series.
    """
    df_copy = df.copy()

    df_copy['hlc3'] = (df_copy['high'] + df_copy['low'] + df_copy['close']) / 3
    df_copy['esa'] = EMA(df_copy, column='hlc3', period=chlen)
    df_copy['abs_diff'] = (df_copy['hlc3'] - df_copy['esa']).abs()
    df_copy['d'] = EMA(df_copy, column='abs_diff', period=chlen)
    df_copy['ci'] = (df_copy['hlc3'] - df_copy['esa']) / (0.015 * df_copy['d'])
    df_copy['tci'] = EMA(df_copy, column='ci', period=avg)
    df_copy['wt1'] = df_copy['tci']
    df_copy['wt2'] = SMA(df_copy, column='wt1', period=smalen)

    # Return only the calculated columns
    return df_copy['wt1'], df_copy['wt2']


def WaveTrend_Oscillator(df, src, n1=8, n2=12):
    """
    WaveTrend Oscillator

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain the source column.
    - src (str): The column to use for calculations.
    - n1 (int): Length for the first EMA. Default is 8.
    - n2 (int): Length for the second EMA. Default is 12.

    Call with:
        wt = WaveTrend_Oscillator(df, 'close')
        df['wavetrend'] = wt['wavetrend']

    Returns:
    - pd.DataFrame: DataFrame with 'wavetrend' column.
    """
    df_copy = df.copy()

    src_series = df[src]
    ema_src = EMA(df.assign(src_series=src_series), 'src_series', n1)
    d = EMA(df.assign(diff=np.abs(src_series - ema_src)), 'diff', n1)
    ci = (src_series - ema_src) / (0.015 * d)
    tci = EMA(df.assign(ci=ci), 'ci', n2)
    wavetrend = tci - SMA(df.assign(tci=tci), 'tci', 4)

    df_copy['wavetrend'] = wavetrend.round(2)
    
    return df_copy[['wavetrend']]


def QQE_Mod(df, rsi_period=6, rsi_smoothing=5, qqe_factor=3, threshold=3, bollinger_length=50, bb_multiplier=0.35,
            rsi_period2=6, rsi_smoothing2=5, qqe_factor2=1.61, threshold2=3):
    """
    QQE Mod Indicator

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain a 'close' column.
    - rsi_period (int): Period for RSI calculation. Default is 6.
    - rsi_smoothing (int): Smoothing period for RSI. Default is 5.
    - qqe_factor (int): Fast QQE Factor. Default is 3.
    - threshold (int): Threshold value. Default is 3.
    - bollinger_length (int): Length for Bollinger Bands calculation. Default is 50.
    - bb_multiplier (float): Multiplier for Bollinger Bands. Default is 0.35.
    - rsi_period2 (int): Period for the second RSI calculation. Default is 6.
    - rsi_smoothing2 (int): Smoothing period for the second RSI. Default is 5.
    - qqe_factor2 (float): Fast QQE Factor for the second QQE. Default is 1.61.
    - threshold2 (int): Threshold value for the second QQE. Default is 3.

    Call with:
        qqe_mod = QQE_Mod(df)
        df['QQE_Line'] = qqe_mod['QQE_Line']
        df['Histo2'] = qqe_mod['Histo2']
        df['QQE_Up'] = qqe_mod['QQE_Up']
        df['QQE_Down'] = qqe_mod['QQE_Down']

    Returns:
    - pd.DataFrame: DataFrame with 'QQE_Line', 'Histo2', 'QQE_Up', and 'QQE_Down' columns.
    """
    def wilders_ema(series, period):
        return series.ewm(alpha=1/period, adjust=False).mean()

    df_copy = df.copy()

    # First QQE Calculation
    src = df_copy['close']
    wilders_period = rsi_period * 2 - 1

    rsi = RSI(df_copy, column='close', period=rsi_period)
    rsi_ma = EMA(df_copy.assign(rsi=rsi), column='rsi', period=rsi_smoothing)
    atr_rsi = abs(rsi_ma.shift(1) - rsi_ma)
    ma_atr_rsi = wilders_ema(atr_rsi, wilders_period)
    dar = wilders_ema(ma_atr_rsi, wilders_period) * qqe_factor

    longband = np.zeros(len(df_copy))
    shortband = np.zeros(len(df_copy))
    trend = np.zeros(len(df_copy))

    delta_fast_atr_rsi = dar
    rsindex = rsi_ma
    newshortband = rsindex + delta_fast_atr_rsi
    newlongband = rsindex - delta_fast_atr_rsi

    for i in range(1, len(df_copy)):
        if rsindex.iloc[i - 1] > longband[i - 1] and rsindex.iloc[i] > longband[i - 1]:
            longband[i] = max(longband[i - 1], newlongband.iloc[i])
        else:
            longband[i] = newlongband.iloc[i]

        if rsindex.iloc[i - 1] < shortband[i - 1] and rsindex.iloc[i] < shortband[i - 1]:
            shortband[i] = min(shortband[i - 1], newshortband.iloc[i])
        else:
            shortband[i] = newshortband.iloc[i]

        cross_1 = (longband[i - 1] > rsindex.iloc[i]) and (longband[i - 1] <= rsindex.iloc[i - 1])
        if (rsindex.iloc[i] > shortband[i - 1]):
            trend[i] = 1
        elif cross_1:
            trend[i] = -1
        else:
            trend[i] = trend[i - 1]

    fast_atr_rsi_tl = np.where(trend == 1, longband, shortband)

    # Bollinger Bands on FastATRRSI TL
    basis = SMA(pd.DataFrame(fast_atr_rsi_tl - 50), column=0, period=bollinger_length)
    dev = bb_multiplier * STDEV(pd.Series(fast_atr_rsi_tl - 50), bollinger_length)
    upper = basis + dev
    lower = basis - dev

    # Second QQE Calculation
    wilders_period2 = rsi_period2 * 2 - 1

    rsi2 = RSI(df_copy, column='close', period=rsi_period2)
    rsi_ma2 = EMA(df_copy.assign(rsi2=rsi2), column='rsi2', period=rsi_smoothing2)
    atr_rsi2 = abs(rsi_ma2.shift(1) - rsi_ma2)
    ma_atr_rsi2 = wilders_ema(atr_rsi2, wilders_period2)
    dar2 = wilders_ema(ma_atr_rsi2, wilders_period2) * qqe_factor2

    longband2 = np.zeros(len(df_copy))
    shortband2 = np.zeros(len(df_copy))
    trend2 = np.zeros(len(df_copy))

    delta_fast_atr_rsi2 = dar2
    rsindex2 = rsi_ma2
    newshortband2 = rsindex2 + delta_fast_atr_rsi2
    newlongband2 = rsindex2 - delta_fast_atr_rsi2

    for i in range(1, len(df_copy)):
        if rsindex2.iloc[i - 1] > longband2[i - 1] and rsindex2.iloc[i] > longband2[i - 1]:
            longband2[i] = max(longband2[i - 1], newlongband2.iloc[i])
        else:
            longband2[i] = newlongband2.iloc[i]

        if rsindex2.iloc[i - 1] < shortband2[i - 1] and rsindex2.iloc[i] < shortband2[i - 1]:
            shortband2[i] = min(shortband2[i - 1], newshortband2.iloc[i])
        else:
            shortband2[i] = newshortband2.iloc[i]

        cross_2 = (longband2[i - 1] > rsindex2.iloc[i]) and (longband2[i - 1] <= rsindex2.iloc[i - 1])
        if (rsindex2.iloc[i] > shortband2[i - 1]):
            trend2[i] = 1
        elif cross_2:
            trend2[i] = -1
        else:
            trend2[i] = trend2[i - 1]

    fast_atr_rsi2_tl = np.where(trend2 == 1, longband2, shortband2)

    hcolor2 = np.where(rsi_ma2 - 50 > threshold2, 'silver', np.where(rsi_ma2 - 50 < -threshold2, 'silver', np.nan))

    df_copy['QQE_Line'] = (fast_atr_rsi2_tl - 50).round(2)
    df_copy['Histo2'] = (rsi_ma2 - 50).round(2)

    greenbar1 = rsi_ma2 - 50 > threshold2
    greenbar2 = rsi_ma - 50 > upper

    redbar1 = rsi_ma2 - 50 < -threshold2
    redbar2 = rsi_ma - 50 < lower

    df_copy['QQE_Up'] = np.where(greenbar1 & greenbar2, rsi_ma2 - 50, np.nan).round(2)
    df_copy['QQE_Down'] = np.where(redbar1 & redbar2, rsi_ma2 - 50, np.nan).round(2)

    return df_copy[['QQE_Line', 'Histo2', 'QQE_Up', 'QQE_Down']]


def ROC(close: pd.Series, window: int = 12, fillna: bool = False) -> pd.Series:
    """Rate of Change (ROC)

    The Rate-of-Change (ROC) indicator, which is also referred to as simply
    Momentum, is a pure momentum oscillator that measures the percent change in
    price from one period to the next. The ROC calculation compares the current
    price with the price “n” periods ago. The plot forms an oscillator that
    fluctuates above and below the zero line as the Rate-of-Change moves from
    positive to negative. As a momentum oscillator, ROC signals include
    centerline crossovers, divergences and overbought-oversold readings.
    Divergences fail to foreshadow reversals more often than not, so this
    article will forgo a detailed discussion on them. Even though centerline
    crossovers are prone to whipsaw, especially short-term, these crossovers
    can be used to identify the overall trend. Identifying overbought or
    oversold extremes comes naturally to the Rate-of-Change oscillator.

    Call with:
        df['roc'] = bta.ROC(df['close'], 12)
    
    Args:
        close(pandas.Series): dataset 'Close' column.
        window(int): n periods.
        fillna(bool): if True, fill nan values.

    Returns:
        pandas.Series: New feature generated.
    """
    roc = ((close - close.shift(window)) / close.shift(window)) * 100
    if fillna:
        roc = roc.fillna(0)
    return roc


def RSI(df, column="close", period=14):
    """
    Relative Strength Index (RSI)

    Call with:
        df['rsi'] = bta.RSI(df, "close", 14)

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain at least the column specified.
    - column (str): The column on which RSI is to be calculated. Default is "close".
    - period (int): The period over which RSI is to be calculated. Default is 14.

    Returns:
    - pandas.Series: A series of RSI values.

    Description:
    RSI measures the magnitude of recent price changes to evaluate overbought or oversold conditions in the price of a stock or other asset.
    """
    delta = df[column].diff(1)
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)

    avg_gain = gain.rolling(window=period, min_periods=1).mean()
    avg_loss = loss.rolling(window=period, min_periods=1).mean()

    for i in range(period, len(df)):
        avg_gain[i] = (avg_gain[i-1] * (period - 1) + gain[i]) / period
        avg_loss[i] = (avg_loss[i-1] * (period - 1) + loss[i]) / period

    rs = avg_gain / avg_loss
    rsi = 100 - (100 / (1 + rs))

    return rsi


def SMI_Momentum(df, k_length=9, d_length=3):
    """ 
    The Stochastic Momentum Index (SMI) Indicator
    
    The Stochastic Momentum Index (SMI) Indicator was developed by 
    William Blau in 1993 and is considered to be a momentum indicator 
    that can help identify trend reversal points

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'high', 'low', and 'close' columns.
    - k_length (int): Period for %K.
    - d_length (int): Period for %D.

    Call with:
        smi = bta.SMI_Momentum(df)
        df['smi'] = smi['smi']

    Returns:
    - pd.DataFrame: DataFrame with smi column populated.
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required columns
    required_columns = ['high', 'low', 'close']
    for col in required_columns:
        if col not in df.columns:
            raise KeyError(f"DataFrame must contain '{col}' column")

    ll = df_copy['low'].rolling(window=k_length).min()
    hh = df_copy['high'].rolling(window=k_length).max()

    diff = hh - ll
    rdiff = df_copy['close'] - (hh + ll) / 2

    avgrel = rdiff.ewm(span=d_length).mean().ewm(span=d_length).mean()
    avgdiff = diff.ewm(span=d_length).mean().ewm(span=d_length).mean()

    df_copy['smi'] = np.where(avgdiff != 0, (avgrel / (avgdiff / 2) * 100), 0)
    
    return df_copy[['smi']]


def StochRSI(
    df: pd.DataFrame,
    close_col: str = 'close',
    window: int = 14,
    smooth1: int = 3,
    smooth2: int = 3,
    fillna: bool = False
) -> pd.DataFrame:
    """
    Stochastic RSI

    Call with:
        stoch_rsi = bta.StochRSI(df, 'close', 14, 3, 3)
        df['stoch_rsi'] = stoch_rsi['stoch_rsi']
        df['stoch_rsi_k'] = stoch_rsi['stoch_rsi_k']
        df['stoch_rsi_d'] = stoch_rsi['stoch_rsi_d']

    Args:
        df (pd.DataFrame): Input DataFrame which should contain the close column.
        close_col (str): Name of the column containing close price data.
        window (int): Lookback period for RSI (default is 14).
        smooth1 (int): Smoothing period for %K line (default is 3).
        smooth2 (int): Smoothing period for %D line (default is 3).
        fillna (bool): If True, fill nan values (default is False).

    Returns:
        pd.DataFrame: DataFrame with columns ['stoch_rsi', 'stoch_rsi_k', 'stoch_rsi_d'].
    """
    df_copy = df.copy()

    # Ensure the DataFrame contains the required column
    if close_col not in df.columns:
        raise KeyError(f"DataFrame must contain '{close_col}' column")

    rsi = RSI(df, close_col, window)
    lowest_low_rsi = rsi.rolling(window).min()
    highest_high_rsi = rsi.rolling(window).max()
    stoch_rsi = (rsi - lowest_low_rsi) / (highest_high_rsi - lowest_low_rsi)
    stoch_rsi_k = stoch_rsi.rolling(smooth1).mean()
    stoch_rsi_d = stoch_rsi_k.rolling(smooth2).mean()

    if fillna:
        stoch_rsi = stoch_rsi.fillna(0)
        stoch_rsi_k = stoch_rsi_k.fillna(0)
        stoch_rsi_d = stoch_rsi_d.fillna(0)

    df_copy['stoch_rsi'] = stoch_rsi
    df_copy['stoch_rsi_k'] = stoch_rsi_k
    df_copy['stoch_rsi_d'] = stoch_rsi_d

    return df_copy[['stoch_rsi', 'stoch_rsi_k', 'stoch_rsi_d']]


def TSI(close: pd.Series, window_slow: int = 25, window_fast: int = 13, fillna: bool = False) -> pd.Series:
    """True Strength Index (TSI)

    Shows both trend direction and overbought/oversold conditions.

    Call with:
        df['tsi'] = bta.TSI(df['close'], 25, 13)

    Args:
        close(pandas.Series): dataset 'Close' column.
        window_slow(int): high period.
        window_fast(int): low period.
        fillna(bool): if True, fill nan values.

    Returns:
        pandas.Series: New feature generated.
    """
    diff_close = close - close.shift(1)
    min_periods_r = 0 if fillna else window_slow
    min_periods_s = 0 if fillna else window_fast
    smoothed = (
        diff_close.ewm(span=window_slow, min_periods=min_periods_r, adjust=False)
        .mean()
        .ewm(span=window_fast, min_periods=min_periods_s, adjust=False)
        .mean()
    )
    smoothed_abs = (
        abs(diff_close)
        .ewm(span=window_slow, min_periods=min_periods_r, adjust=False)
        .mean()
        .ewm(span=window_fast, min_periods=min_periods_s, adjust=False)
        .mean()
    )
    tsi = smoothed / smoothed_abs
    tsi *= 100
    if fillna:
        tsi = tsi.fillna(0)
    return tsi


def UltimateOscillator(
    high: pd.Series,
    low: pd.Series,
    close: pd.Series,
    window1: int = 7,
    window2: int = 14,
    window3: int = 28,
    weight1: float = 4.0,
    weight2: float = 2.0,
    weight3: float = 1.0,
    fillna: bool = False,
) -> pd.Series:
    """Ultimate Oscillator

    Call with:
        df['uo'] = bta.UltimateOscillator(df['high'], df['low'], df['close'], 7, 14, 28)

    Args:
        high(pandas.Series): dataset 'High' column.
        low(pandas.Series): dataset 'Low' column.
        close(pandas.Series): dataset 'Close' column.
        window1(int): short period.
        window2(int): medium period.
        window3(int): long period.
        weight1(float): weight of short BP average for UO.
        weight2(float): weight of medium BP average for UO.
        weight3(float): weight of long BP average for UO.
        fillna(bool): if True, fill nan values with 50.

    Returns:
        pandas.Series: New feature generated.
    """
    close_shift = close.shift(1)
    true_range = IndicatorMixin._true_range(high, low, close_shift)
    buying_pressure = close - pd.DataFrame({"low": low, "close": close_shift}).min(axis=1, skipna=False)
    min_periods_s = 0 if fillna else window1
    min_periods_m = 0 if fillna else window2
    min_periods_l = 0 if fillna else window3
    avg_s = (buying_pressure.rolling(window1, min_periods=min_periods_s).sum()
             / true_range.rolling(window1, min_periods=min_periods_s).sum())
    avg_m = (buying_pressure.rolling(window2, min_periods=min_periods_m).sum()
             / true_range.rolling(window2, min_periods=min_periods_m).sum())
    avg_l = (buying_pressure.rolling(window3, min_periods=min_periods_l).sum()
             / true_range.rolling(window3, min_periods=min_periods_l).sum())
    uo = 100.0 * ((weight1 * avg_s) + (weight2 * avg_m) + (weight3 * avg_l)) / (weight1 + weight2 + weight3)
    if fillna:
        uo = uo.fillna(50)
    return uo

def StochasticsOscillator(
    df: pd.DataFrame,
    high_col: str = 'high',
    low_col: str = 'low',
    close_col: str = 'close',
    window: int = 14,
    smooth_window: int = 3,
    fillna: bool = False,
) -> pd.DataFrame:
    """
    Stochastic Oscillator, Stochastic Signal, and Histogram Combined.

    Call with:
        stoch = bta.StochasticsOscillator(df, 'high', 'low', 'close', 14, 3)
        df['stoch'] = stoch['stoch']
        df['stoch_signal'] = stoch['stoch_signal']
        df['stoch_hist'] = stoch['stoch_hist']

    Args:
        df(pandas.DataFrame): Input DataFrame.
        high_col(str): Column name for 'High' prices.
        low_col(str): Column name for 'Low' prices.
        close_col(str): Column name for 'Close' prices.
        window(int): Lookback period for stochastic calculation.
        smooth_window(int): Lookback period for signal calculation.
        fillna(bool): If True, fill nan values.

    Returns:
        pandas.DataFrame: DataFrame with stoch, stoch_signal, and stoch_hist columns.
    """
    high = df[high_col]
    low = df[low_col]
    close = df[close_col]

    min_periods = 0 if fillna else window
    smin = low.rolling(window, min_periods=min_periods).min()
    smax = high.rolling(window, min_periods=min_periods).max()
    stoch_k = 100 * (close - smin) / (smax - smin)
    if fillna:
        stoch_k = stoch_k.fillna(50)

    min_periods = 0 if fillna else smooth_window
    stoch_d = stoch_k.rolling(smooth_window, min_periods=min_periods).mean()
    if fillna:
        stoch_d = stoch_d.fillna(50)

    stoch_hist = stoch_k - stoch_d
    if fillna:
        stoch_hist = stoch_hist.fillna(0)

    return pd.DataFrame({
        'stoch': stoch_k,
        'stoch_signal': stoch_d,
        'stoch_hist': stoch_hist
    })


def WilliamsR(
    high: pd.Series,
    low: pd.Series,
    close: pd.Series,
    lbp: int = 14,
    fillna: bool = False,
) -> pd.Series:
    """Williams %R

    Call with:
        df['williams_r'] = bta.WilliamsR(df['high'], df['low'], df['close'], 14)
    Args:
        high(pandas.Series): dataset 'High' column.
        low(pandas.Series): dataset 'Low' column.
        close(pandas.Series): dataset 'Close' column.
        lbp(int): lookback period.
        fillna(bool): if True, fill nan values with -50.

    Returns:
        pandas.Series: New feature generated.
    """
    min_periods = 0 if fillna else lbp
    highest_high = high.rolling(lbp, min_periods=min_periods).max()
    lowest_low = low.rolling(lbp, min_periods=min_periods).min()
    wr = -100 * (highest_high - close) / (highest_high - lowest_low)
    if fillna:
        wr = wr.fillna(-50)
    return wr


        ----- End of momentum.py -----

        cycles.py

        ----- Start of cycles.py -----

# -*- coding: utf-8 -*-
import numpy as np
import pandas as pd
from .bamboo_ta import *

        ----- End of cycles.py -----

        bamboo_ta.py

        ----- Start of bamboo_ta.py -----

# bamboo_ta.py
# -*- coding: utf-8 -*-
# Import the individual bamboo ta libraries
from bamboo_ta.candles import *
from bamboo_ta.cycles import *
from bamboo_ta.momentum import *
from bamboo_ta.performance import *
from bamboo_ta.statistics import *
from bamboo_ta.trend import *
from bamboo_ta.utility import *
from bamboo_ta.volatility import *
from bamboo_ta.volume import *
        ----- End of bamboo_ta.py -----

        volatility.py

        ----- Start of volatility.py -----

# -*- coding: utf-8 -*-
# volatility.py
import numpy as np
import pandas as pd


def Average_True_Range(df, period=14):
# def ATR(df, period=14):
    """
    Average True Range (ATR)

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain columns 'high', 'low', and 'close'.
    - period (int): Period for the ATR calculation. Default is 14.

    Call with:
        atr = Average_True_Range(df)
        df['atr'] = atr

    Returns:
    - pd.Series: Series of ATR values.
    """
    df_copy = df.copy()
    df_copy['high_low'] = df_copy['high'] - df_copy['low']
    df_copy['high_close'] = (df_copy['high'] - df_copy['close'].shift()).abs()
    df_copy['low_close'] = (df_copy['low'] - df_copy['close'].shift()).abs()
    df_copy['true_range'] = df_copy[['high_low', 'high_close', 'low_close']].max(axis=1)
    df_copy['atr'] = df_copy['true_range'].rolling(window=period, min_periods=1).mean()

    return df_copy['atr']


def BollingerBands(df, column="close", period=20, std_dev=2, ddof=0):
    """
    Bollinger Bands (BBANDS)

    Call with:
        bb_result = bta.BollingerBands(df, "close", 21, 2, 0)
        df['bb_upper'] = bb_result['BB_upper']
        df['bb_middle'] = bb_result['BB_middle']
        df['bb_lower'] = bb_result['BB_lower']

    Args:
    df (pd.DataFrame): DataFrame containing the data
    column (str): The column name on which the BBANDS is to be applied
    period (int): Look-back period to compute the moving average
    std_dev (int): Number of standard deviations to compute the upper and lower bands
    ddof (int): Degrees of Freedom to use in standard deviation calculation. Default: 0

    Returns:
    pd.DataFrame: DataFrame with 'Upper_Band', 'Middle_Band', 'Lower_Band' columns added.
    """

    # Local import to avoid circular dependency
    from .trend import SMA

    # Middle Band = SMA
    sma = SMA(df, column=column, period=period)

    # Calculate standard deviation of the specified column
    rolling_std = df[column].rolling(window=period).std(ddof=ddof)

    # Upper Band = Middle Band + (std_dev * rolling standard deviation)
    upper_band = sma + (rolling_std * std_dev)

    # Lower Band = Middle Band - (std_dev * rolling standard deviation)
    lower_band = sma - (rolling_std * std_dev)

    # Returning as DataFrame
    return pd.DataFrame({
        'BB_upper': upper_band,
        'BB_middle': sma,
        'BB_lower': lower_band
    })


# def TR(df):
#     """
#     True Range (TR) calculation.
    
#     Parameters:
#     - df (pandas.DataFrame): Input DataFrame which should contain columns: 'high', 'low', and 'close'.
    
#     Returns:
#     - pandas.Series: A series of True Range values.
#     """
#     high_low = df['high'] - df['low']
#     high_close = np.abs(df['high'] - df['close'].shift())
#     low_close = np.abs(df['low'] - df['close'].shift())

#     tr = high_low.combine(high_close, max).combine(low_close, max)
#     return tr


def True_Range(df):
    """
    Calculate True Range (TR)

    Parameters:
    - df (pandas.DataFrame): Input DataFrame which should contain 'high', 'low', and 'close' columns.

    Call with:
        tr = True_Range(df)
        df['true_range'] = tr

    Returns:
    - pd.Series: Series of True Range values.
    """
    df_copy = df.copy()
    prev_close = df_copy['close'].shift()
    df_copy['true_range'] = pd.concat([df_copy['high'] - df_copy['low'], abs(df_copy['high'] - prev_close), abs(df_copy['low'] - prev_close)], axis=1).max(axis=1)

    return df_copy['true_range']


'''
TODO:
KeltnerChannel (+ width)
DonchianChannel (+ width)
Ulcer Index

    https://stockcharts.com/school/doku.php?id=chart_school:technical_indicators:ulcer_index

Bollingerbands width and more

'''
        ----- End of volatility.py -----

